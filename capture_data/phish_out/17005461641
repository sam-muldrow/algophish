<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head profile="http://gmpg.org/xfn/11">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>The Comonad.Reader</title>
	<meta name="generator" content="WordPress 2.8.4" /> <!-- leave this for stats please -->
	<style type="text/css" media="screen">
		@import url( http://comonad.com/reader/wp-content/themes/connections/style.css );
	</style>	
        <link rel="openid.server" href="https://api.screenname.aol.com/auth/openidServer"/>
        <link rel="openid.delegate" href="http://openid.aol.com/edwardallankmett"/>

	<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://comonad.com/reader/feed/" />
	<link rel="alternate" type="application/atom+xml" title="Atom 0.3" href="http://comonad.com/reader/feed/atom/" />
	<link rel="pingback" href="http://comonad.com/reader/xmlrpc.php" />
        <link rel="shortcut icon" href="http://comonad.com/reader/wp-content/themes/connections/favicon.ico" />
	<!--[if IE]><style type="text/css"> img { behavior: url(/reader/pngbehavior/pngbehavior.htc); } </style><![endif]-->
    	<link rel='archives' title='October 2022' href='http://comonad.com/reader/2022/10/' />
	<link rel='archives' title='January 2018' href='http://comonad.com/reader/2018/01/' />
	<link rel='archives' title='January 2016' href='http://comonad.com/reader/2016/01/' />
	<link rel='archives' title='September 2015' href='http://comonad.com/reader/2015/09/' />
	<link rel='archives' title='July 2015' href='http://comonad.com/reader/2015/07/' />
	<link rel='archives' title='May 2015' href='http://comonad.com/reader/2015/05/' />
	<link rel='archives' title='April 2015' href='http://comonad.com/reader/2015/04/' />
	<link rel='archives' title='February 2015' href='http://comonad.com/reader/2015/02/' />
	<link rel='archives' title='December 2014' href='http://comonad.com/reader/2014/12/' />
	<link rel='archives' title='August 2014' href='http://comonad.com/reader/2014/08/' />
	<link rel='archives' title='April 2014' href='http://comonad.com/reader/2014/04/' />
	<link rel='archives' title='May 2013' href='http://comonad.com/reader/2013/05/' />
	<link rel='archives' title='April 2013' href='http://comonad.com/reader/2013/04/' />
	<link rel='archives' title='January 2013' href='http://comonad.com/reader/2013/01/' />
	<link rel='archives' title='December 2012' href='http://comonad.com/reader/2012/12/' />
	<link rel='archives' title='September 2012' href='http://comonad.com/reader/2012/09/' />
	<link rel='archives' title='August 2012' href='http://comonad.com/reader/2012/08/' />
	<link rel='archives' title='June 2012' href='http://comonad.com/reader/2012/06/' />
	<link rel='archives' title='May 2012' href='http://comonad.com/reader/2012/05/' />
	<link rel='archives' title='April 2012' href='http://comonad.com/reader/2012/04/' />
	<link rel='archives' title='December 2011' href='http://comonad.com/reader/2011/12/' />
	<link rel='archives' title='November 2011' href='http://comonad.com/reader/2011/11/' />
	<link rel='archives' title='October 2011' href='http://comonad.com/reader/2011/10/' />
	<link rel='archives' title='September 2011' href='http://comonad.com/reader/2011/09/' />
	<link rel='archives' title='July 2011' href='http://comonad.com/reader/2011/07/' />
	<link rel='archives' title='June 2011' href='http://comonad.com/reader/2011/06/' />
	<link rel='archives' title='July 2010' href='http://comonad.com/reader/2010/07/' />
	<link rel='archives' title='May 2010' href='http://comonad.com/reader/2010/05/' />
	<link rel='archives' title='April 2010' href='http://comonad.com/reader/2010/04/' />
	<link rel='archives' title='September 2009' href='http://comonad.com/reader/2009/09/' />
	<link rel='archives' title='August 2009' href='http://comonad.com/reader/2009/08/' />
	<link rel='archives' title='July 2009' href='http://comonad.com/reader/2009/07/' />
	<link rel='archives' title='June 2009' href='http://comonad.com/reader/2009/06/' />
	<link rel='archives' title='March 2009' href='http://comonad.com/reader/2009/03/' />
	<link rel='archives' title='December 2008' href='http://comonad.com/reader/2008/12/' />
	<link rel='archives' title='November 2008' href='http://comonad.com/reader/2008/11/' />
	<link rel='archives' title='June 2008' href='http://comonad.com/reader/2008/06/' />
	<link rel='archives' title='May 2008' href='http://comonad.com/reader/2008/05/' />
	<link rel='archives' title='April 2008' href='http://comonad.com/reader/2008/04/' />
	<link rel='archives' title='March 2008' href='http://comonad.com/reader/2008/03/' />
	<link rel='archives' title='January 2008' href='http://comonad.com/reader/2008/01/' />
	<link rel='archives' title='July 2007' href='http://comonad.com/reader/2007/07/' />
	<link rel='archives' title='May 2007' href='http://comonad.com/reader/2007/05/' />
	<link rel='archives' title='November 2006' href='http://comonad.com/reader/2006/11/' />
	<link rel='archives' title='October 2006' href='http://comonad.com/reader/2006/10/' />
	<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://comonad.com/reader/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://comonad.com/reader/wp-includes/wlwmanifest.xml" /> 
<link rel='index' title='The Comonad.Reader' href='http://comonad.com/reader' />
<meta name="generator" content="WordPress 2.8.4" />
</head>

<body>
<div id="rap">
	<div id="header">
	<ul id="topnav">
		<li><a href="/reader" id="navHome" title="Posted Recently" accesskey="h">Home |</a></li>
		<li><a href="/reader/about/" id="navAbout" title="About the Author" accesskey="a">About |</a></li>
		<li><a href="/reader/source;item=libraries" id="navSource" title="Source Code" accesskey="s">Source |</a></li>
		<li><a href="mailto:ekmett@gmail.com" id="navContact" title="Contact the Author" accesskey="c">Contact </a></li>
	</ul>
	<a href="http://comonad.com/reader" id="logoHome" title="Posted Recently"><img id="logo" src="/reader/pngbehavior/blank.gif" ></a>
	<h1><a href="http://comonad.com/reader" title="The Comonad.Reader">The Comonad.Reader</a></h1>		
	<div id="desc">types, (co)monads, substructural logic</div>
</div>
	<div id="main">
	<div id="content">
						<div class="post">
				<p class="post-date">Fri 21 Oct 2022</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2022/internalized-guarded-recursion-for-equational-reasoning/" rel="bookmark" title="Permanent Link: Internalized Guarded Recursion for Equational Reasoning">Internalized Guarded Recursion for Equational Reasoning</a></h2>
Posted by Gershom Bazerman under <a href="http://comonad.com/reader/category/data-structures/" title="View all posts in Data Structures" rel="category tag">Data Structures</a> ,  <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> <br/><span>Comments Off</span>&nbsp;</div>
<div class="post-content">
	<p>I recently <a href="https://www.youtube.com/watch?v=xdUgkGqKjS8">presented a paper</a> on infinite traversals at the Haskell Symposium: <a href="https://gbaz.github.io/papers/3546189.3549915.pdf">A totally predictable outcome: an investigation of traversals of infinite structures</a>. The main result there is a characterization of when a call to <code>traverse</code> on an infinite Traversable functor (like an infinite lazy list) yields a non-bottom result. It turns out this is a condition on the Applicative one traverses with that loosely amounts to it having only a single data constructor. What I want to talk about here is how the technique introduced in that paper, which I call "internal guarded recursion" can be used not only in a lightweight formal way to prove characterization theorems or the like, but just in everyday programming as a "back of the envelope" or "streetfighting" hack to quickly figure out when recursive functional programs terminate and when they go into infinite loops.</p>
<p>Let's talk about the basic trick that makes the whole thing work. First, we introduce an abstract newtype for identity, which we will disallow pattern matching against, and instead only allow access to through the structure of an applicative functor.</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Later a = Later a <span style="color: #06c; font-weight: bold;">deriving</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a>
<span style="color: #06c; font-weight: bold;">instance</span> Applicative Later <span style="color: #06c; font-weight: bold;">where</span>
    pure = Later
    Later f &lt; *&gt; Later x = Later <span style="color: green;">&#40;</span>f x<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>Next, we introduce the <em>only</em> function allowed to perform recursion:</p>
<pre class="haskell">&nbsp;
lfix :: <span style="color: green;">&#40;</span>Later a -&gt; a<span style="color: green;">&#41;</span> -&gt; a
lfix f = fix <span style="color: green;">&#40;</span>f . pure<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>This function has almost the same type signature as the typical fixpoint operator, but it "guards" the argument to the function it is taking the fixedpoint of by our abstract <code>Later</code> type constructor.</p>
<p>Now, if you write code that only has recursion via `lfix` and no other function can implicitly or explicitly invoke itself (which the paper refers to as "working in the guarded fragment), your code will <i>never produce a bottom</i>. You can have whatever sorts of recursive Haskell '98 data definitions you like, it doesn't matter! (However, if you have "impredicative" datatypes that pack polymorphic functions into them, I think it would matter... but let's leave that aside). Try, for example, using only this form of recursion, to write a function that produces an infinite list. You'll realize that each recursive step requires using up one <code>Later</code> constructor as "fuel". And since there's no way to get an infinite amount of <code>Later</code> constructors to begin with, you'll only be able to produce lists of finite depth.</p>
<p>However, we <em>can</em> create related data structures to our existing ones, which "guard" their own recurrence behind a <code>Later</code> type constructor as well -- and we can create, consume and manipulate those also, and also do so without risk of writing an expression that produces a bottom. For example, here is the type of possibly infinite lists:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> Stream a =
    Nil
    | Cons a <span style="color: green;">&#40;</span>Later <span style="color: green;">&#40;</span>Stream a<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>And here is a function that interleaves two such lists:</p>
<pre class="haskell">&nbsp;
sinterleave :: Stream a -&gt; Stream a -&gt; Stream a
sinterleave = lfix $ \f s1 s2 -&gt; <span style="color: #06c; font-weight: bold;">case</span> s1 <span style="color: #06c; font-weight: bold;">of</span>
    <span style="color: green;">&#40;</span>Cons x xs<span style="color: green;">&#41;</span> -&gt; Cons x <span style="color: green;">&#40;</span>f &lt; *&gt; pure s2 &lt; *&gt; xs<span style="color: green;">&#41;</span>
    _ -&gt; s2
&nbsp;</pre>
<p>Now, I'm going to diverge from the paper and pose a sort of general problem, based on some discussions I had at ICFP. Suppose you have some tricky recursion, possibly involving "<a href="https://wiki.haskell.org/Tying_the_Knot">tying the knot</a>" and want to show that it terminates, or to figure out under which conditions it terminates -- how can you do that? It turns out that internal guarded recursion can help! Here's the recipe:</p>
<p>1. Write your function using only explicit recursion (via <code>fix</code>).<br />
2. Change <code>fix</code> to <code>lfix</code><br />
3. Figure out what work you have to do adding applicative operations involving <code>Later</code> to fix the types.</p>
<p>The paper has in it a general theorem that says, loosely speaking, that if you have code involving <code>lfix</code> and <code>Later</code>, and change that back to <code>fix</code> and erase all the mucking around with <code>Later</code> you get "essentially the same" function, and you still have a guarantee it won't produce bottoms. So this just turns that around -- start with your normal code, and show you can write it even in the guarded fragment, and then that tells you the properties of your original code!</p>
<p>I'll present this approach to reasoning about two tricky but well known problems in functional programming. First, as suggested by Tom Schrijvers as a question at the talk, is the famous "repmin" function introduced by Bird in <a href="https://link.springer.com/article/10.1007/BF00264249">1984</a>. This is a program that makes essential use of laziness to traverse a tree only once, but replacing each element in the tree by the minimum element anywhere in the tree. Here's a quick one-liner version, making use of traversal in the writer monad -- it works over any finite traversable structure, including typical trees. But it is perhaps easiest to test it over lists. For now, we'll ignore the issue of what happens with traversals of infinite structures, as that will complicate the example.</p>
<pre class="haskell">&nbsp;
repMin1 :: <span style="color: green;">&#40;</span>Traversable t, <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Ord"><span style="background-color: #efefbf; font-weight: bold;">Ord</span></a> a<span style="color: green;">&#41;</span> =&gt; t a -&gt; t a
repMin1 xs =
     <span style="color: #06c; font-weight: bold;">let</span> <span style="color: green;">&#40;</span>ans,m<span style="color: green;">&#41;</span> = <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:minimum"><span style="font-weight: bold;">minimum</span></a> . runWriter $
                    traverse <span style="color: green;">&#40;</span>\x -&gt; tell <span style="color: green;">&#91;</span>x<span style="color: green;">&#93;</span> &gt;&gt; pure m<span style="color: green;">&#41;</span> xs <span style="color: #06c; font-weight: bold;">in</span> ans
&nbsp;</pre>
<p>Note that this above definition makes use of a recursive definition -- the body of the definition of <code>(ans,m)</code> makes use of the <code>m</code> being defined.  This works because the definition does not pattern match on the m to compute -- otherwise we would bottom out. Using internal guarded recursion, we can let the type system guide us into rewriting our code into a form where it is directly evident that this does not bottom, rather than relying on careful reasoning about semantics. The first step is to mechanically transform the initial definition into one that is exactly the same, but where the implicit recursion has been rendered explicit by use of fix:</p>
<pre class="haskell">&nbsp;
repMin2 :: <span style="color: green;">&#40;</span>Traversable t, <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Ord"><span style="background-color: #efefbf; font-weight: bold;">Ord</span></a> a<span style="color: green;">&#41;</span> =&gt; t a -&gt; t a
repMin2 xs =
  <span style="color: #06c; font-weight: bold;">let</span> res = fix go <span style="color: #06c; font-weight: bold;">in</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fst"><span style="font-weight: bold;">fst</span></a> res
   <span style="color: #06c; font-weight: bold;">where</span>
    go res = <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:minimum"><span style="font-weight: bold;">minimum</span></a> . runWriter $
               traverse <span style="color: green;">&#40;</span>\x -&gt; tell <span style="color: green;">&#91;</span>x<span style="color: green;">&#93;</span> &gt;&gt; pure <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:snd"><span style="font-weight: bold;">snd</span></a> res<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> xs
&nbsp;</pre>
<p>The next step is to now replace <code>fix</code> by <code>lfix</code>. When we do so, the type of <code>go</code> will no longer be correct. In particular, its argument, <code>res</code> will now be guarded by a <code>Later</code>. So we can no longer apply <code>snd</code> directly to it, but instead have to <code>fmap</code>. The compiler will notice this and yell at us, at which point we make that small tweak as well. In turn, this forces a change to the type signature of the overall function. With that done, everything still checks!</p>
<pre class="haskell">&nbsp;
repMin3 :: <span style="color: green;">&#40;</span>Traversable t, <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Ord"><span style="background-color: #efefbf; font-weight: bold;">Ord</span></a> a<span style="color: green;">&#41;</span> =&gt; t a -&gt; t <span style="color: green;">&#40;</span>Later a<span style="color: green;">&#41;</span>
repMin3 xs =
  <span style="color: #06c; font-weight: bold;">let</span> res = lfix go <span style="color: #06c; font-weight: bold;">in</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fst"><span style="font-weight: bold;">fst</span></a> res
   <span style="color: #06c; font-weight: bold;">where</span>
    go res = <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:minimum"><span style="font-weight: bold;">minimum</span></a> . runWriter $
                traverse <span style="color: green;">&#40;</span>\x -&gt; tell <span style="color: green;">&#91;</span>x<span style="color: green;">&#93;</span> &gt;&gt; pure <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:snd"><span style="font-weight: bold;">snd</span></a> &lt; $&gt; res<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> xs
&nbsp;</pre>
<p>We have now verified that the original <code>repMin1</code> function does not bottom out on finite structures. Further, the "one layer" of <code>Later</code> in the type of <code>repMin3</code> tells us that there was exactly one recursive step invoked in computing the final result!</p>
<p>The astute reader may have noticed a further complication -- to genuinely be in the guarded recursive fragment, we need to make sure all functions in sight have not been written using standard recursion, but only with guarded recursion. But in fact, both <code>minimum</code> and <code>traverse</code> are going to be written recursively! We limited ourselves to considering finite trees to avoid worrying about this for our example. But let's now briefly consider what happens otherwise. By the results in the paper, we can still use a guarded recursive traverse in the writer monad, which will produce a potentially productive stream of results -- one where there may be arbitrarily many <code>Later</code> steps between each result. Further, a guarded recursive <code>minimum</code> on such a stream, or even on a necessarily productive <code>Stream</code> as given above, will necessarily produce a value that is potentially infinitely delayed. So without grinding out the detailed equational substitution, we can conclude that the type signature we would have to produce in the case of a potentially infinite tree would in fact be: <code>(Traversable t, Ord a) => t a -> t (Partial a)</code> -- where a partial value is one that may be delayed behind an arbitrary (including infinite) sequence of <code>Later</code>. This in turns tells us that <code>repMin</code> on a potentially infinite structure would still produce safely the <em>skeleton</em> of the structure we started with. However, at each individual leaf, the value would potentially be bottom. And, in fact, by standard reasoning (it takes an infinite amount of time to find the minimum of an infinite stream), we can conclude that when <code>repMin</code> is run on an infinite structure, then indeed each leaf <em>would</em> be bottom!</p>
<p>We'll now consider one further example, arising from <a href="https://scholarworks.brandeis.edu/esploro/outputs/undergraduate/Getting-A-Quick-Fix-On-Comonads/9923880018001921">work by Kenneth Foner</a> on fixed points of comonads. In their paper, Foner provides an efficient fixed point operator for comonads with an "apply" operator, but also makes reference to an inefficient version which they believe has the same semantics, and was introduced by Dominic Orchard. This latter operator is extremely simple to define, and so an easy candidate for an example. We'll first recall the methods of comonads, and then introduce Orchard's fixed-point:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">class</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> w =&gt; <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#t:Comonad"><span style="background-color: #efefbf; font-weight: bold;">Comonad</span></a> w <span style="color: #06c; font-weight: bold;">where</span>
    <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extract"><span style="font-weight: bold;">extract</span></a> :: w a -&gt; a
    <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:duplicate"><span style="font-weight: bold;">duplicate</span></a> :: w a -&gt; w <span style="color: green;">&#40;</span>w a<span style="color: green;">&#41;</span>
    <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extend"><span style="font-weight: bold;">extend</span></a> :: <span style="color: green;">&#40;</span>w a -&gt; b<span style="color: green;">&#41;</span> -&gt; w a -&gt; w b
&nbsp;
cfix f :: <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#t:Comonad"><span style="background-color: #efefbf; font-weight: bold;">Comonad</span></a> w =&gt; <span style="color: green;">&#40;</span>w a -&gt; a<span style="color: green;">&#41;</span> -&gt; w a
cfix f = fix <span style="color: green;">&#40;</span><a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extend"><span style="font-weight: bold;">extend</span></a> f<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>So the question is -- when does cfix not bottom out? To answer this, we again just change <code>fix</code> to <code>lfix</code> and let the typechecker tells us what goes wrong. We quickly discover that our code no longer typechecks, because <code>lfix</code> enforces we are given a <code>Later (w a)</code> but the argument to <code>extend f</code> needs to be a plain old <code>w a</code>. We ask ghc for the type of the intermediate conversion function necessary, and arrive at the following:</p>
<pre class="haskell">&nbsp;
lcfix :: <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#t:Comonad"><span style="background-color: #efefbf; font-weight: bold;">Comonad</span></a> w =&gt; <span style="color: green;">&#40;</span>Later <span style="color: green;">&#40;</span>w b<span style="color: green;">&#41;</span> -&gt; w a<span style="color: green;">&#41;</span> -&gt; <span style="color: green;">&#40;</span>w a -&gt; b<span style="color: green;">&#41;</span> -&gt; w b
lcfix conv f = lfix <span style="color: green;">&#40;</span><a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extend"><span style="font-weight: bold;">extend</span></a> f . conv<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>So we discover that comonad fix will not bottom when we can provide some <code>conv</code> function that is "like the identity" (so it erases away when we strip out the mucking about with <code>Later</code>) but can send <code>Later (w a) -> w b</code>. If we choose to unify <code>a</code> and <code>b</code>, then this property (of some type to be equipped with an "almost identity" between it and it delayed by a <code>Later</code>) is examined in the paper at some length under the name "stability" -- and our conclusion is that cfix will terminate when the type <code>w a</code> is stable (which is to say that it in one way or another represents a potentially partial value). Also from the paper, we know that one easy way to get stability is when the type <code>w</code> is <code>Predictable</code> -- i.e. when it has an "almost identity" map <code>Later (w a) -> w (Later a)</code> and when <code>a</code> itself is stable. This handles most uses of comonad fix -- since functors of "fixed shape" (otherwise known as representable, or iso to <code>r -> a</code> for a fixed <code>r</code>) are all stable. And the stability condition on the underlying <code>a</code> tells us that even though we'll get out a perfectly good spine, whether or not there will be a bottom value at any given location in the resultant <code>w a</code> depends on the precise function being passed in.</p>
<p>In fact, if we simply start with the idea of predictability in hand, we can specialize the above code in a different way, by taking <code>predict</code> itself to be our conversion function, and unifying <code>b</code> with <code>Later a</code>, which yields the following:</p>
<pre class="haskell">&nbsp;
lcfix2 :: <span style="color: green;">&#40;</span><a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#t:Comonad"><span style="background-color: #efefbf; font-weight: bold;">Comonad</span></a> w, Predict w<span style="color: green;">&#41;</span> =&gt; <span style="color: green;">&#40;</span>w <span style="color: green;">&#40;</span>Later a<span style="color: green;">&#41;</span> -&gt; a<span style="color: green;">&#41;</span> -&gt; w a
lcfix2 f = lfix <span style="color: green;">&#40;</span><a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extend"><span style="font-weight: bold;">extend</span></a> f . predict<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>This signature is nice because it does not require stability -- i.e. there is no possibility of partial results. Further, it is particularly suggestive -- it looks almost like that of <code>lfix</code> but lifts both the input to the argument and the output of the fixed-point up under a <code>w</code>. This warns us how hard it is to get useful values out of fixing a comonad -- in particular, just as with our <code>lfix</code> itself, we can't directly pattern match on the values we are taking fixed points of, but instead only use them in constructing larger structures.</p>
<p>These examples illustrate both the power of the internal guarded recursion approach, and also some of its limits. It can tell us a lot of high level information about what does and doesn't produce bottoms, and it can produce conditions under which bottoms will never occur. However, there are also cases where we have code that sometimes bottoms, depending on specific functions it is passed -- the fact that it potentially bottoms is represented in the type, but the exact conditions under which bottoms will or will not occur aren't able to be directly "read off". In fact, in the references to the paper, there are much richer variants of guarded recursion that allow more precision in typing various sorts of recursive functions, and of course there is are general metamathematical barriers to going sufficiently far -- a typing system rich enough to say if any integer function terminates is also rich enough to say if e.g. the collatz conjecture is true or not! But with all those caveats in mind, I think this is still a useful tool that doesn't only have theoretical properties, but also practical use. The next time you have a tricky recursive function that you're <em>pretty sure</em> terminates, try these simple steps: 1) rewrite to use explicit fixed points; 2) change those to guarded recursive fixed points; 3) let ghc guide you in fixing the types; 4) see what you learn!</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Tue 16 Jan 2018</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2018/computational-quadrinitarianism-curious-correspondences-go-cubical/" rel="bookmark" title="Permanent Link: Computational Quadrinitarianism (Curious Correspondences go Cubical)">Computational Quadrinitarianism (Curious Correspondences go Cubical)</a></h2>
Posted by Gershom Bazerman under <a href="http://comonad.com/reader/category/uncategorized/" title="View all posts in Uncategorized" rel="category tag">Uncategorized</a> <br/><a href="http://comonad.com/reader/2018/computational-quadrinitarianism-curious-correspondences-go-cubical/#comments" title="Comment on Computational Quadrinitarianism (Curious Correspondences go Cubical)">[103] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>Back in 2011, in an influential blog post [<a href="#1">1</a>], Robert Harper coined the term  "computational trinitarianism" to describe an idea that had been around a long time — that the connection between programming languages, logic, and categories, most famously expressed in the Curry-Howard-Lambek correspondence — should guide the practice of researchers into computation. In particular "any concept arising in one aspect should have meaning from the perspective of the other two". This was especially satisfying to those of us trying learning categorical semantics and often finding it disappointing how little it is appreciated in the computer science community writ large.</p>
<h4>1. Categories</h4>
<p>Over the years I've thought about trinitarianism a lot, and learned from where it fails to work as much as where it succeeds. One difficulty is that learning to read a logic like a type theory, or vice versa, is almost a definitional trick, because it occurs at the level of reinterpretation of syntax. With categories it is  typically not so easy. (There is a straightforward version of categorical semantics like this — yielding "syntactic categories" — but it is difficult to connect it to the broader world of categorical semantics, and often it is sidestepped in favor of deeper models.)</p>
<p>One thing I came to realize is that there is no one notion of categorical semantics — the way in which the simply typed lambda calculus takes models in cartesian closed categories is fundamentally unlike the way in which linear logics take models in symmetric monoidal categories. If you want to study models of dependent type theories, you have a range of approaches, only some of which have been partially unified by Ahrens, Lumsdaine and Voevodsky in particular [<a href="#2">2</a>]. And then there are the LCCC models pioneered by Seely for extensional type theory, not to mention the approach that takes semantics directly in toposes, or in triposes (the latter having been invented to unify a variety of structures, and in the process giving rise to still more questions). And then there is the approach that doesn't use categories at all, but multicategories.</p>
<p>Going the other way, we also run into obstacles: there is a general notion, opposite to the "syntactic category" of a type theory, which is the "internal logic" of a category. But depending on the form of category, "internal logic" can take many forms. If you are in a topos, there is a straightforward internal logic called the Mitchell–Bénabou language. In this setting, most "logical" operations factor through the truth-lattice of the subobject classifier. This is very convenient, but if you don't have a proper subobject classifier, then you are forced to reach for other interpretations. As such, it is not infrequently the case that we have a procedure for deriving a category from some logical theory, and a procedure for constructing a logical theory from some category, but there is no particular reason to expect that where we arrive, when we take the round-trip, is close to, much less precisely, where we began.</p>
<h4>2. Spaces, Logics</h4>
<p>Over the past few years I've been in a topos theory reading group. In the course of this, I've realized at least one problem with all the above (by no means the only one) — Harper's holy trinity is fundamentally incomplete. There is another structure of interest — of equal weight to categories, logics, and languages — which it is necessary to understand to see how everything fits. This structure is <i>spaces</i>. I had thought that it was a unique innovation of homotopy type theory to consider logics (resp. type theories) that took semantics in spaces. But it turns out that I just didn't know the history of constructive logic very well. In fact, in roughly the same period that Curry was exploring the relationship of combinatory algebras to logic, Alfred Tarski and Marshall Stone were developing <i>topological</i> models for intuitionistic logic, in terms of what we call Heyting Algebras [<a href="#3">3</a>] [<a href="#4">4</a>]. And just as, as Harper explained, logic, programming and category theory give us insights into implication in the form of entailment, typing judgments, and morphisms, so to, as we will see, do spaces.</p>
<p>A Heyting algebra is a special type of distributive lattice (partially ordered set, equipped with meet and join operations, such that meet and join distribute over one another) which has an implication operation that satisfies curry/uncurry adjointness — i.e. such that c ∧ a ≤ b < -> c ≤ a → b. (Replace meet here by "and" (spelled "*"), and ≤ by ⊢ and we have the familiar type-theoretic statement that c * a ⊢ b < -> c ⊢ a → b).</p>
<p>If you haven't encountered this before, it is worth unpacking. Given a set, we equip it with a partial order by specifying a "≤" operation, such that a ≤ a, if a ≤ b and b ≤ a, then a = b, and finally that if a ≤ b and b ≤ c, then a ≤ c. We can think of such things as Hasse diagrams — a bunch of nodes with some lines between them that only go upwards. If a node b is reachable from a node a by following these upwards lines, then a ≤ b. This "only upwards" condition is enough to enforce all three conditions. We can define ∨ (join) as a binary operation that takes two nodes, and gives a node a ∨ b that is greater than either node, and furthermore is the <i>uniquely least</i> node greater than both of them. (Note: A general partial order may have many pairs of nodes that do not have any node greater than both of them, or may that may have more than one incomparable node greater than them.) We can define ∧ (meet) dually, as the uniquely greatest node less than both of them. If all elements of a partially ordered set have a join and meet, we have a lattice.</p>
<p>It is tempting to read meet and join as "and" and "or" in logic. But these logical connectives satisfy an additional important property — distributivity: a & (b | c) = (a & b) | (a & c). (By the lattice laws, the dual property with and swapped with or is also implied). Translated for lattices this reads: a ∧ (b ∨ c) = (a ∧ b) ∨ (a ∧ c). Rather than thinking just about boolean logic, we can think about lattices built from sets — with meets as union, join as intersection, and ≤ given by inclusion. It is easy to verify that such lattices are distributive. Furthermore, every distributive lattice can be given (up to isomorphism) as one built out of sets in this way. While a partially ordered set can have a Hasse diagram of pretty arbitrary shape, a lattice is more restrictive — I imagine it as sort of the tiled diamonds of an actual lattice like one might use in a garden, but with some nodes and edges possibly removed.</p>
<p>Furthermore, there's an amazing result that you can tell if a lattice is distributive by looking for just two prototypical non-distributive lattices as sublattices. If neither is contained in the original lattice, then the lattice is distributed. These tell us how distribution can fail in two canonical ways. The first is three incomparable elements, all of which share a common join (the top) and meet (the bottom). The join of anything but their bottom element with them is therefore the top. Hence if we take the meet of two joins, we still get the top. But the meet of any two non-top elements is the bottom and so, if we take the join of any element with the meet of any other two, we get back to the first element, not all the way to the top, and the equality fails. The second taboo lattice is constructed by having two elements in an ordered relationship, and another incomparable to them — again  augmented with a bottom and top. A similar argument shows that if you go one way across the desired entity, you pick out the topmost of the two ordered elements, and the other way yields the bottommost. (The <a href="https://en.wikipedia.org/wiki/Distributive_lattice#Characteristic_properties">wikipedia article on distributive lattices</a> has some very good diagrams to visualize all this). So a distributive lattice has even more structure than before — incomparable elements must have enough meets and joins to prevent these sublattices from appearing, and this forces even more the appearance of a tiled-diamond like structure.</p>
<p>To get us to a Heyting algebra, we need more structure still — we need implication, which is like an internal function arrow, or an internal ≤ relation. Recall that the equation we want to satisfy is "c ∧ a ≤ b < -> c ≤ a → b". The idea is that we should be able to read ≤ itself as an "external implication" and so if c and a taken together imply b, "a implies b" is the portion of that implication if we "only have" c. We can see it as a partial application of the external implication. If we have a lattice that permits infinite joins (or just a finite lattice such that we don't need them), then it is straightforward to see how to construct this. To build a → b, we just look at <i>every possible</i> choice of c that satisfies c ∧ a ≤ b, and then take the join of all of them to be our object a → b. Then, by construction, a → b is necessarily greater than or equal to any c that satisfies the left hand side of the equation. And conversely, any element that a → b is greater than is necessarily one that satisfies the left hand side, and the bi-implication is complete. (This, by the way, gives a good intuition for the definition of an exponential in a category of presheaves). Another way to think of a → b is as the greatest element of the lattice such that a → b ∧ a ≤ b (exercise: relate this to the first definition). It is also a good exercise to explore what happens in certain simple cases — what if a is 0 (false)? What if it is 1? The same as b? Now ask the same questions of b.</p>
<p>So why is a Heyting algebra a <i>topological</i> construct? Consider any topological space as given by a collection of open sets, satisfying the usual principles (including the empty set and the total set, and closed under union and finite intersection). These covers have a partial ordering, given by containment. They have unions and intersections (all joins and meets), a top and bottom element (the total space, and the null space). Furthermore, they have an implication operation as described above. As an open set, a → b is given by the meet of all opens c for which a ∧ c ≤ b. (We can think of this as "the biggest context, for which a ⊢ b"). In fact, the axioms for open sets feel almost exactly like the rules we've described for Heyting algebras. It turns out this is only half true — open sets always give Heyting algebras, and we can turn every Heyting algebra into a space. However, in both directions the round trip may take us to somewhere slightly different than where we started. Nonetheless it turns out that if we take complete Heyting algebras where finite meets distribute over infinite joins, we get something called "frames." And the opposite category of frames yields "locales" — a suitable generalization of topological spaces, first named by John Isbell in 1972 [<a href="#5">5</a>].  Spaces that correspond precisely to locales are called <i>sober</i>, and locales that correspond precisely to spaces are said to have "enough points" or be "spatial locales".</p>
<p>In fact, we don't need to fast-forward to 1972 to get some movement in the opposite direction. In 1944, McKinsey and Tarski embarked on a program of "The Algebra of Topology" which sought to describe topological spaces in purely algebraic (axiomatic) terms [<a href="#6">6</a>]. The resultant closure algebras (these days often discussed as their duals, interior algebras) provided a semantics for S4 modal logic. [<a href="#7">7</a>] A further development in this regard came with Kripke models for logic [<a href="#8">8</a>] (though arguably they're really Beth models [<a href="#9">9</a>]).</p>
<p>Here's an easy way to think about Kripke models. Start with any partial ordered set. Now, for each object, instead consider instead all morphisms into it. Since each morphism from any object a to any object b exists only if a ≤ b, and we consider such paths unique (if there are two "routes" showing a ≤ b, we consider them the same in this setting) this amounts to replacing each element a with the set of all elements ≤ a. (The linked pdf does this upside down, but it doesn't really matter). Even though the initial setting may not have been Heyting algebra, this transformed setting <i>is</i> a Heyting algebra. (In fact, by a special case of the Yoneda lemma!). This yields Kripke models.</p>
<p>Now consider "collapsings" of elements in the initial partial order — monotone downwards maps taken by sending some elements to other elements less than them in a way that doesn't distort orderings. (I.e. if f(a) ≤ f(b) in the collapsed order, then that means that a ≤ b in the original order). Just as we can lift elements from the initial partial order into their downsets (sets of elements less than them) in the kripkified Heyting Algebra, we can lift our collapsing functions into collapsing functions in our generated Heyting Algebra. With a little work we can see that collapsings in the partial order also yield collapsings in the Heyting Algebra.</p>
<p>Furthermore, it turns out, more or less, that you can generate every closure algebra in this way. Now if we consider closure algebras a bit (and this shouldn't surprise us if we know about S4), we see that we can always take a to Ca, that if we send a → b, then we can send Ca → Cb, and furthermore that CCa → Ca in a natural way (in fact, they're equal!). So closure algebras have the structure of an idempotent monad. (Note: the arrows here should not be seen as representing internal implication — as above they represent the logical turnstile ⊢ or perhaps, if you're really in a Kripke setting, the forcing turnstile ⊩).</p>
<p>Now we have a correspondence between logic and computation (Curry-Howard), logic and categories (Lambek-Scott), and logic and spaces (Tarski-Stone). So maybe, instead of Curry-Howard-Lambek, we should speak of Curry-Howard-Lambek-Scott-Tarski-Stone! (Or, if we want to actually bother to say it, just Curry-Howard-Lambek-Stone. Sorry, Tarski and Scott!) Where do the remaining correspondences arise from? A cubical Kan operation, naturally! But let us try to sketch in a few more details.</p>
<h4>3. Spaces, Categories</h4>
<p>All this about monads and Yoneda suggests that there's something categorical going on. And indeed, there is. A poset is, in essence, a "decategorified category" — that is to say, a category where any two objects have at most one morphism between them. I think of it as if it were a balloon animal that somebody let all the air out of. We can pick up the end of our poset and blow into it, inflating the structure back up, and allowing multiple morphisms between each object. If we do so, something miraculous occurs — our arbitrary posets turn into arbitrary categories, and the induced Heyting algebra from their opens turns into the induced category of set-valued presheaves of that category. The resultant structure is a presheaf topos. If we "inflate up" an appropriate notion of a closure operator we arrive at a Grothendieck topos! And indeed, the internal language of a topos is higher-order intuitionistic type theory [<a href="#10">10</a>].</p>
<h4>4. Spaces, Programming Languages</h4>
<p>All of this suggests a compelling story: logic describes theories via algebraic syntax. Equipping these theories with various forms of structural operations produces categories of one sort or another, in the form of fibrations. The intuition is that types are spaces, and contexts are <i>also</i> spaces. And furthermore, types are <i>covered</i> by the contexts in which their terms may be derived. This is one sense in which we it seems possible to interpret the Meillies/Zeilberger notion of a type refinement system as a functor [<a href="#11">11</a>].</p>
<p>But where do programming languages fit in? Programming languages, difficult as it is to sometimes remember, are more than their type theories. They have a semantic of computation as well. For example, a general topos does not have partial functions, or a fixed point combinator. But computations, often, do. This led to one of the first applications of topology to programming languages — the introduction of domain theory, in which terms are special kinds of spaces — directed complete partial orders — and functions obey a special kind of continuity (preservation of directed suprema) that allows us to take their fixed points. But while the category of dcpos is cartesian closed, the category of dcpos with only appropriately continuous morphisms is <i>not</i>. Trying to resolve this gap, one way or another, seems to have been a theme of research in domain theory throughout the 80s and 90s [<a href="#12">12</a>].</p>
<p>Computations can also be concurrent. Topological and topos-theoretic notions again can play an important role. In particular, to consider two execution paths to be "the same" one needs a notion of equivalence. This equivalence can be seen, stepwise, as a topological "two-cell" tracing out at each step an equivalence between the two execution paths. One approach to this is in Joyal, Nielson and Winskel's treatment of open maps [<a href="#13">13</a>]. I've also just seen Patrick Schultz and David I. Spivak's "Temporal Type Theory" which seems very promising in this regard  [<a href="#14">14</a>].</p>
<p>What is the general theme? Computation starts somewhere, and then goes somewhere else. If it stayed in the same place, it would not "compute". A computation is necessarily a path in some sense. Computational settings describe ways to take maps between spaces, under a suitable notion of topology. To describe the spaces themselves, we need a language — that language is a logic, or a type theory. Toposes are a canonical place (though not the only one) where logics and spaces meet (and where, to a degree, we can even distinguish their "logical" and "spatial" content). That leaves categories as the ambient language in which all this interplay can be described and generalized.</p>
<h4>5. Spaces, Categories</h4>
<p>All the above only sketches the state of affairs up to roughly the mid '90s. The connection to spaces starts in the late 30s, going through logic, and then computation. But the categorical notion of spaces we have is in some sense impoverished. A topos-theoretic generalization of a space still only describes, albeit in generalized terms, open sets and their lattice of subobject relations. Spaces have a whole other structure built on top of that. From their topology we can extract algebraic structures that describe their shape — this is the subject of algebraic topology. In fact, it was in axiomatizing a branch of algebraic topology (homology) that category theory was first compelled to be invented. And the "standard construction" of a monad was first constructed in the study of homology groups (as the Godement resolution).</p>
<p>What happens if we turn the tools of categorical generalization of algebraic topology on categories themselves? This corresponds to another step in the "categorification" process described above. Where to go from "0" to "1" we took a partially ordered set and allowed there to be multiple maps between objects, to go from "1" to "2" we can now take a category, where such multiple maps exist, and allow there to be multiple maps <i>between maps</i>.  Now two morphisms, say "f . g" and "h" need not merely be equal or not, but they may be "almost equal" with their equality given by a 2-cell. This is just as two homotopies between spaces may themselves be homotopic. And to go from "2" to "3" we can continue the process again. This yields n-categories. An n-category with all morphisms at every level invertible is an (oo,0)-category, or an infinity groupoid. And in many setups this is the same thing as a topological space (and the question of which setup is appropriate falls under the name "homotopy hypothesis" [<a href="#15">15</a>]). When morphisms at the first level (the category level) can have direction (just as in normal categories) then those are (oo,1)-categories, and the correspondence between groupoids and spaces is constructed as an equivalence of such categories. These too have direct topological content, and one setting in which this is especially apparent is that of quasi-categories, which are (oo,1)-categories that are built directly from simplicial sets — an especially nice categorical model of spaces (the simplicial sets at play here are those that satisfy a "weak" Kan condition, which is a way of asking that composition behave correctly).</p>
<p>It is in these generalized (oo,1)-toposes that homotopy type theory takes its models. And, it is hypothesized that a suitable version of HoTT should in fact be the initial model (or "internal logic") of an "elementary infinity topos" when we finally figure out how to describe what such a thing is.</p>
<p>So perhaps it is not that we should be computational trinitarians, or quadrinitarians. Rather, it is that the different aspects which we examine — logic, languages, categories, spaces — only appear as distinct manifestations when viewed at a low dimensionality. In the untruncated view of the world, the modern perspective is, perhaps, topological pantheism — spaces are in all things, and through spaces, all things are made as one.</p>
<p><i>Thanks to James Deikun and Dan Doel for helpful technical and editorial comments</i></p>
<p>[<a name="1"></a>1] <a href="https://existentialtype.wordpress.com/2011/03/27/the-holy-trinity/">https://existentialtype.wordpress.com/2011/03/27/the-holy-trinity/<br />
[</a><a name="2"></a>2] <a href="https://arxiv.org/abs/1705.04310">https://arxiv.org/abs/1705.04310</a><br />
[<a name="3"></a>3] <a href="http://www.sciacchitano.it/Tempo/Aussagenkalk%C3%BCl%20Topologie.pdf">http://www.sciacchitano.it/Tempo/Aussagenkalk%C3%BCl%20Topologie.pdf</a><br />
[<a name="4"></a>4] <a href="https://eudml.org/doc/27235">https://eudml.org/doc/27235</a><br />
[<a name="5"></a>5] <a href="http://www.mscand.dk/article/view/11409">http://www.mscand.dk/article/view/11409</a><br />
[<a name="6"></a>6] <a href="https://www.dimap.ufrn.br/~jmarcos/papers/AoT-McKinsey_Tarski.pdf">https://www.dimap.ufrn.br/~jmarcos/papers/AoT-McKinsey_Tarski.pdf</a><br />
[<a name="7"></a>7] <a href="https://logic.berkeley.edu/colloquium/BezhanishviliSlides.pdf">https://logic.berkeley.edu/colloquium/BezhanishviliSlides.pdf</a><br />
[<a name="8"></a>8] <a href="www2.math.uu.se/~palmgren/tillog/heyting3.pdf">www2.math.uu.se/~palmgren/tillog/heyting3.pdf</a><br />
[<a name="9"></a>9] <a href="http://festschriften.illc.uva.nl/j50/contribs/troelstra/troelstra.pdf">http://festschriften.illc.uva.nl/j50/contribs/troelstra/troelstra.pdf</a><br />
[<a name="10"></a>10] <a href="http://www.sciencedirect.com/science/article/pii/0022404980901024">http://www.sciencedirect.com/science/article/pii/0022404980901024</a><br />
[<a name="11"></a>11] <a href="https://arxiv.org/abs/1310.0263">https://arxiv.org/abs/1310.0263</a><br />
[<a name="12"></a>12] <a href="https://www.dpmms.cam.ac.uk/~martin/Research/Oldpapers/synthetic91.pdf">https://www.dpmms.cam.ac.uk/~martin/Research/Oldpapers/synthetic91.pdf</a><br />
[<a name="13"></a>13] <a href="http://www.brics.dk/RS/94/7/index.html">http://www.brics.dk/RS/94/7/index.html</a><br />
[<a name="14"></a>14] <a href="https://arxiv.org/abs/1710.10258">https://arxiv.org/abs/1710.10258</a><br />
[<a name="15"></a>15] <a href="https://ncatlab.org/nlab/show/homotopy+hypothesis">https://ncatlab.org/nlab/show/homotopy+hypothesis</a></p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Sat 6 Jan 2018</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2018/the-state-comonad/" rel="bookmark" title="Permanent Link: The State Comonad">The State Comonad</a></h2>
Posted by Edward Kmett under <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> ,  <a href="http://comonad.com/reader/category/monads/" title="View all posts in Monads" rel="category tag">Monads</a> <br/><a href="http://comonad.com/reader/2018/the-state-comonad/#comments" title="Comment on The State Comonad">[49] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>Is <code>State</code> a <code>Comonad</code>? </p>
<p>Not <code>Costate</code> or rather, <code>Store</code> as we tend to call it today, but actually <code>State s</code> itself?</p>
<p>Let's see!</p>
<p> <a href="http://comonad.com/reader/2018/the-state-comonad/#more-1139" class="more-link">(more...)</a></p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Wed 13 Jan 2016</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2016/adjoint-triples/" rel="bookmark" title="Permanent Link: Adjoint Triples">Adjoint Triples</a></h2>
Posted by Dan Doel under <a href="http://comonad.com/reader/category/category-theory/" title="View all posts in Category Theory" rel="category tag">Category Theory</a> ,  <a href="http://comonad.com/reader/category/comonads/" title="View all posts in Comonads" rel="category tag">Comonads</a> ,  <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> ,  <a href="http://comonad.com/reader/category/logic/" title="View all posts in Logic" rel="category tag">Logic</a> ,  <a href="http://comonad.com/reader/category/mathematics/" title="View all posts in Mathematics" rel="category tag">Mathematics</a> ,  <a href="http://comonad.com/reader/category/monads/" title="View all posts in Monads" rel="category tag">Monads</a> ,  <a href="http://comonad.com/reader/category/type-theory/" title="View all posts in Type Theory" rel="category tag">Type Theory</a> ,  <a href="http://comonad.com/reader/category/uncategorized/" title="View all posts in Uncategorized" rel="category tag">Uncategorized</a> <br/><a href="http://comonad.com/reader/2016/adjoint-triples/#comments" title="Comment on Adjoint Triples">[426] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>A common occurrence in category theory is the <a href="https://ncatlab.org/nlab/show/adjoint+triple">adjoint triple</a>. This is a pair of adjunctions relating three functors:</p>
<pre>
F ⊣ G ⊣ H
F ⊣ G, G ⊣ H
</pre>
<p>Perhaps part of the reason they are so common is that (co)limits form one:</p>
<pre>
colim ⊣ Δ ⊣ lim
</pre>
<p>where <code>Δ : C -> C^J</code> is the diagonal functor, which takes objects in <code>C</code> to the constant functor returning that object. A version of this shows up in Haskell (with some extensions) and dependent type theories, as:</p>
<pre>
∃ ⊣ Const ⊣ ∀
Σ ⊣ Const ⊣ Π
</pre>
<p>where, if we only care about quantifying over a single variable, existential and sigma types can be seen as a left adjoint to a diagonal functor that maps types into constant type families (either over <code>*</code> for the first triple in Haskell, or some other type for the second in a dependently typed language), while universal and pi types can be seen as a right adjoint to the same.</p>
<p>It's not uncommon to see the above information in type theory discussion forums. But, there are a few cute properties and examples of adjoint triples that I haven't really seen come up in such contexts.</p>
<p>To begin, we can compose the two adjunctions involved, since the common functor ensures things match up. By calculating on the hom definition, we can see:</p>
<pre>
Hom(FGA, B)     Hom(GFA, B)
    ~=              ~=
Hom(GA, GB)     Hom(FA, HB)
    ~=              ~=
Hom(A, HGB)     Hom(A, GHB)
</pre>
<p>So there are two ways to compose the adjunctions, giving two induced adjunctions:</p>
<pre>
FG ⊣ HG,  GF ⊣ GH
</pre>
<p>And there is something special about these adjunctions. Note that <code>FG</code> is the comonad for the <code>F ⊣ G</code> adjunction, while <code>HG</code> is the monad for the <code>G ⊣ H</code> adjunction. Similarly, <code>GF</code> is the <code>F ⊣ G</code> monad, and <code>GH</code> is the <code>G ⊣ H</code> comonad. So each adjoint triple gives rise to two adjunctions between monads and comonads.</p>
<p>The second of these has another interesting property. We often want to consider the algebras of a monad, and coalgebras of a comonad. The (co)algebra operations with carrier <code>A</code> have type:</p>
<pre>
alg   : GFA -> A
coalg : A -> GHA
</pre>
<p>but these types are isomorphic according to the <code>GF ⊣ GH</code> adjunction. Thus, one might guess that <code>GF</code> monad algebras are also <code>GH</code> comonad coalgebras, and that in such a situation, we actually have some structure that can be characterized both ways. In fact this is true for any monad left adjoint to a comonad; <a href="#note0">[0]</a> but all adjoint triples give rise to these.</p>
<p>The first adjunction actually turns out to be more familiar for the triple examples above, though. (Edit: <a href="#note2">[2]</a>) If we consider the <code>Σ ⊣ Const ⊣ Π</code> adjunction, where:</p>
<pre>
Σ Π : (A -> Type) -> Type
Const : Type -> (A -> Type)
</pre>
<p>we get:</p>
<pre>
ΣConst : Type -> Type
ΣConst B = A × B
ΠConst : Type -> Type
ΠConst B = A -> B
</pre>
<p>So this is the familiar adjunction:</p>
<pre>
A × - ⊣ A -> -
</pre>
<p>But, there happens to be a triple that is a bit more interesting for both cases. It refers back to categories of functors vs. bare type constructors mentioned in previous posts. So, suppose we have a category called <code>Con</code> whose objects are (partially applied) type constructors (f, g) with kind <code>* -> *</code>, and arrows are polymorphic functions with types like:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">forall</span> x. f x -&gt; g x
&nbsp;</pre>
<p>And let us further imagine that there is a similar category, called <code>Func</code>, except its objects are the things with <code>Functor</code> instances. Now, there is a functor:</p>
<pre>
U : Func -> Con
</pre>
<p>that 'forgets' the functor instance requirement. This functor is in the middle of an adjoint triple:</p>
<pre>
F ⊣ U ⊣ C
F, C : Con -> Func
</pre>
<p>where <code>F</code> creates the free functor over a type constructor, and <code>C</code> creates the cofree functor over a type constructor. These can be written using the types:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> F f a = <span style="color: #06c; font-weight: bold;">forall</span> e. F <span style="color: green;">&#40;</span>e -&gt; a<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>f e<span style="color: green;">&#41;</span>
<span style="color: #06c; font-weight: bold;">newtype</span> C f a = C <span style="color: green;">&#40;</span><span style="color: #06c; font-weight: bold;">forall</span> r. <span style="color: green;">&#40;</span>a -&gt; r<span style="color: green;">&#41;</span> -&gt; f r<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>and these types will also serve as the types involved in the composite adjunctions:</p>
<pre>
FU ⊣ CU : Func -> Func
UF ⊣ UC : Con -> Con
</pre>
<p>Now, <code>CU</code> is a monad on functors, and the Yoneda lemma tells us that it is actually the identity monad. Similarly, <code>FU</code> is a comonad, and the co-Yoneda lemma tells us that it is the identity comonad (which makes sense, because identity is self-adjoint; and the above is why <code>F</code> and <code>C</code> are often named <code>(Co)Yoneda</code> in Haskell examples).</p>
<p>On the other hand, <code>UF</code> is a <em>monad</em> on type constructors (note, <code>U</code> isn't represented in the Haskell types; <code>F</code> and <code>C</code> just play triple duty, and the constraints on <code>f</code> control what's going on):</p>
<pre class="haskell">&nbsp;
eta :: f a -&gt; F f a
eta = F <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a>
&nbsp;
transform :: <span style="color: green;">&#40;</span><span style="color: #06c; font-weight: bold;">forall</span> x. f x -&gt; g x<span style="color: green;">&#41;</span> -&gt; F f a -&gt; F g a
transform tr <span style="color: green;">&#40;</span>F g x<span style="color: green;">&#41;</span> = F g <span style="color: green;">&#40;</span>tr x<span style="color: green;">&#41;</span>
&nbsp;
mu :: F <span style="color: green;">&#40;</span>F f<span style="color: green;">&#41;</span> a -&gt; F f a
mu <span style="color: green;">&#40;</span>F g <span style="color: green;">&#40;</span>F h x<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> = F <span style="color: green;">&#40;</span>g . h<span style="color: green;">&#41;</span> x
&nbsp;</pre>
<p>and <code>UC</code> is a <em>comonad</em>:</p>
<pre class="haskell">&nbsp;
epsilon :: C f a -&gt; f a
epsilon <span style="color: green;">&#40;</span>C e<span style="color: green;">&#41;</span> = e <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a>
&nbsp;
transform' :: <span style="color: green;">&#40;</span><span style="color: #06c; font-weight: bold;">forall</span> x. f x -&gt; g x<span style="color: green;">&#41;</span> -&gt; C f a -&gt; C g a
transform' tr <span style="color: green;">&#40;</span>C e<span style="color: green;">&#41;</span> = C <span style="color: green;">&#40;</span>tr . e<span style="color: green;">&#41;</span>
&nbsp;
delta :: C f a -&gt; C <span style="color: green;">&#40;</span>C f<span style="color: green;">&#41;</span> a
delta <span style="color: green;">&#40;</span>C e<span style="color: green;">&#41;</span> = C $ \h -&gt; C $ \g -&gt; e <span style="color: green;">&#40;</span>g . h<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>These are not the identity (co)monad, but this is the case where we have algebras and coalgebras that are equivalent. So, what are the (co)algebras? If we consider <code>UF</code> (and unpack the definitions somewhat):</p>
<pre class="haskell">&nbsp;
alg :: <span style="color: #06c; font-weight: bold;">forall</span> e. <span style="color: green;">&#40;</span>e -&gt; a, f e<span style="color: green;">&#41;</span> -&gt; f a
alg <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a>, x<span style="color: green;">&#41;</span> = x
alg <span style="color: green;">&#40;</span>g . h, x<span style="color: green;">&#41;</span> = alg <span style="color: green;">&#40;</span>g, alg <span style="color: green;">&#40;</span>h, x<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>and for <code>UC</code>:</p>
<pre class="haskell">&nbsp;
coalg :: f a -&gt; <span style="color: #06c; font-weight: bold;">forall</span> r. <span style="color: green;">&#40;</span>a -&gt; r<span style="color: green;">&#41;</span> -&gt; f r
coalg x <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a> = x
coalg x <span style="color: green;">&#40;</span>g . h<span style="color: green;">&#41;</span> = coalg <span style="color: green;">&#40;</span>coalg x h<span style="color: green;">&#41;</span> g
&nbsp;</pre>
<p>in other words, (co)algebra actions of these (co)monads are (mangled) <code>fmap</code> implementations, and the commutativity requirements are exactly what is required to be a law abiding instance. So the (co)algebras are exactly the <code>Functors</code>. <a href="#note1">[1]</a></p>
<p>There are, of course, many other examples of adjoint triples. And further, there are even adjoint quadruples, which in turn give rise to adjoint triples of (co)monads. Hopefully this has sparked some folks' interest in finding and studying more interesting examples.</p>
<p><a name="note0">[0]</a>: Another exmaple is <code>A × - ⊣ A -> -</code> where the <code>A</code> in question is a monoid. (Co)monad (co)algebras of these correspond to actions of the monoid on the carrier set.</p>
<p><a name="note1">[1]</a>: This shouldn't be too surprising, because having a category of (co)algebraic structures that is equivalent to the category of (co)algebras of the (co)monad that comes from the (co)free-forgetful adjunction is the basis for doing algebra in category theory (with (co)monads, at least). However, it is somewhat unusual for a forgetful functor to have both a left and right adjoint. In many cases, something is either algebraic or coalgebraic, and not both.</p>
<p><a name="note2">[2]</a>: Urs Schreiber informed me of an interesting interpretation of the <code>ConstΣ ⊣ ConstΠ</code> adjunction. If you are familiar with modal logic and the possible worlds semantics thereof, you can probably imagine that we could model it using something like <code>P : W -> Type</code>, where <code>W</code> is the type of possible worlds, and propositions are types. Then values of type <code>Σ P</code> demonstrate that <code>P</code> holds in particular worlds, while values of type <code>Π P</code> demonstrate that it holds in all worlds. <code>Const</code> turns these types back into world-indexed 'propositions,' so <code>ConstΣ</code> is the possibility modality and <code>ConstΠ</code> is the necessity modality.</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Tue 15 Sep 2015</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2015/some-rough-notes-on-univalent-foundations-and-b-systems-part-i/" rel="bookmark" title="Permanent Link: Some Rough Notes on Univalent Foundations and B-Systems, Part I">Some Rough Notes on Univalent Foundations and B-Systems, Part I</a></h2>
Posted by Gershom Bazerman under <a href="http://comonad.com/reader/category/homotopy-type-theory/" title="View all posts in Homotopy Type Theory" rel="category tag">Homotopy Type Theory</a> ,  <a href="http://comonad.com/reader/category/type-theory/" title="View all posts in Type Theory" rel="category tag">Type Theory</a> <br/><a href="http://comonad.com/reader/2015/some-rough-notes-on-univalent-foundations-and-b-systems-part-i/#comments" title="Comment on Some Rough Notes on Univalent Foundations and B-Systems, Part I">[423] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>I recently attended <a href="http://rdp15.mimuw.edu.pl/">RDP</a> in Warsaw, where there was quite a bit of work on Homotopy Type Theory, including a special workshop organized to present recent and ongoing work. The organizers of all the events did a fantastic job and there was a great deal of exciting work. I should add that I will not be able to go to RDP next year, as the two constituent central conferences (RTA — Rewriting Techniques and Applications and TLCA — Typed Lambda Calculus and Applications) have merged and changed names. Next year it will now be called FSCD — Formal Structures for Computation and Deduction. So I very much look forward to attending FSCD instead.</p>
<p>In any case, one of the invited speakers was Vladimir Voevodsky, who gave an invited talk on his recent work relating to univalent foundations titled "From Syntax to Semantics of Dependent Type Theories — Formalized”. This was a very clear talk that helped me understand his current research direction and the motivations for it. I also had the benefit of some very useful conversations with others involved in collaboration with some of this work, who patiently answered my questions. The notes below are complimentary to the <a href="http://hott-uf.gforge.inria.fr/HOTTUF_Vladimir.pdf">slides from his talk</a>.</p>
<p>I had sort of understood what the motivation for studying “C-Systems” was, but I had not taken it on myself to look at Voevodsky’s <a href="http://arxiv.org/abs/1410.5389">“B-Systems</a>” before, nor had I grasped how his research programme fit together. Since I found this experience enlightening, I figured I might as well write up what I think I understand, with all the usual caveats. Also note, in all the below, by “type theory” I invariably mean the intensional sort. So all the following is in reference to the B-systems paper that Voevodsky has posted on arXiv (<a href="http://arxiv.org/abs/1410.5389">arXiv:1410.5389</a>).</p>
<p>That said, if anything I describe here strikes you as funny, it is more likely that I am not describing things right than that the source material is troublesome — i.e. take this with a grain of salt. And bear in mind that I am not attempting to directly paraphrase Voevodsky himself or others I spoke to, but rather I am giving an account of where what they described resonated with me, and filtered through my own examples, etc. Also, if all of the “why and wherefore” is already familiar to you, feel free to skip directly to the “B-Systems” section where I will just discuss Voevodsky’s paper on this topic, and my attempts to understand portions of it. And if you already understand B-Systems, please do reply and explain all the things I’m sure I’m missing!</p>
<p> <a href="http://comonad.com/reader/2015/some-rough-notes-on-univalent-foundations-and-b-systems-part-i/#more-1105" class="more-link">(more...)</a></p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Wed 22 Jul 2015</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2015/on-the-unsafety-of-interleaved-io/" rel="bookmark" title="Permanent Link: On the unsafety of interleaved I/O">On the unsafety of interleaved I/O</a></h2>
Posted by Dan Doel under <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> <br/><a href="http://comonad.com/reader/2015/on-the-unsafety-of-interleaved-io/#comments" title="Comment on On the unsafety of interleaved I/O">[474] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>One area where I'm at odds with the prevailing winds in Haskell is lazy I/O. It's often said that lazy I/O is evil, scary and confusing, and it breaks things like referential transparency. Having a soft spot for it, and not liking most of the alternatives, I end up on the opposite side when the topic comes up, if I choose to pick the fight. I usually don't feel like I come away from such arguments having done much good at giving lazy I/O its justice. So, I thought perhaps it would be good to spell out my whole position, so that I can give the best defense I can give, and people can continue to ignore it, without costing me as much time in the future. :)</p>
<p>So, what's the argument that lazy I/O, or <code>unsafeInterleaveIO</code> on which it's based, breaks referential transparency? It usually looks something like this:</p>
<pre class="haskell">&nbsp;
swap <span style="color: green;">&#40;</span>x, y<span style="color: green;">&#41;</span> = <span style="color: green;">&#40;</span>y, x<span style="color: green;">&#41;</span>
&nbsp;
setup = <span style="color: #06c; font-weight: bold;">do</span>
  r1 &lt; - newIORef <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:True"><span style="font-weight: bold;">True</span></a>
  r2 &lt;- newIORef <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:True"><span style="font-weight: bold;">True</span></a>
  v1 &lt;- unsafeInterleaveIO $ <span style="color: #06c; font-weight: bold;">do</span> writeIORef r2 <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:False"><span style="font-weight: bold;">False</span></a> ; readIORef r1
  v2 &lt;- unsafeInterleaveIO $ <span style="color: #06c; font-weight: bold;">do</span> writeIORef r1 <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:False"><span style="font-weight: bold;">False</span></a> ; readIORef r2
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:return"><span style="font-weight: bold;">return</span></a> <span style="color: green;">&#40;</span>v1, v2<span style="color: green;">&#41;</span>
&nbsp;
main = <span style="color: #06c; font-weight: bold;">do</span>
  p1 &lt;- setup
  p2 &lt;- setup
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:print"><span style="font-weight: bold;">print</span></a> p1
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:print"><span style="font-weight: bold;">print</span></a> . swap $ p2
&nbsp;</pre>
<p>I ran this, and got:</p>
</pre>
<pre>
(True, False)
(True, False)
</pre>
<p>So this is supposed to demonstrate that the pure values depend on evaluation order, and we have broken a desirable property of Haskell.</p>
<p>First a digression. Personally I distinguish the terms, "referential transparency," and, "purity," and use them to identify two desirable properties of Haskell. The first I use for the property that allows you to factor your program by introducing (or eliminating) named subexpressions. So, instead of:</p>
<pre class="haskell">&nbsp;
f e e
&nbsp;</pre>
<p>we are free to write:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">let</span> x = e <span style="color: #06c; font-weight: bold;">in</span> f x x
&nbsp;</pre>
<p>or some variation. I have no argument for this meaning, other than it's what I thought it meant when I first heard the term used with respect to Haskell, it's a useful property, and it's the best name I can think of for the property. I also (of course) think it's better than some of the other explanations you'll find for what people mean when they say Haskell has referential transparency, since it doesn't mention functions or "values". It's just about equivalence of expressions.</p>
<p>Anyhow, for me, the above example is in no danger of violating referential transparency. There is no factoring operation that will change the meaning of the program. I can even factor out <code>setup</code> (or inline it, since it's already named):</p>
<pre class="haskell">&nbsp;
main = <span style="color: #06c; font-weight: bold;">let</span> m = setup
        <span style="color: #06c; font-weight: bold;">in</span> <span style="color: #06c; font-weight: bold;">do</span> p1 &lt; - m
              p2 &lt;- m
              <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:print"><span style="font-weight: bold;">print</span></a> p1
              <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:print"><span style="font-weight: bold;">print</span></a> . swap $ p2
&nbsp;</pre>
<p>This is the way in which <code>IO</code> preserves referential transparency, unlike side effects, in my view (note: the embedded language represented by <code>IO</code> does not have this property, since otherwise <code>p1</code> could be used in lieu of <code>p2</code>; this is why you shouldn't spend much time writing <code>IO</code> stuff, because it's a bad language embedded in a good one).</p>
<p>The other property, "purity," I pull from Amr Sabry's paper, <a href="http://www.cs.indiana.edu/~sabry/papers/purelyFunctional.ps">What is a Purely Functional Language?</a> There he argues that a functional language should be considered "pure" if it is an extension of the lambda calculus in which there are no contexts which observe differences in evaluation order. Effectively, evaluation order must only determine whether or not you get an answer, not change the answer you get.</p>
<p>This is slightly different from my definition of referential transparency earlier, but it's also a useful property to have. Referential transparency tells us that we can freely refactor, and purity tells us that we can change the order things are evaluated, both without changing the meaning of our programs.</p>
<p>Now, it would seem that the original interleaving example violates purity.  Depending on the order that the values are evaluated, opponents of lazy I/O say, the values change. However, this argument doesn't impress me, because I think the proper way to think about <code>unsafeInterleaveIO</code> is as concurrency, and in that case, it isn't very strange that the results of running it would be non-deterministic. And in that case, there's not much you can do to prove that the evaluation order is affecting results, and that you aren't simply very unlucky and always observing results that happen to correspond to evaluation order.</p>
<p>In fact, there's something I didn't tell you. I didn't use the <code>unsafeInterleaveIO</code> from base. I wrote my own. It looks like this:</p>
</pre>
<pre class="haskell">&nbsp;
unsafeInterleaveIO :: <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:IO"><span style="background-color: #efefbf; font-weight: bold;">IO</span></a> a -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:IO"><span style="background-color: #efefbf; font-weight: bold;">IO</span></a> a
unsafeInterleaveIO action = <span style="color: #06c; font-weight: bold;">do</span>
  iv &lt; - new
  forkIO $
    randomRIO <span style="color: green;">&#40;</span><span style="color: red;">1</span>,<span style="color: red;">5</span><span style="color: green;">&#41;</span> &gt;&gt;= threadDelay . <span style="color: green;">&#40;</span>*<span style="color: red;">1000</span><span style="color: green;">&#41;</span> &gt;&gt;
    action &gt;&gt;= write iv
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:return"><span style="font-weight: bold;">return</span></a> . <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:read"><span style="font-weight: bold;">read</span></a> $ iv
&nbsp;</pre>
<p><code>iv</code> is an <code>IVar</code> (I used <a href="https://hackage.haskell.org/package/ivar-simple">ivar-simple</a>). The pertinent operations on them are:</p>
<pre class="haskell">&nbsp;
new :: <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:IO"><span style="background-color: #efefbf; font-weight: bold;">IO</span></a> <span style="color: green;">&#40;</span>IVar a<span style="color: green;">&#41;</span>
write :: IVar a -&gt; a -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:IO"><span style="background-color: #efefbf; font-weight: bold;">IO</span></a> <span style="color: green;">&#40;</span><span style="color: green;">&#41;</span>
<a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:read"><span style="font-weight: bold;">read</span></a> :: IVar a -&gt; a
&nbsp;</pre>
<p><code>new</code> creates an empty <code>IVar</code>, and we can <code>write</code> to one only once; trying to write a second time will throw an exception. But this is no problem for me, because I obviously only attempt to write once. <code>read</code> will block until its argument is actually is set, and since that can only happen once, it is considered safe for <code>read</code> to not require <code>IO</code>. [1]</p>
<p>Using this and <code>forkIO</code>, one can easily write something like <code>unsafeInterleaveIO</code>, which accepts an <code>IO a</code> argument and yields an <code>IO a</code> whose result is guaranteed to be the result of running the argument at some time in the future. The only difference is that the real <code>unsafeInterleaveIO</code> schedules things just in time, whereas mine schedules them in a relatively random order (I'll admit I had to try a few times before I got the 'expected' lazy IO answer).</p>
<p>But, we could even take this to be the specification of interleaving. It runs <code>IO</code> actions concurrently, and you will be fine as long as you aren't attempting to depend on the exact scheduling order (or whether things get scheduled at all in some cases).</p>
<p>In fact, thinking of lazy I/O as concurrency turns most spooky examples into threading problems that I would expect most people to consider rather basic. For instance:</p>
<ul>
<li>Don't pass a handle to another thread and close it in the original.</li>
<li>Don't fork more file-reading threads than you have file descriptors.</li>
<li>Don't fork threads to handle files if you're concerned about the files being closed deterministically.</li>
<li>Don't read from the same handle in multiple threads (unless you don't care about each thread seeing a random subsequence of the stream).</li>
</ul>
<p>And of course, the original example in this article is just non-determinism introduced by concurrency, but not of a sort that requires fundamentally different explanation than fork. The main pitfall, in my biased opinion, is that the scheduling for interleaving is explained in a way that encourages people to try to guess exactly what it will do. But the presumption of purity (and the reordering GHC actually does based on it) actually means that you cannot assume that much more about the scheduling than you can about my scheduler, at least in general.</p>
<p>This isn't to suggest that lazy I/O is appropriate for every situation. Sometimes the above advice means that it is not appropriate to use concurrency. However, in my opinion, people are over eager to ban lazy I/O even for simple uses where it is the nicest solution, and justify it based on the 'evil' and 'confusing' ascriptions. But, personally, I don't think this is justified, unless one does the same for pretty much all concurrency.</p>
<p>I suppose the only (leading) question left to ask is which should be declared unsafe, fork or ivars, since together they allow you to construct a(n even less deterministic) <code>unsafeInterleaveIO</code>?</p>
<p>[1] Note that there are other implementations of <code>IVar</code>. I'd expect the most popular to be in <a href="https://hackage.haskell.org/package/monad-par">monad-par</a> by Simon Marlow. That allows one to construct an operation like <code>read</code>, but it is actually <em>less</em> deterministic in my construction, because it seems that it will not block unless perhaps you write and read within a single 'transaction,' so to speak.</p>
<p>In fact, this actually breaks referential transparency in conjunction with <code>forkIO</code>:</p>
<pre class="haskell">&nbsp;
deref = runPar . get
&nbsp;
randomDelay = randomRIO <span style="color: green;">&#40;</span><span style="color: red;">1</span>,<span style="color: red;">10</span><span style="color: green;">&#41;</span> &gt;&gt;= threadDelay . <span style="color: green;">&#40;</span><span style="color: red;">1000</span>*<span style="color: green;">&#41;</span>
&nbsp;
myHandle m = m `<a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:catch"><span style="font-weight: bold;">catch</span></a>` \<span style="color: green;">&#40;</span>_ :: SomeExpression<span style="color: green;">&#41;</span> -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:putStrLn"><span style="font-weight: bold;">putStrLn</span></a> <span style="color: #3c7331;">&quot;Bombed&quot;</span>
&nbsp;
mySpawn :: <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:IO"><span style="background-color: #efefbf; font-weight: bold;">IO</span></a> a -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:IO"><span style="background-color: #efefbf; font-weight: bold;">IO</span></a> <span style="color: green;">&#40;</span>IVar a<span style="color: green;">&#41;</span>
mySpawn action = <span style="color: #06c; font-weight: bold;">do</span>
  iv &lt; - runParIO new
  forkIO $ randomDelay &gt;&gt; action &gt;&gt;= runParIO . put_ iv
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:return"><span style="font-weight: bold;">return</span></a> iv
&nbsp;
main = <span style="color: #06c; font-weight: bold;">do</span>
  iv &lt; - mySpawn <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:return"><span style="font-weight: bold;">return</span></a> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:True"><span style="font-weight: bold;">True</span></a><span style="color: green;">&#41;</span>
  myHandle . <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:print"><span style="font-weight: bold;">print</span></a> $ deref iv
  randomDelay
  myHandle . <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:print"><span style="font-weight: bold;">print</span></a> $ deref iv
&nbsp;</pre>
<p>Sometimes this will print "Bombed" twice, and sometimes it will print "Bombed" followed by "True". The latter will never happen if we factor out the <code>deref iv</code> however. The blocking behavior is essential to <code>deref</code> maintaining referential transparency, and it seems like monad-par only blocks within a single <code>runPar</code>, not across multiples. Using ivar-simple in this example always results in "True" being printed twice.</p>
<p>It is also actually possible for <code>unsafeInterleaveIO</code> to break referential transparency if it is implemented incorrectly (or if the optimizer mucks with the internals in some bad way). But I haven't seen an example that couldn't be considered a bug in the implementation rather than some fundamental misbehavior. And my reference implementation here (with a suboptimal scheduler) suggests that there is no break that isn't just a bug.</pre>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Mon 25 May 2015</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2015/categories-of-structures-in-haskell/" rel="bookmark" title="Permanent Link: Categories of Structures in Haskell">Categories of Structures in Haskell</a></h2>
Posted by Dan Doel under <a href="http://comonad.com/reader/category/category-theory/" title="View all posts in Category Theory" rel="category tag">Category Theory</a> ,  <a href="http://comonad.com/reader/category/comonads/" title="View all posts in Comonads" rel="category tag">Comonads</a> ,  <a href="http://comonad.com/reader/category/data-structures/" title="View all posts in Data Structures" rel="category tag">Data Structures</a> ,  <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> ,  <a href="http://comonad.com/reader/category/kan-extensions/" title="View all posts in Kan Extensions" rel="category tag">Kan Extensions</a> ,  <a href="http://comonad.com/reader/category/mathematics/" title="View all posts in Mathematics" rel="category tag">Mathematics</a> ,  <a href="http://comonad.com/reader/category/monads/" title="View all posts in Monads" rel="category tag">Monads</a> ,  <a href="http://comonad.com/reader/category/type-hackery/" title="View all posts in Type Hackery" rel="category tag">Type Hackery</a> ,  <a href="http://comonad.com/reader/category/uncategorized/" title="View all posts in Uncategorized" rel="category tag">Uncategorized</a> <br/><a href="http://comonad.com/reader/2015/categories-of-structures-in-haskell/#comments" title="Comment on Categories of Structures in Haskell">[510] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>In the last couple posts I've used some 'free' constructions, and not remarked too much on how they arise. In this post, I'd like to explore them more. This is going to be something of a departure from the previous posts, though, since I'm not going to worry about thinking precisely about bottom/domains. This is more an exercise in applying some category theory to Haskell, "fast and loose".</p>
<p>(Advance note: for some continuous code to look at see <a href="http://code.haskell.org/~dolio/haskell-share/categories-of-structures/COS.hs">this file</a>.)</p>
<p>First, it'll help to talk about how some categories can work in Haskell. For any kind <code>k</code> made of <code>*</code> and <code>(->)</code>, [0] we can define a category of type constructors. Objects of the category will be first-class [1] types of that kind, and arrows will be defined by the following type family:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Transformer f g = Transform <span style="color: green;">&#123;</span> <span style="color: green;">&#40;</span>$$<span style="color: green;">&#41;</span> :: <span style="color: #06c; font-weight: bold;">forall</span> i. f i ~&gt; g i <span style="color: green;">&#125;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">type</span> family <span style="color: green;">&#40;</span>~&gt;<span style="color: green;">&#41;</span> :: k -&gt; k -&gt; * <span style="color: #06c; font-weight: bold;">where</span>
  <span style="color: green;">&#40;</span>~&gt;<span style="color: green;">&#41;</span> = <span style="color: green;">&#40;</span>-&gt;<span style="color: green;">&#41;</span>
  <span style="color: green;">&#40;</span>~&gt;<span style="color: green;">&#41;</span> = Transformer
&nbsp;
<span style="color: #06c; font-weight: bold;">type</span> a &lt; -&gt; b = <span style="color: green;">&#40;</span>a -&gt; b, b -&gt; a<span style="color: green;">&#41;</span>
<span style="color: #06c; font-weight: bold;">type</span> a &lt; ~&gt; b = <span style="color: green;">&#40;</span>a ~&gt; b, b ~&gt; a<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>So, for a base case, * has monomorphic functions as arrows, and categories for higher kinds have polymorphic functions that saturate the constructor:</p>
<pre class="haskell">&nbsp;
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Int"><span style="background-color: #efefbf; font-weight: bold;">Int</span></a> ~&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Char"><span style="background-color: #efefbf; font-weight: bold;">Char</span></a> = <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Int"><span style="background-color: #efefbf; font-weight: bold;">Int</span></a> -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Char"><span style="background-color: #efefbf; font-weight: bold;">Char</span></a>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Maybe"><span style="background-color: #efefbf; font-weight: bold;">Maybe</span></a> ~&gt; <span style="color: green;">&#91;</span><span style="color: green;">&#93;</span> = <span style="color: #06c; font-weight: bold;">forall</span> a. <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Maybe"><span style="background-color: #efefbf; font-weight: bold;">Maybe</span></a> a -&gt; <span style="color: green;">&#91;</span>a<span style="color: green;">&#93;</span>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Either"><span style="background-color: #efefbf; font-weight: bold;">Either</span></a> ~&gt; <span style="color: green;">&#40;</span>,<span style="color: green;">&#41;</span> = <span style="color: #06c; font-weight: bold;">forall</span> a b. <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Either"><span style="background-color: #efefbf; font-weight: bold;">Either</span></a> a b -&gt; <span style="color: green;">&#40;</span>a, b<span style="color: green;">&#41;</span>
  StateT ~&gt; ReaderT = <span style="color: #06c; font-weight: bold;">forall</span> s m a. StateT s m a -&gt; ReaderT s m a
&nbsp;</pre>
<p>We can of course define identity and composition for these, and it will be handy to do so:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">class</span> Morph <span style="color: green;">&#40;</span>p :: k -&gt; k -&gt; *<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a> :: p a a
  <span style="color: green;">&#40;</span>.<span style="color: green;">&#41;</span> :: p b c -&gt; p a b -&gt; p a c
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Morph <span style="color: green;">&#40;</span>-&gt;<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a> x = x
  <span style="color: green;">&#40;</span>g . f<span style="color: green;">&#41;</span> x = g <span style="color: green;">&#40;</span>f x<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Morph <span style="color: green;">&#40;</span><span style="color: green;">&#40;</span>~&gt;<span style="color: green;">&#41;</span> :: k -&gt; k -&gt; *<span style="color: green;">&#41;</span>
      =&gt; Morph <span style="color: green;">&#40;</span>Transformer :: <span style="color: green;">&#40;</span>i -&gt; k<span style="color: green;">&#41;</span> -&gt; <span style="color: green;">&#40;</span>i -&gt; k<span style="color: green;">&#41;</span> -&gt; *<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a> = Transform <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a>
  Transform f . Transform g = Transform $ f . g
&nbsp;</pre>
<p>These categories can be looked upon as the most basic substrates in Haskell. For instance, every type of kind <code>* -> *</code> is an object of the relevant category, even if it's a GADT or has other structure that prevents it from being nicely functorial.</p>
<p>The category for * is of course just the normal category of types and functions we usually call Hask, and it is fairly analogous to the category of sets. One common activity in category theory is to study categories of sets equipped with extra structure, and it turns out we can do this in Haskell, as well. And it even makes some sense to study categories of structures over any of these type categories.</p>
<p>When we equip our types with structure, we often use type classes, so that's how I'll do things here. Classes have a special status socially in that we expect people to only define instances that adhere to certain equational rules. This will take the place of equations that we are not able to state in the Haskell type system, because it doesn't have dependent types. So using classes will allow us to define more structures that we normally would, if only by convention.</p>
<p>So, if we have a kind <code>k</code>, then a corresponding structure will be <code>σ :: k -> Constraint</code>. We can then define the category <code>(k,σ)</code> as having objects <code>t :: k</code> such that there is an instance <code>σ t</code>. Arrows are then taken to be <code>f :: t ~> u</code> such that <code>f</code> "respects" the operations of <code>σ</code>.</p>
<p>As a simple example, we have:</p>
<pre class="haskell">&nbsp;
  k = *
  σ = Monoid :: * -&gt; Constraint
&nbsp;
  Sum <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Integer"><span style="background-color: #efefbf; font-weight: bold;">Integer</span></a>, Product <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Integer"><span style="background-color: #efefbf; font-weight: bold;">Integer</span></a>, <span style="color: green;">&#91;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Integer"><span style="background-color: #efefbf; font-weight: bold;">Integer</span></a><span style="color: green;">&#93;</span> :: <span style="color: green;">&#40;</span>*, Monoid<span style="color: green;">&#41;</span>
&nbsp;
  f :: <span style="color: green;">&#40;</span>Monoid m, Monoid n<span style="color: green;">&#41;</span> =&gt; m -&gt; n
    <span style="color: #06c; font-weight: bold;">if</span> f mempty = mempty
       f <span style="color: green;">&#40;</span>m &lt;&gt; n<span style="color: green;">&#41;</span> = f m &lt;&gt; f n
&nbsp;</pre>
<p>This is just the category of monoids in Haskell.</p>
<p>As a side note, we will sometimes be wanting to quantify over these "categories of structures". There isn't really a good way to package together a kind and a structure such that they work as a unit, but we can just add a constraint to the quantification. So, to quantify over all <code>Monoid</code>s, we'll use '<code>forall m. Monoid m => ...</code>'.</p>
<p>Now, once we have these categories of structures, there is an obvious forgetful functor back into the unadorned category. We can then look for free and cofree functors as adjoints to this. More symbolically:</p>
<pre class="haskell">&nbsp;
  Forget σ :: <span style="color: green;">&#40;</span>k,σ<span style="color: green;">&#41;</span> -&gt; k
  Free   σ :: k -&gt; <span style="color: green;">&#40;</span>k,σ<span style="color: green;">&#41;</span>
  Cofree σ :: k -&gt; <span style="color: green;">&#40;</span>k,σ<span style="color: green;">&#41;</span>
&nbsp;
  Free σ ⊣ Forget σ ⊣ Cofree σ
&nbsp;</pre>
<p>However, what would be nicer (for some purposes) than having to look for these is being able to construct them all systematically, without having to think much about the structure <code>σ</code>.</p>
<p>Category theory gives a hint at this, too, in the form of Kan extensions. In category terms they look like:</p>
<pre>
  p : C -> C'
  f : C -> D
  Ran p f : C' -> D
  Lan p f : C' -> D

  Ran p f c' = end (c : C). Hom_C'(c', p c) ⇒ f c
  Lan p f c' = coend (c : c). Hom_C'(p c, c') ⊗ f c
</pre>
<p>where <code>⇒</code> is a "power" and <code>⊗</code> is a copower, which are like being able to take exponentials and products by sets (or whatever the objects of the hom category are), instead of other objects within the category. Ends and coends are like universal and existential quantifiers (as are limits and colimits, but ends and coends involve mixed-variance).</p>
<p>Some handy theorems relate Kan extensions and adjoint functors:</p>
<pre>
  if L ⊣ R
  then L = Ran R Id and R = Lan L Id

  if Ran R Id exists and is absolute
  then Ran R Id ⊣ R

  if Lan L Id exists and is absolute
  then L ⊣ Lan L Id

  Kan P F is absolute iff forall G. (G . Kan P F) ~= Kan P (G . F)
</pre>
<p>It turns out we can write down Kan extensions fairly generally in Haskell. Our restricted case is:</p>
<pre class="haskell">&nbsp;
  p = Forget σ :: <span style="color: green;">&#40;</span>k,σ<span style="color: green;">&#41;</span> -&gt; k
  f = Id :: <span style="color: green;">&#40;</span>k,σ<span style="color: green;">&#41;</span> -&gt; <span style="color: green;">&#40;</span>k,σ<span style="color: green;">&#41;</span>
&nbsp;
  Free   σ = <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> <span style="color: green;">&#40;</span>Forget σ<span style="color: green;">&#41;</span> Id :: k -&gt; <span style="color: green;">&#40;</span>k,σ<span style="color: green;">&#41;</span>
  Cofree σ = <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Lan"><span style="background-color: #efefbf; font-weight: bold;">Lan</span></a> <span style="color: green;">&#40;</span>Forget σ<span style="color: green;">&#41;</span> Id :: k -&gt; <span style="color: green;">&#40;</span>k,σ<span style="color: green;">&#41;</span>
&nbsp;
  g :: <span style="color: green;">&#40;</span>k,σ<span style="color: green;">&#41;</span> -&gt; j
  g . Free   σ = <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> <span style="color: green;">&#40;</span>Forget σ<span style="color: green;">&#41;</span> g
  g . Cofree σ = <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Lan"><span style="background-color: #efefbf; font-weight: bold;">Lan</span></a> <span style="color: green;">&#40;</span>Forget σ<span style="color: green;">&#41;</span> g
&nbsp;</pre>
<p>As long as the final category is like one of our type constructor categories, ends are universal quantifiers, powers are function types, coends are existential quantifiers and copowers are product spaces. This only breaks down for our purposes when <code>g</code> is contravariant, in which case they are flipped.  For higher kinds, these constructions occur point-wise. So, we can break things down into four general cases, each with cases for each arity:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Ran0 σ p <span style="color: green;">&#40;</span>f :: k -&gt; *<span style="color: green;">&#41;</span> a =
  Ran0 <span style="color: green;">&#123;</span> ran0 :: <span style="color: #06c; font-weight: bold;">forall</span> r. σ r =&gt; <span style="color: green;">&#40;</span>a ~&gt; p r<span style="color: green;">&#41;</span> -&gt; f r <span style="color: green;">&#125;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Ran1 σ p <span style="color: green;">&#40;</span>f :: k -&gt; j -&gt; *<span style="color: green;">&#41;</span> a b =
  Ran1 <span style="color: green;">&#123;</span> ran1 :: <span style="color: #06c; font-weight: bold;">forall</span> r. σ r =&gt; <span style="color: green;">&#40;</span>a ~&gt; p r<span style="color: green;">&#41;</span> -&gt; f r b <span style="color: green;">&#125;</span>
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- ...</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> RanOp0 σ p <span style="color: green;">&#40;</span>f :: k -&gt; *<span style="color: green;">&#41;</span> a =
  <span style="color: #06c; font-weight: bold;">forall</span> e. σ e =&gt; RanOp0 <span style="color: green;">&#40;</span>a ~&gt; p e<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>f e<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- ...</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> Lan0 σ p <span style="color: green;">&#40;</span>f :: k -&gt; *<span style="color: green;">&#41;</span> a =
  <span style="color: #06c; font-weight: bold;">forall</span> e. σ e =&gt; Lan0 <span style="color: green;">&#40;</span>p e ~&gt; a<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>f e<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> Lan1 σ p <span style="color: green;">&#40;</span>f :: k -&gt; j -&gt; *<span style="color: green;">&#41;</span> a b =
  <span style="color: #06c; font-weight: bold;">forall</span> e. σ e =&gt; Lan1 <span style="color: green;">&#40;</span>p e ~&gt; a<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>f e b<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- ...</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> LanOp0 σ p <span style="color: green;">&#40;</span>f :: k -&gt; *<span style="color: green;">&#41;</span> a =
  LanOp0 <span style="color: green;">&#123;</span> lan0 :: <span style="color: #06c; font-weight: bold;">forall</span> r. σ r =&gt; <span style="color: green;">&#40;</span>p r -&gt; a<span style="color: green;">&#41;</span> -&gt; f r <span style="color: green;">&#125;</span>
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- ...</span>
&nbsp;</pre>
<p>The more specific proposed (co)free definitions are:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">type</span> family Free   :: <span style="color: green;">&#40;</span>k -&gt; Constraint<span style="color: green;">&#41;</span> -&gt; k -&gt; k
<span style="color: #06c; font-weight: bold;">type</span> family Cofree :: <span style="color: green;">&#40;</span>k -&gt; Constraint<span style="color: green;">&#41;</span> -&gt; k -&gt; k
&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Free0 σ a = Free0 <span style="color: green;">&#123;</span> gratis0 :: <span style="color: #06c; font-weight: bold;">forall</span> r. σ r =&gt; <span style="color: green;">&#40;</span>a ~&gt; r<span style="color: green;">&#41;</span> -&gt; r <span style="color: green;">&#125;</span>
<span style="color: #06c; font-weight: bold;">type</span> <span style="color: #06c; font-weight: bold;">instance</span> Free = Free0
&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Free1 σ f a = Free1 <span style="color: green;">&#123;</span> gratis1 :: <span style="color: #06c; font-weight: bold;">forall</span> g. σ g =&gt; <span style="color: green;">&#40;</span>f ~&gt; g<span style="color: green;">&#41;</span> -&gt; g a <span style="color: green;">&#125;</span>
<span style="color: #06c; font-weight: bold;">type</span> <span style="color: #06c; font-weight: bold;">instance</span> Free = Free1
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- ...</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> Cofree0 σ a = <span style="color: #06c; font-weight: bold;">forall</span> e. σ e =&gt; Cofree0 <span style="color: green;">&#40;</span>e ~&gt; a<span style="color: green;">&#41;</span> e
<span style="color: #06c; font-weight: bold;">type</span> <span style="color: #06c; font-weight: bold;">instance</span> Cofree = Cofree0
&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> Cofree1 σ f a = <span style="color: #06c; font-weight: bold;">forall</span> g. σ g =&gt; Cofree1 <span style="color: green;">&#40;</span>g ~&gt; f<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>g a<span style="color: green;">&#41;</span>
<span style="color: #06c; font-weight: bold;">type</span> <span style="color: #06c; font-weight: bold;">instance</span> Cofree = Cofree1
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- ...</span>
&nbsp;</pre>
<p>We can define some handly classes and instances for working with these types, several of which generalize existing Haskell concepts:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">class</span> Covariant <span style="color: green;">&#40;</span>f :: i -&gt; j<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  comap :: <span style="color: green;">&#40;</span>a ~&gt; b<span style="color: green;">&#41;</span> -&gt; <span style="color: green;">&#40;</span>f a ~&gt; f b<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">class</span> Contravariant f <span style="color: #06c; font-weight: bold;">where</span>
  contramap :: <span style="color: green;">&#40;</span>b ~&gt; a<span style="color: green;">&#41;</span> -&gt; <span style="color: green;">&#40;</span>f a ~&gt; f b<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">class</span> Covariant m =&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Monad"><span style="background-color: #efefbf; font-weight: bold;">Monad</span></a> <span style="color: green;">&#40;</span>m :: i -&gt; i<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  pure :: a ~&gt; m a
  join :: m <span style="color: green;">&#40;</span>m a<span style="color: green;">&#41;</span> ~&gt; m a
&nbsp;
<span style="color: #06c; font-weight: bold;">class</span> Covariant w =&gt; <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#t:Comonad"><span style="background-color: #efefbf; font-weight: bold;">Comonad</span></a> <span style="color: green;">&#40;</span>w :: i -&gt; i<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extract"><span style="font-weight: bold;">extract</span></a> :: w a ~&gt; a
  split :: w a ~&gt; w <span style="color: green;">&#40;</span>w a<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">class</span> Couniversal σ f | f -&gt; σ <span style="color: #06c; font-weight: bold;">where</span>
  couniversal :: σ r =&gt; <span style="color: green;">&#40;</span>a ~&gt; r<span style="color: green;">&#41;</span> -&gt; <span style="color: green;">&#40;</span>f a ~&gt; r<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">class</span> Universal σ f | f -&gt; σ <span style="color: #06c; font-weight: bold;">where</span>
  universal :: σ e =&gt; <span style="color: green;">&#40;</span>e ~&gt; a<span style="color: green;">&#41;</span> -&gt; <span style="color: green;">&#40;</span>e ~&gt; f a<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Covariant <span style="color: green;">&#40;</span>Free0 σ<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  comap f <span style="color: green;">&#40;</span>Free0 e<span style="color: green;">&#41;</span> = Free0 <span style="color: green;">&#40;</span>e . <span style="color: green;">&#40;</span>.f<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Monad"><span style="background-color: #efefbf; font-weight: bold;">Monad</span></a> <span style="color: green;">&#40;</span>Free0 σ<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  pure x = Free0 $ \k -&gt; k x
  join <span style="color: green;">&#40;</span>Free0 e<span style="color: green;">&#41;</span> = Free0 $ \k -&gt; e $ \<span style="color: green;">&#40;</span>Free0 e<span style="color: green;">&#41;</span> -&gt; e k
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Couniversal σ <span style="color: green;">&#40;</span>Free0 σ<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  couniversal h <span style="color: green;">&#40;</span>Free0 e<span style="color: green;">&#41;</span> = e h
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- ...</span>
&nbsp;</pre>
<p>The only unfamiliar classes here should be <code>(Co)Universal</code>. They are for witnessing the adjunctions that make <code>Free σ</code> the initial <code>σ</code> and <code>Cofree σ</code> the final <code>σ</code> in the relevant way. Only one direction is given, since the opposite is very easy to construct with the (co)monad structure.</p>
<p><code>Free σ</code> is a monad and couniversal, <code>Cofree σ</code> is a comonad and universal.</p>
<p>We can now try to convince ourselves that <code>Free σ</code> and <code>Cofree σ</code> are absolute Here are some examples:</p>
<pre class="haskell">&nbsp;
free0Absolute0 :: <span style="color: #06c; font-weight: bold;">forall</span> g σ a. <span style="color: green;">&#40;</span>Covariant g, σ <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
               =&gt; g <span style="color: green;">&#40;</span>Free0 σ a<span style="color: green;">&#41;</span> &lt; -&gt; <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> σ Forget g a
free0Absolute0 = <span style="color: green;">&#40;</span>l, r<span style="color: green;">&#41;</span>
 <span style="color: #06c; font-weight: bold;">where</span>
 l :: g <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span> -&gt; <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> σ Forget g a
 l g = Ran0 $ \k -&gt; comap <span style="color: green;">&#40;</span>couniversal $ remember0 . k<span style="color: green;">&#41;</span> g
&nbsp;
 r :: <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> σ Forget g a -&gt; g <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span>
 r <span style="color: green;">&#40;</span>Ran0 e<span style="color: green;">&#41;</span> = e $ Forget0 . pure
&nbsp;
free0Absolute1 :: <span style="color: #06c; font-weight: bold;">forall</span> <span style="color: green;">&#40;</span>g :: * -&gt; * -&gt; *<span style="color: green;">&#41;</span> σ a x. <span style="color: green;">&#40;</span>Covariant g, σ <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
               =&gt; g <span style="color: green;">&#40;</span>Free0 σ a<span style="color: green;">&#41;</span> x &lt; -&gt; <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> σ Forget g a x
free0Absolute1 = <span style="color: green;">&#40;</span>l, r<span style="color: green;">&#41;</span>
 <span style="color: #06c; font-weight: bold;">where</span>
 l :: g <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span> x -&gt; <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> σ Forget g a x
 l g = Ran1 $ \k -&gt; comap <span style="color: green;">&#40;</span>couniversal $ remember0 . k<span style="color: green;">&#41;</span> $$ g
&nbsp;
 r :: <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> σ Forget g a x -&gt; g <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span> x
 r <span style="color: green;">&#40;</span>Ran1 e<span style="color: green;">&#41;</span> = e $ Forget0 . pure
&nbsp;
free0Absolute0Op :: <span style="color: #06c; font-weight: bold;">forall</span> g σ a. <span style="color: green;">&#40;</span>Contravariant g, σ <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
                 =&gt; g <span style="color: green;">&#40;</span>Free0 σ a<span style="color: green;">&#41;</span> &lt; -&gt; RanOp σ Forget g a
free0Absolute0Op = <span style="color: green;">&#40;</span>l, r<span style="color: green;">&#41;</span>
 <span style="color: #06c; font-weight: bold;">where</span>
 l :: g <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span> -&gt; RanOp σ Forget g a
 l = RanOp0 $ Forget0 . pure
&nbsp;
 r :: RanOp σ Forget g a -&gt; g <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span>
 r <span style="color: green;">&#40;</span>RanOp0 h g<span style="color: green;">&#41;</span> = contramap <span style="color: green;">&#40;</span>couniversal $ remember0 . h<span style="color: green;">&#41;</span> g
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- ...</span>
&nbsp;</pre>
<p>As can be seen, the definitions share a lot of structure. I'm quite confident that with the right building blocks these could be defined once for each of the four types of Kan extensions, with types like:</p>
<pre class="haskell">&nbsp;
freeAbsolute
  :: <span style="color: #06c; font-weight: bold;">forall</span> g σ a. <span style="color: green;">&#40;</span>Covariant g, σ <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
  =&gt; g <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span> &lt; ~&gt; <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> σ Forget g a
&nbsp;
cofreeAbsolute
  :: <span style="color: #06c; font-weight: bold;">forall</span> g σ a. <span style="color: green;">&#40;</span>Covariant g, σ <span style="color: green;">&#40;</span>Cofree σ a<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
  =&gt; g <span style="color: green;">&#40;</span>Cofree σ a<span style="color: green;">&#41;</span> &lt; ~&gt; <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Lan"><span style="background-color: #efefbf; font-weight: bold;">Lan</span></a> σ Forget g a
&nbsp;
freeAbsoluteOp
  :: <span style="color: #06c; font-weight: bold;">forall</span> g σ a. <span style="color: green;">&#40;</span>Contravariant g, σ <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
  =&gt; g <span style="color: green;">&#40;</span>Free σ a<span style="color: green;">&#41;</span> &lt; ~&gt; RanOp σ Forget g a
&nbsp;
cofreeAbsoluteOp
  :: <span style="color: #06c; font-weight: bold;">forall</span> g σ a. <span style="color: green;">&#40;</span>Contravariant g, σ <span style="color: green;">&#40;</span>Cofree σ a<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
  =&gt; g <span style="color: green;">&#40;</span>Cofree σ a<span style="color: green;">&#41;</span> &lt; ~&gt; LanOp σ Forget g a
&nbsp;</pre>
<p>However, it seems quite difficult to structure things in a way such that GHC will accept the definitions. I've successfully written <code>freeAbsolute</code> using some axioms, but turning those axioms into class definitions and the like seems impossible.</p>
<p>Anyhow, the punchline is that we can prove absoluteness using only the premise that there is a valid <code>σ</code> instance for <code>Free σ</code> and <code>Cofree σ</code>. This tends to be quite easy; we just borrow the structure of the type we are quantifying over. This means that in all these cases, we are justified in saying that <code>Free σ ⊣ Forget σ ⊣ Cofree σ</code>, and we have a very generic presentations of (co)free structures in Haskell. So let's look at some.</p>
<p>We've already seen <code>Free Monoid</code>, and last time we talked about <code>Free Applicative</code>, and its relation to traversals. But, <code>Applicative</code> is to traversal as <code>Functor</code> is to lens, so it may be interesting to consider constructions on that. Both <code>Free Functor</code> and <code>Cofree Functor</code> make <code>Functor</code>s:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Free1 <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> f<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>Free1 e<span style="color: green;">&#41;</span> = Free1 $ <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f . e
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Cofree1 <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> f<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>Cofree1 h e<span style="color: green;">&#41;</span> = Cofree1 h <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f e<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>And of course, they are (co)monads, covariant functors and (co)universal among <code>Functor</code>s. But, it happens that I know some other types with these properties:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> CoYo f a = <span style="color: #06c; font-weight: bold;">forall</span> e. CoYo <span style="color: green;">&#40;</span>e -&gt; a<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>f e<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Covariant CoYo <span style="color: #06c; font-weight: bold;">where</span>
  comap f = Transform $ \<span style="color: green;">&#40;</span>CoYo h e<span style="color: green;">&#41;</span> -&gt; CoYo h <span style="color: green;">&#40;</span>f $$ e<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Monad"><span style="background-color: #efefbf; font-weight: bold;">Monad</span></a> CoYo <span style="color: #06c; font-weight: bold;">where</span>
  pure = Transform $ CoYo <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a>
  join = Transform $ \<span style="color: green;">&#40;</span>CoYo h <span style="color: green;">&#40;</span>CoYo h' e<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> -&gt; CoYo <span style="color: green;">&#40;</span>h . h'<span style="color: green;">&#41;</span> e
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>CoYo f<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>CoYo h e<span style="color: green;">&#41;</span> = CoYo <span style="color: green;">&#40;</span>f . h<span style="color: green;">&#41;</span> e
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Couniversal <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> CoYo <span style="color: #06c; font-weight: bold;">where</span>
  couniversal tr = Transform $ \<span style="color: green;">&#40;</span>CoYo h e<span style="color: green;">&#41;</span> -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> h <span style="color: green;">&#40;</span>tr $$ e<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Yo f a = Yo <span style="color: green;">&#123;</span> oy :: <span style="color: #06c; font-weight: bold;">forall</span> r. <span style="color: green;">&#40;</span>a -&gt; r<span style="color: green;">&#41;</span> -&gt; f r <span style="color: green;">&#125;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Covariant Yo <span style="color: #06c; font-weight: bold;">where</span>
  comap f = Transform $ \<span style="color: green;">&#40;</span>Yo e<span style="color: green;">&#41;</span> -&gt; Yo $ <span style="color: green;">&#40;</span>f $$<span style="color: green;">&#41;</span> . e
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#t:Comonad"><span style="background-color: #efefbf; font-weight: bold;">Comonad</span></a> Yo <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extract"><span style="font-weight: bold;">extract</span></a> = Transform $ \<span style="color: green;">&#40;</span>Yo e<span style="color: green;">&#41;</span> -&gt; e <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:id"><span style="font-weight: bold;">id</span></a>
  split = Transform $ \<span style="color: green;">&#40;</span>Yo e<span style="color: green;">&#41;</span> -&gt; Yo $ \k -&gt; Yo $ \k' -&gt; e $ k' . k
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Yo f<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>Yo e<span style="color: green;">&#41;</span> = Yo $ \k -&gt; e <span style="color: green;">&#40;</span>k . f<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Universal <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> Yo <span style="color: #06c; font-weight: bold;">where</span>
  universal tr = Transform $ \e -&gt; Yo $ \k -&gt; tr $$ <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> k e
&nbsp;</pre>
<p>These are the types involved in the (co-)Yoneda lemma. <code>CoYo</code> is a monad, couniversal among functors, and <code>CoYo f</code> is a <code>Functor</code>. <code>Yo</code> is a comonad, universal among functors, and is always a <code>Functor</code>. So, are these equivalent types?</p>
<pre class="haskell">&nbsp;
coyoIso :: CoYo &lt; ~&gt; Free <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a>
coyoIso = <span style="color: green;">&#40;</span>Transform $ couniversal pure, Transform $ couniversal pure<span style="color: green;">&#41;</span>
&nbsp;
yoIso :: Yo &lt; ~&gt; Cofree <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a>
yoIso = <span style="color: green;">&#40;</span>Transform $ universal <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extract"><span style="font-weight: bold;">extract</span></a>, Transform $ universal <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extract"><span style="font-weight: bold;">extract</span></a><span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>Indeed they are. And similar identities hold for the contravariant versions of these constructions.</p>
<p>I don't have much of a use for this last example. I suppose to be perfectly precise, I should point out that these uses of <code>(Co)Yo</code> are not actually part of the (co-)Yoneda lemma. They are two different constructions.  The (co-)Yoneda lemma can be given in terms of Kan extensions as:</p>
<pre class="haskell">&nbsp;
yoneda :: <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Ran"><span style="background-color: #efefbf; font-weight: bold;">Ran</span></a> Id f &lt; ~&gt; f
&nbsp;
coyoneda :: <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Functor-KanExtension.html#t:Lan"><span style="background-color: #efefbf; font-weight: bold;">Lan</span></a> Id f &lt; ~&gt; f
&nbsp;</pre>
<p>But, the use of <code>(Co)Yo</code> to make <code>Functor</code>s out of things that aren't necessarily is properly thought of in other terms. In short, we have some kind of category of Haskell types with only identity arrows---it is discrete. Then any type constructor, even non-functorial ones, is certainly a functor from said category (call it Haskrete) into the normal one (Hask). And there is an inclusion functor from Haskrete into Hask:</p>
<pre>
             F
 Haskrete -----> Hask
      |        /|
      |       /
      |      /
Incl  |     /
      |    /  Ran/Lan Incl F
      |   /
      |  /
      v /
    Hask
</pre>
<p>So, <code>(Co)Free Functor</code> can also be thought of in terms of these Kan extensions involving the discrete category.</p>
<p>To see more fleshed out, loadable versions of the code in this post, see <a href="http://code.haskell.org/~dolio/haskell-share/categories-of-structures/COS.hs">this file</a>. I may also try a similar Agda development at a later date, as it may admit the more general absoluteness constructions easier.</p>
<p>[0]: The reason for restricting ourselves to kinds involving only <code>*</code> and <code>(->)</code> is that they work much more simply than data kinds. Haskell values can't depend on type-level entities without using type classes. For *, this is natural, but for something like <code>Bool -> *</code>, it is more natural for transformations to be able to inspect the booleans, and so should be something more like <code>forall b. InspectBool b => f b -> g b</code>.</p>
<p>[1]: First-class types are what you get by removing type families and synonyms from consideration. The reason for doing so is that these can't be used properly as parameters and the like, except in cases where they reduce to some other type that is first-class. For example, if we define:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">type</span> I a = a
&nbsp;</pre>
<p>even though GHC will report <code>I :: * -> *</code>, it is not legal to write <code>Transform I I</code>.</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Wed 29 Apr 2015</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2015/domains-sets-traversals-and-applicatives/" rel="bookmark" title="Permanent Link: Domains, Sets, Traversals and Applicatives">Domains, Sets, Traversals and Applicatives</a></h2>
Posted by Dan Doel under <a href="http://comonad.com/reader/category/category-theory/" title="View all posts in Category Theory" rel="category tag">Category Theory</a> ,  <a href="http://comonad.com/reader/category/comonads/" title="View all posts in Comonads" rel="category tag">Comonads</a> ,  <a href="http://comonad.com/reader/category/data-structures/" title="View all posts in Data Structures" rel="category tag">Data Structures</a> ,  <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> ,  <a href="http://comonad.com/reader/category/mathematics/" title="View all posts in Mathematics" rel="category tag">Mathematics</a> ,  <a href="http://comonad.com/reader/category/monads/" title="View all posts in Monads" rel="category tag">Monads</a> <br/><a href="http://comonad.com/reader/2015/domains-sets-traversals-and-applicatives/#comments" title="Comment on Domains, Sets, Traversals and Applicatives">[70] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>Last time I looked at free monoids, and noticed that in Haskell lists don't really cut it. This is a consequence of laziness and general recursion. To model a language with those properties, one needs to use domains and monotone, continuous maps, rather than sets and total functions (a call-by-value language with general recursion would use domains and strict maps instead).</p>
<p>This time I'd like to talk about some other examples of this, and point out how doing so can (perhaps) resolve some disagreements that people have about the specific cases.</p>
<p>The first example is not one that I came up with: induction. It's sometimes said that Haskell does not have inductive types at all, or that we cannot reason about functions on its data types by induction. However, I think this is (techincally) inaccurate. What's true is that we cannot simply pretend that that our types are sets and use the induction principles for sets to reason about Haskell programs.  Instead, one has to figure out what inductive domains would be, and what their proof principles are.</p>
<p>Fortunately, there are some papers about doing this. The most recent (that I'm aware of) is <a href="http://arxiv.org/pdf/1206.0357.pdf">Generic Fibrational Induction</a>. I won't get too into the details, but it shows how one can talk about induction in a general setting, where one has a category that roughly corresponds to the type theory/programming language, and a second category of proofs that is 'indexed' by the first category's objects. Importantly, it is not required that the second category is somehow 'part of' the type theory being reasoned about, as is often the case with dependent types, although that is also a special case of their construction.</p>
<p>One of the results of the paper is that this framework can be used to talk about induction principles for types that don't make sense as sets. Specifically:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Hyp = Hyp <span style="color: green;">&#40;</span><span style="color: green;">&#40;</span>Hyp -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Int"><span style="background-color: #efefbf; font-weight: bold;">Int</span></a><span style="color: green;">&#41;</span> -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Int"><span style="background-color: #efefbf; font-weight: bold;">Int</span></a><span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>the type of "hyperfunctions". Instead of interpreting this type as a set, where it would effectively require a set that is isomorphic to the power set of its power set, they interpret it in the category of domains and strict functions mentioned earlier. They then construct the proof category in a similar way as one would for sets, except instead of talking about predicates as sub<i>sets</i>, we talk about sub-<i>domains</i> instead. Once this is done, their framework gives a notion of induction for this type.</p>
<p>This example is suitable for ML (and suchlike), due to the strict functions, and sort of breaks the idea that we can really get away with only thinking about sets, even there. Sets are good enough for some simple examples (like flat domains where we don't care about ⊥), but in general we have to generalize induction itself to apply to all types in the 'good' language.</p>
<p>While I haven't worked out how the generic induction would work out for Haskell, I have little doubt that it would, because ML actually contains all of Haskell's data types (and vice versa). So the fact that the framework gives meaning to induction for ML implies that it does so for Haskell. If one wants to know what induction for Haskell's 'lazy naturals' looks like, they can study the ML analogue of:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> LNat = Zero | Succ <span style="color: green;">&#40;</span><span style="color: green;">&#40;</span><span style="color: green;">&#41;</span> -&gt; LNat<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>because function spaces lift their codomain, and make things 'lazy'.</p>
<p>----</p>
<p>The other example I'd like to talk about hearkens back to the previous article.  I explained how <code>foldMap</code> is the proper fundamental method of the <code>Foldable</code> class, because it can be massaged to look like:</p>
<pre class="haskell">&nbsp;
foldMap :: Foldable f =&gt; f a -&gt; FreeMonoid a
&nbsp;</pre>
<p>and lists are not the free monoid, because they do not work properly for various infinite cases.</p>
<p>I also mentioned that <code>foldMap</code> looks a lot like <code>traverse</code>: </p>
<pre class="haskell">&nbsp;
foldMap  :: <span style="color: green;">&#40;</span>Foldable t   , Monoid m<span style="color: green;">&#41;</span>      =&gt; <span style="color: green;">&#40;</span>a -&gt; m<span style="color: green;">&#41;</span>   -&gt; t a -&gt; m
traverse :: <span style="color: green;">&#40;</span>Traversable t, Applicative f<span style="color: green;">&#41;</span> =&gt; <span style="color: green;">&#40;</span>a -&gt; f b<span style="color: green;">&#41;</span> -&gt; t a -&gt; f <span style="color: green;">&#40;</span>t b<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>And of course, we have <code>Monoid m => Applicative (Const m)</code>, and the functions are expected to agree in this way when applicable.</p>
<p>Now, people like to get in arguments about whether traversals are allowed to be infinite. I know Ed Kmett likes to argue that they can be, because he has lots of examples. But, not everyone agrees, and especially people who have papers proving things about traversals tend to side with the finite-only side. I've heard this includes one of the inventors of <code>Traversable</code>, Conor McBride.</p>
<p>In my opinion, the above disagreement is just another example of a situation where we have a generic notion instantiated in two different ways, and intuition about one does not quite transfer to the other. If you are working in a language like Agda or Coq (for proving), you will be thinking about traversals in the context of sets and total functions. And there, traversals are finite. But in Haskell, there are infinitary cases to consider, and they should work out all right when thinking about domains instead of sets. But I should probably put forward some argument for this position (and even if I don't need to, it leads somewhere else interesting).</p>
<p>One example that people like to give about finitary traversals is that they can be done via lists. Given a finite traversal, we can traverse to get the elements (using <code>Const [a]</code>), traverse the list, then put them back where we got them by traversing again (using <code>State [a]</code>). Usually when you see this, though, there's some subtle cheating in relying on the list to be exactly the right length for the second traversal. It will be, because we got it from a traversal of the same structure, but I would expect that proving the function is actually total to be a lot of work. Thus, I'll use this as an excuse to do my own cheating later.</p>
<p>Now, the above uses lists, but why are we using lists when we're in Haskell? We know they're deficient in certain ways. It turns out that we can give a lot of the same relevant structure to the better free monoid type:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> FM a = FM <span style="color: green;">&#40;</span><span style="color: #06c; font-weight: bold;">forall</span> m. Monoid m =&gt; <span style="color: green;">&#40;</span>a -&gt; m<span style="color: green;">&#41;</span> -&gt; m<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">deriving</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a><span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Applicative FM <span style="color: #06c; font-weight: bold;">where</span>
  pure x = FM <span style="color: green;">&#40;</span>$ x<span style="color: green;">&#41;</span>
  FM ef &lt; *&gt; FM ex = FM $ \k -&gt; ef $ \f -&gt; ex $ \x -&gt; k <span style="color: green;">&#40;</span>f x<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Monoid <span style="color: green;">&#40;</span>FM a<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  mempty = FM $ \_ -&gt; mempty
  mappend <span style="color: green;">&#40;</span>FM l<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>FM r<span style="color: green;">&#41;</span> = FM $ \k -&gt; l k &lt;&gt; r k
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Foldable FM <span style="color: #06c; font-weight: bold;">where</span>
  foldMap f <span style="color: green;">&#40;</span>FM e<span style="color: green;">&#41;</span> = e f
&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Ap f b = Ap <span style="color: green;">&#123;</span> unAp :: f b <span style="color: green;">&#125;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span>Applicative f, Monoid b<span style="color: green;">&#41;</span> =&gt; Monoid <span style="color: green;">&#40;</span>Ap f b<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  mempty = Ap $ pure mempty
  mappend <span style="color: green;">&#40;</span>Ap l<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>Ap r<span style="color: green;">&#41;</span> = Ap $ <span style="color: green;">&#40;</span>&lt;&gt;<span style="color: green;">&#41;</span> &lt; $&gt; l &lt; *&gt; r
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Traversable FM <span style="color: #06c; font-weight: bold;">where</span>
  traverse f <span style="color: green;">&#40;</span>FM e<span style="color: green;">&#41;</span> = unAp . e $ Ap . <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> pure . f
&nbsp;</pre>
<p>So, free monoids are <code>Monoids</code> (of course), <code>Foldable</code>, and even <code>Traversable</code>. At least, we can define something with the right type that wouldn't bother anyone if it were written in a total language with the right features, but in Haskell it happens to allow various infinite things that people don't like.</p>
<p>Now it's time to cheat. First, let's define a function that can take any <code>Traversable</code> to our free monoid:</p>
<pre class="haskell">&nbsp;
toFreeMonoid :: Traversable t =&gt; t a -&gt; FM a
toFreeMonoid f = FM $ \k -&gt; getConst $ traverse <span style="color: green;">&#40;</span>Const . k<span style="color: green;">&#41;</span> f
&nbsp;</pre>
<p>Now let's define a <code>Monoid</code> that's not a monoid:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> Cheat a = Empty | Single a | Append <span style="color: green;">&#40;</span>Cheat a<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>Cheat a<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Monoid <span style="color: green;">&#40;</span>Cheat a<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  mempty = Empty
  mappend = Append
&nbsp;</pre>
<p>You may recognize this as the data version of the free monoid from the previous article, where we get the real free monoid by taking a quotient. using this, we can define an <code>Applicative</code> that's not valid:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Cheating b a =
  Cheating <span style="color: green;">&#123;</span> prosper :: Cheat b -&gt; a <span style="color: green;">&#125;</span> <span style="color: #06c; font-weight: bold;">deriving</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a><span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Applicative <span style="color: green;">&#40;</span>Cheating b<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  pure x = Cheating $ \_ -&gt; x
&nbsp;
  Cheating f &lt; *&gt; Cheating x = Cheating $ \c -&gt; <span style="color: #06c; font-weight: bold;">case</span> c <span style="color: #06c; font-weight: bold;">of</span>
    Append l r -&gt; f l <span style="color: green;">&#40;</span>x r<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>Given these building blocks, we can define a function to relabel a traversable using a free monoid:</p>
<pre class="haskell">&nbsp;
relabel :: Traversable t =&gt; t a -&gt; FM b -&gt; t b
relabel t <span style="color: green;">&#40;</span>FM m<span style="color: green;">&#41;</span> = propser <span style="color: green;">&#40;</span>traverse <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:const"><span style="font-weight: bold;">const</span></a> hope<span style="color: green;">&#41;</span> t<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>m Single<span style="color: green;">&#41;</span>
 <span style="color: #06c; font-weight: bold;">where</span>
 hope = Cheating $ \c -&gt; <span style="color: #06c; font-weight: bold;">case</span> c <span style="color: #06c; font-weight: bold;">of</span>
   Single x -&gt; x
&nbsp;</pre>
<p>And we can implement any traversal by taking a trip through the free monoid:</p>
<pre class="haskell">&nbsp;
slowTraverse
  :: <span style="color: green;">&#40;</span>Applicative f, Traversable t<span style="color: green;">&#41;</span> =&gt; <span style="color: green;">&#40;</span>a -&gt; f b<span style="color: green;">&#41;</span> -&gt; t a -&gt; f <span style="color: green;">&#40;</span>t b<span style="color: green;">&#41;</span>
slowTraverse f t = <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> <span style="color: green;">&#40;</span>relabel t<span style="color: green;">&#41;</span> . traverse f . toFreeMonoid $ t
&nbsp;</pre>
<p>And since we got our free monoid via traversing, all the partiality I hid in the above won't blow up in practice, rather like the case with lists and finite traversals.</p>
<p>Arguably, this is worse cheating. It relies on the exact association structure to work out, rather than just number of elements. The reason is that for infinitary cases, you cannot flatten things out, and there's really no way to detect when you have something infinitary. The finitary traversals have the luxury of being able to reassociate everything to a canonical form, while the infinite cases force us to not do any reassociating at all. So this might be somewhat unsatisfying.</p>
<p>But, what if we didn't have to cheat at all? We can get the free monoid by tweaking <code>foldMap</code>, and it looks like <code>traverse</code>, so what happens if we do the same manipulation to the latter?</p>
<p>It turns out that lens has a type for this purpose, a slight specialization of which is:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Bazaar a b t =
  Bazaar <span style="color: green;">&#123;</span> runBazaar :: <span style="color: #06c; font-weight: bold;">forall</span> f. Applicative f =&gt; <span style="color: green;">&#40;</span>a -&gt; f b<span style="color: green;">&#41;</span> -&gt; f t <span style="color: green;">&#125;</span>
&nbsp;</pre>
<p>Using this type, we can reorder <code>traverse</code> to get:</p>
<pre class="haskell">&nbsp;
howBizarre :: Traversable t =&gt; t a -&gt; Bazaar a b <span style="color: green;">&#40;</span>t b<span style="color: green;">&#41;</span>
howBizarre t = Bazaar $ \k -&gt; traverse k t
&nbsp;</pre>
<p>But now, what do we do with this? And what even is it? [1]</p>
<p>If we continue drawing on intuition from <code>Foldable</code>, we know that <code>foldMap</code> is related to the free monoid. <code>Traversable</code> has more indexing, and instead of <code>Monoid</code> uses <code>Applicative</code>. But the latter are actually related to the former; <code>Applicative</code>s are monoidal (closed) functors. And it turns out, <code>Bazaar</code> has to do with free <code>Applicative</code>s.</p>
<p>If we want to construct free <code>Applicative</code>s, we can use our universal property encoding trick:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Free p f a =
  Free <span style="color: green;">&#123;</span> gratis :: <span style="color: #06c; font-weight: bold;">forall</span> g. p g =&gt; <span style="color: green;">&#40;</span><span style="color: #06c; font-weight: bold;">forall</span> x. f x -&gt; g x<span style="color: green;">&#41;</span> -&gt; g a <span style="color: green;">&#125;</span>
&nbsp;</pre>
<p>This is a higher-order version of the free <code>p</code>, where we parameterize over the constraint we want to use to represent structures. So <code>Free Applicative f</code> is the free <code>Applicative</code> over a type constructor <code>f</code>. I'll leave the instances as an exercise.</p>
<p>Since free monoid is a monad, we'd expect <code>Free p</code> to be a monad, too.  In this case, it is a McBride style indexed monad, as seen in <a href="https://personal.cis.strath.ac.uk/conor.mcbride/Kleisli.pdf">The Kleisli Arrows of Outrageous Fortune</a>.</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">type</span> f ~&gt; g = <span style="color: #06c; font-weight: bold;">forall</span> x. f x -&gt; g x
&nbsp;
embed :: f ~&gt; Free p f
embed fx = Free $ \k -&gt; k fx
&nbsp;
translate :: <span style="color: green;">&#40;</span>f ~&gt; g<span style="color: green;">&#41;</span> -&gt; Free p f ~&gt; Free p g
translate tr <span style="color: green;">&#40;</span>Free e<span style="color: green;">&#41;</span> = Free $ \k -&gt; e <span style="color: green;">&#40;</span>k . tr<span style="color: green;">&#41;</span>
&nbsp;
collapse :: Free p <span style="color: green;">&#40;</span>Free p f<span style="color: green;">&#41;</span> ~&gt; Free p f
collapse <span style="color: green;">&#40;</span>Free e<span style="color: green;">&#41;</span> = Free $ \k -&gt; e $ \<span style="color: green;">&#40;</span>Free e'<span style="color: green;">&#41;</span> -&gt; e' k
&nbsp;</pre>
<p>That paper explains how these are related to Atkey style indexed monads:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> At key i j <span style="color: #06c; font-weight: bold;">where</span>
  At :: key -&gt; At key i i
&nbsp;
<span style="color: #06c; font-weight: bold;">type</span> Atkey m i j a = m <span style="color: green;">&#40;</span>At a j<span style="color: green;">&#41;</span> i
&nbsp;
ireturn :: IMonad m =&gt; a -&gt; Atkey m i i a
ireturn = ...
&nbsp;
ibind :: IMonad m =&gt; Atkey m i j a -&gt; <span style="color: green;">&#40;</span>a -&gt; Atkey m j k b<span style="color: green;">&#41;</span> -&gt; Atkey m i k b
ibind = ...
&nbsp;</pre>
<p>It turns out, <code>Bazaar</code> is exactly the Atkey indexed monad derived from the <code>Free Applicative</code> indexed monad (with some arguments shuffled) [2]:</p>
<pre class="haskell">&nbsp;
hence :: Bazaar a b t -&gt; Atkey <span style="color: green;">&#40;</span>Free Applicative<span style="color: green;">&#41;</span> t b a
hence bz = Free $ \tr -&gt; runBazaar bz $ tr . At
&nbsp;
forth :: Atkey <span style="color: green;">&#40;</span>Free Applicative<span style="color: green;">&#41;</span> t b a -&gt; Bazaar a b t
forth fa = Bazaar $ \g -&gt; gratis fa $ \<span style="color: green;">&#40;</span>At a<span style="color: green;">&#41;</span> -&gt; g a
&nbsp;
imap :: <span style="color: green;">&#40;</span>a -&gt; b<span style="color: green;">&#41;</span> -&gt; Bazaar a i j -&gt; Bazaar b i j
imap f <span style="color: green;">&#40;</span>Bazaar e<span style="color: green;">&#41;</span> = Bazaar $ \k -&gt; e <span style="color: green;">&#40;</span>k . f<span style="color: green;">&#41;</span>
&nbsp;
ipure :: a -&gt; Bazaar a i i
ipure x = Bazaar <span style="color: green;">&#40;</span>$ x<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: green;">&#40;</span>&gt;&gt;&gt;=<span style="color: green;">&#41;</span> :: Bazaar a j i -&gt; <span style="color: green;">&#40;</span>a -&gt; Bazaar b k j<span style="color: green;">&#41;</span> -&gt; Bazaar b k i
Bazaar e &gt;&gt;&gt;= f = Bazaar $ \k -&gt; e $ \x -&gt; runBazaar <span style="color: green;">&#40;</span>f x<span style="color: green;">&#41;</span> k
&nbsp;
<span style="color: green;">&#40;</span>&gt;==&gt;<span style="color: green;">&#41;</span> :: <span style="color: green;">&#40;</span>s -&gt; Bazaar i o t<span style="color: green;">&#41;</span> -&gt; <span style="color: green;">&#40;</span>i -&gt; Bazaar a b o<span style="color: green;">&#41;</span> -&gt; s -&gt; Bazaar a b t
<span style="color: green;">&#40;</span>f &gt;==&gt; g<span style="color: green;">&#41;</span> x = f x &gt;&gt;&gt;= g
&nbsp;</pre>
<p>As an aside, <code>Bazaar</code> is also an (Atkey) indexed comonad, and the one that characterizes traversals, similar to how indexed store characterizes lenses. A <code>Lens s t a b</code> is equivalent to a coalgebra <code>s -> Store a b t</code>. A traversal is a similar <code>Bazaar</code> coalgebra:</p>
<pre class="haskell">&nbsp;
  s -&gt; Bazaar a b t
    ~
  s -&gt; <span style="color: #06c; font-weight: bold;">forall</span> f. Applicative f =&gt; <span style="color: green;">&#40;</span>a -&gt; f b<span style="color: green;">&#41;</span> -&gt; f t
    ~
  <span style="color: #06c; font-weight: bold;">forall</span> f. Applicative f =&gt; <span style="color: green;">&#40;</span>a -&gt; f b<span style="color: green;">&#41;</span> -&gt; s -&gt; f t
&nbsp;</pre>
<p>It so happens that Kleisli composition of the Atkey indexed monad above <code>(>==>)</code> is traversal composition.</p>
<p>Anyhow, <code>Bazaar</code> also inherits <code>Applicative</code> structure from <code>Free Applicative</code>:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Bazaar a b<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>Bazaar e<span style="color: green;">&#41;</span> = Bazaar $ \k -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>e k<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Applicative <span style="color: green;">&#40;</span>Bazaar a b<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  pure x = Bazaar $ \_ -&gt; pure x
  Bazaar ef &lt; *&gt; Bazaar ex = Bazaar $ \k -&gt; ef k &lt; *&gt; ex k
&nbsp;</pre>
<p>This is actually analogous to the <code>Monoid</code> instance for the free monoid; we just delegate to the underlying structure.</p>
<p>The more exciting thing is that we can fold and traverse over the first argument of <code>Bazaar</code>, just like we can with the free monoid:</p>
<pre class="haskell">&nbsp;
bfoldMap :: Monoid m =&gt; <span style="color: green;">&#40;</span>a -&gt; m<span style="color: green;">&#41;</span> -&gt; Bazaar a b t -&gt; m
bfoldMap f <span style="color: green;">&#40;</span>Bazaar e<span style="color: green;">&#41;</span> = getConst $ e <span style="color: green;">&#40;</span>Const . f<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Comp g f a = Comp <span style="color: green;">&#123;</span> getComp :: g <span style="color: green;">&#40;</span>f a<span style="color: green;">&#41;</span> <span style="color: green;">&#125;</span> <span style="color: #06c; font-weight: bold;">deriving</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a><span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span>Applicative f, Applicative g<span style="color: green;">&#41;</span> =&gt; Applicative <span style="color: green;">&#40;</span>Comp g f<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  pure = Comp . pure . pure
  Comp f &lt; *&gt; Comp x = Comp $ liftA2 <span style="color: green;">&#40;</span>&lt; *&gt;<span style="color: green;">&#41;</span> f x
&nbsp;
btraverse
  :: <span style="color: green;">&#40;</span>Applicative f<span style="color: green;">&#41;</span> =&gt; <span style="color: green;">&#40;</span>a -&gt; f a'<span style="color: green;">&#41;</span> -&gt; Bazaar a b t -&gt; Bazaar a' b t
btraverse f <span style="color: green;">&#40;</span>Bazaar e<span style="color: green;">&#41;</span> = getComp $ e <span style="color: green;">&#40;</span>c . <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> ipure . f<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>This is again analogous to the free monoid code. <code>Comp</code> is the analogue of <code>Ap</code>, and we use <code>ipure</code> in <code>traverse</code>. I mentioned that <code>Bazaar</code> is a comonad:</p>
<pre class="haskell">&nbsp;
<a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extract"><span style="font-weight: bold;">extract</span></a> :: Bazaar b b t -&gt; t
<a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extract"><span style="font-weight: bold;">extract</span></a> <span style="color: green;">&#40;</span>Bazaar e<span style="color: green;">&#41;</span> = runIdentity $ e Identity
&nbsp;</pre>
<p>And now we are finally prepared to not cheat:</p>
<pre class="haskell">&nbsp;
honestTraverse
  :: <span style="color: green;">&#40;</span>Applicative f, Traversable t<span style="color: green;">&#41;</span> =&gt; <span style="color: green;">&#40;</span>a -&gt; f b<span style="color: green;">&#41;</span> -&gt; t a -&gt; f <span style="color: green;">&#40;</span>t b<span style="color: green;">&#41;</span>
honestTraverse f = <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> <a href="http://comonad.com/haskell/category-extras/dist/doc/html/category-extras/Control-Comonad.html#v:extract"><span style="font-weight: bold;">extract</span></a> . btraverse f . howBizarre
&nbsp;</pre>
<p>So, we can traverse by first turning out <code>Traversable</code> into some structure that's kind of like the free monoid, except having to do with <code>Applicative</code>, traverse that, and then pull a result back out. <code>Bazaar</code> retains the information that we're eventually building back the same type of structure, so we don't need any cheating.</p>
<p>To pull this back around to domains, there's nothing about this code to object to if done in a total language. But, if we think about our free <code>Applicative</code>-ish structure, in Haskell, it will naturally allow infinitary expressions composed of the <code>Applicative</code> operations, just like the free monoid will allow infinitary monoid expressions. And this is okay, because <i>some</i> <code>Applicative</code>s can make sense of those, so throwing them away would make the type not free, in the same way that even finite lists are not the free monoid in Haskell. And this, I think, is compelling enough to say that infinite traversals are right for Haskell, just as they are wrong for Agda.</p>
<p>For those who wish to see executable code for all this, I've put a files <a href="http://code.haskell.org/~dolio/haskell-share/FMon.hs">here</a> and <a href="http://code.haskell.org/~dolio/haskell-share/Libre.hs">here</a>. The latter also contains some extra goodies at the end that I may talk about in further installments.</p>
<p>[1] Truth be told, I'm not exactly sure.</p>
<p>[2] It turns out, you can generalize <code>Bazaar</code> to have a correspondence for every choice of <code>p</code></p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Bizarre p a b t =
  Bizarre <span style="color: green;">&#123;</span> bizarre :: <span style="color: #06c; font-weight: bold;">forall</span> f. p f =&gt; <span style="color: green;">&#40;</span>a -&gt; f b<span style="color: green;">&#41;</span> -&gt; f t <span style="color: green;">&#125;</span>
&nbsp;</pre>
<p><code>hence</code> and <code>forth</code> above go through with the more general types. This can be seen <a href="http://code.haskell.org/~dolio/haskell-share/Libre.hs">here</a>.</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Sat 21 Feb 2015</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2015/free-monoids-in-haskell/" rel="bookmark" title="Permanent Link: Free Monoids in Haskell">Free Monoids in Haskell</a></h2>
Posted by Dan Doel under <a href="http://comonad.com/reader/category/category-theory/" title="View all posts in Category Theory" rel="category tag">Category Theory</a> ,  <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> ,  <a href="http://comonad.com/reader/category/mathematics/" title="View all posts in Mathematics" rel="category tag">Mathematics</a> <br/><a href="http://comonad.com/reader/2015/free-monoids-in-haskell/#comments" title="Comment on Free Monoids in Haskell">[52] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>It is often stated that <code>Foldable</code> is effectively the <code>toList</code> class. However, this turns out to be wrong. The real fundamental member of <code>Foldable</code> is <code>foldMap</code> (which should look suspiciously like <code>traverse</code>, incidentally). To understand exactly why this is, it helps to understand another surprising fact: lists are not free monoids in Haskell.</p>
<p>This latter fact can be seen relatively easily by considering another list-like type:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> SL a = Empty | SL a :&gt; a
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Monoid <span style="color: green;">&#40;</span>SL a<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  mempty = Empty
  mappend ys Empty = ys
  mappend ys <span style="color: green;">&#40;</span>xs :&gt; x<span style="color: green;">&#41;</span> = <span style="color: green;">&#40;</span>mappend ys xs<span style="color: green;">&#41;</span> :&gt; x
&nbsp;
single :: a -&gt; SL a
single x = Empty :&gt; x
&nbsp;</pre>
<p>So, we have a type <code>SL a</code> of snoc lists, which are a monoid, and a function that embeds <code>a</code> into <code>SL a</code>. If (ordinary) lists were the free monoid, there would be a unique monoid homomorphism from lists to snoc lists. Such a homomorphism (call it <code>h</code>) would have the following properties:</p>
<pre class="haskell">&nbsp;
h <span style="color: green;">&#91;</span><span style="color: green;">&#93;</span> = Empty
h <span style="color: green;">&#40;</span>xs &lt;&gt; ys<span style="color: green;">&#41;</span> = h xs &lt;&gt; h ys
h <span style="color: green;">&#91;</span>x<span style="color: green;">&#93;</span> = single x
&nbsp;</pre>
<p>And in fact, this (together with some general facts about Haskell functions) should be enough to define <code>h</code> for our purposes (or any purposes, really).  So, let's consider its behavior on two values:</p>
<pre class="haskell">&nbsp;
h <span style="color: green;">&#91;</span><span style="color: red;">1</span><span style="color: green;">&#93;</span> = single <span style="color: red;">1</span>
&nbsp;
h <span style="color: green;">&#91;</span><span style="color: red;">1</span>,<span style="color: red;">1</span>..<span style="color: green;">&#93;</span> = h <span style="color: green;">&#40;</span><span style="color: green;">&#91;</span><span style="color: red;">1</span><span style="color: green;">&#93;</span> &lt;&gt; <span style="color: green;">&#91;</span><span style="color: red;">1</span>,<span style="color: red;">1</span>..<span style="color: green;">&#93;</span><span style="color: green;">&#41;</span> <span style="color: #5d478b; font-style: italic;">-- [1,1..] is an infinite list of 1s</span>
          = h <span style="color: green;">&#91;</span><span style="color: red;">1</span><span style="color: green;">&#93;</span> &lt;&gt; h <span style="color: green;">&#91;</span><span style="color: red;">1</span>,<span style="color: red;">1</span>..<span style="color: green;">&#93;</span>
&nbsp;</pre>
<p>This second equation can tell us what the value of <code>h</code> is at this infinite value, since we can consider it the definition of a possibly infinite value:</p>
<pre class="haskell">&nbsp;
x = h <span style="color: green;">&#91;</span><span style="color: red;">1</span><span style="color: green;">&#93;</span> &lt;&gt; x = fix <span style="color: green;">&#40;</span>single <span style="color: red;">1</span> &lt;&gt;<span style="color: green;">&#41;</span>
h <span style="color: green;">&#91;</span><span style="color: red;">1</span>,<span style="color: red;">1</span>..<span style="color: green;">&#93;</span> = x
&nbsp;</pre>
<p><code>(single 1 <>)</code> is a strict function, so the fixed point theorem tells us that <code>x = ⊥</code>.</p>
<p>This is a problem, though. Considering some additional equations:</p>
<pre class="haskell">&nbsp;
<span style="color: green;">&#91;</span><span style="color: red;">1</span>,<span style="color: red;">1</span>..<span style="color: green;">&#93;</span> &lt;&gt; <span style="color: green;">&#91;</span>n<span style="color: green;">&#93;</span> = <span style="color: green;">&#91;</span><span style="color: red;">1</span>,<span style="color: red;">1</span>..<span style="color: green;">&#93;</span> <span style="color: #5d478b; font-style: italic;">-- true for all n</span>
h <span style="color: green;">&#91;</span><span style="color: red;">1</span>,<span style="color: red;">1</span>..<span style="color: green;">&#93;</span> = ⊥
h <span style="color: green;">&#40;</span><span style="color: green;">&#91;</span><span style="color: red;">1</span>,<span style="color: red;">1</span>..<span style="color: green;">&#93;</span> &lt;&gt; <span style="color: green;">&#91;</span><span style="color: red;">1</span><span style="color: green;">&#93;</span><span style="color: green;">&#41;</span> = h <span style="color: green;">&#91;</span><span style="color: red;">1</span>,<span style="color: red;">1</span>..<span style="color: green;">&#93;</span> &lt;&gt; h <span style="color: green;">&#91;</span><span style="color: red;">1</span><span style="color: green;">&#93;</span>
                   = ⊥ &lt;&gt; single <span style="color: red;">1</span>
                   = ⊥ :&gt; <span style="color: red;">1</span>
                   ≠ ⊥
&nbsp;</pre>
<p>So, our requirements for <code>h</code> are contradictory, and no such homomorphism can exist.</p>
<p>The issue is that Haskell types are domains. They contain these extra partially defined values and infinite values. The monoid structure on (cons) lists  has infinite lists absorbing all right-hand sides, while the snoc lists are just the opposite.  </p>
<p>This also means that finite lists (or any method of implementing finite sequences) are not free monoids in Haskell. They, as domains, still contain the additional bottom element, and it absorbs all other elements, which is incorrect behavior for the free monoid: </p>
<pre class="haskell">&nbsp;
pure x &lt;&gt; ⊥ = ⊥
h ⊥ = ⊥
h <span style="color: green;">&#40;</span>pure x &lt;&gt; ⊥<span style="color: green;">&#41;</span> = <span style="color: green;">&#91;</span>x<span style="color: green;">&#93;</span> &lt;&gt; h ⊥
                = <span style="color: green;">&#91;</span>x<span style="color: green;">&#93;</span> ++ ⊥
                = x:⊥
                ≠ ⊥
&nbsp;</pre>
<p>So, what is the free monoid? In a sense, it can't be written down at all in Haskell, because we cannot enforce value-level equations, and because we don't have quotients. But, if conventions are good enough, there is a way. First, suppose we have a free monoid type <code>FM a</code>. Then for any other monoid <code>m</code> and embedding <code>a -> m</code>, there must be a monoid homomorphism from <code>FM a</code> to <code>m</code>. We can model this as a Haskell type:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">forall</span> a m. Monoid m =&gt; <span style="color: green;">&#40;</span>a -&gt; m<span style="color: green;">&#41;</span> -&gt; FM a -&gt; m
&nbsp;</pre>
<p>Where we consider the <code>Monoid m</code> constraint to be enforcing that <code>m</code> actually has valid monoid structure. Now, a trick is to recognize that this sort of universal property can be used to <em>define</em> types in Haskell (or, GHC at least), due to polymorphic types being first class; we just rearrange the arguments and quantifiers, and take <code>FM a</code> to be the polymorphic type:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> FM a = FM <span style="color: green;">&#123;</span> unFM :: <span style="color: #06c; font-weight: bold;">forall</span> m. Monoid m =&gt; <span style="color: green;">&#40;</span>a -&gt; m<span style="color: green;">&#41;</span> -&gt; m <span style="color: green;">&#125;</span>
&nbsp;</pre>
<p>Types defined like this are automatically universal in the right sense. <a href="#footnote-1">[1]</a> The only thing we have to check  is that <code>FM a</code> is actually a monoid over <code>a</code>. But that turns out to be easily witnessed:</p>
<pre class="haskell">&nbsp;
embed :: a -&gt; FM a
embed x = FM $ \k -&gt; k x
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Monoid <span style="color: green;">&#40;</span>FM a<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
  mempty = FM $ \_ -&gt; mempty
  mappend <span style="color: green;">&#40;</span>FM e1<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>FM e2<span style="color: green;">&#41;</span> = FM $ \k -&gt; e1 k &lt;&gt; e2 k
&nbsp;</pre>
<p>Demonstrating that the above is a proper monoid delegates to instances of <code>Monoid</code> being proper monoids. So as long as we trust that convention, we have a free monoid.</p>
<p>However, one might wonder what a free monoid would look like as something closer to a traditional data type. To construct that, first ignore the required equations, and consider only the generators; we get:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">data</span> FMG a = None | Single a | FMG a :&lt;&gt; FMG a
&nbsp;</pre>
<p>Now, the proper <code>FM a</code> is the quotient of this by the equations:</p>
<pre class="haskell">&nbsp;
None :&lt;&gt; x = x = x :&lt;&gt; None
x :&lt;&gt; <span style="color: green;">&#40;</span>y :&lt;&gt; z<span style="color: green;">&#41;</span> = <span style="color: green;">&#40;</span>x :&lt;&gt; y<span style="color: green;">&#41;</span> :&lt;&gt; z
&nbsp;</pre>
<p>One way of mimicking this in Haskell is to hide the implementation in a module, and only allow elimination into <code>Monoid</code>s (again, using the convention that <code>Monoid</code> ensures actual monoid structure) using the function:</p>
<pre class="haskell">&nbsp;
unFMG :: <span style="color: #06c; font-weight: bold;">forall</span> a m. Monoid m =&gt; FMG a -&gt; <span style="color: green;">&#40;</span>a -&gt; m<span style="color: green;">&#41;</span> -&gt; m
unFMG None _ = mempty
unFMG <span style="color: green;">&#40;</span>Single x<span style="color: green;">&#41;</span> k = k x
unFMG <span style="color: green;">&#40;</span>x :&lt;&gt; y<span style="color: green;">&#41;</span> k = unFMG x k &lt;&gt; unFMG y k
&nbsp;</pre>
<p>This is actually how quotients can be thought of in richer languages; the quotient does not eliminate any of the generated structure internally, it just restricts the way in which the values can be consumed. Those richer languages just allow us to prove equations, and enforce properties by proof obligations, rather than conventions and structure hiding. Also, one should note that the above should look pretty similar to our encoding of <code>FM a</code> using universal quantification earlier.</p>
<p>Now, one might look at the above and have some objections. For one, we'd normally think that the quotient of the above type is just <code>[a]</code>. Second, it seems like the type is revealing something about the associativity of the operations, because defining recursive values via left nesting is different from right nesting, and this difference is observable by extracting into different monoids. But aren't monoids supposed to remove associativity as a concern? For instance:</p>
<pre class="haskell">&nbsp;
ones1 = embed <span style="color: red;">1</span> &lt;&gt; ones1
ones2 = ones2 &lt;&gt; embed <span style="color: red;">1</span>
&nbsp;</pre>
<p>Shouldn't we be able to prove these are the same, becuase of an argument like:</p>
<pre class="haskell">&nbsp;
ones1 = embed <span style="color: red;">1</span> &lt;&gt; <span style="color: green;">&#40;</span>embed <span style="color: red;">1</span> &lt;&gt; ...<span style="color: green;">&#41;</span>
      ... reassociate ...
      = <span style="color: green;">&#40;</span>... &lt;&gt; embed <span style="color: red;">1</span><span style="color: green;">&#41;</span> &lt;&gt; embed <span style="color: red;">1</span>
      = ones2
&nbsp;</pre>
<p>The answer is that the equation we have only specifies the behavior of associating three values:</p>
<pre class="haskell">&nbsp;
x &lt;&gt; <span style="color: green;">&#40;</span>y &lt;&gt; z<span style="color: green;">&#41;</span> = <span style="color: green;">&#40;</span>x &lt;&gt; y<span style="color: green;">&#41;</span> &lt;&gt; z
&nbsp;</pre>
<p>And while this is sufficient to nail down the behavior of <em>finite</em> values, and <em>finitary</em> reassociating, it does not tell us that <em>infinitary</em> reassociating yields the same value back. And the "... reassociate ..." step in the argument above was decidedly infinitary. And while the rules tell us that we can peel any finite number of copies of <code>embed 1</code> to the front of <code>ones1</code> or the end of <code>ones2</code>, it does not tell us that <code>ones1 = ones2</code>. And in fact it is vital for <code>FM a</code> to have distinct values for these two things; it is what makes it the free monoid when we're dealing with domains of lazy values.</p>
<p>Finally, we can come back to <code>Foldable</code>. If we look at <code>foldMap</code>:</p>
<pre class="haskell">&nbsp;
foldMap :: <span style="color: green;">&#40;</span>Foldable f, Monoid m<span style="color: green;">&#41;</span> =&gt; <span style="color: green;">&#40;</span>a -&gt; m<span style="color: green;">&#41;</span> -&gt; f a -&gt; m
&nbsp;</pre>
<p>we can rearrange things a bit, and get the type:</p>
<pre class="haskell">&nbsp;
Foldable f =&gt; f a -&gt; <span style="color: green;">&#40;</span><span style="color: #06c; font-weight: bold;">forall</span> m. Monoid m =&gt; <span style="color: green;">&#40;</span>a -&gt; m<span style="color: green;">&#41;</span> -&gt; m<span style="color: green;">&#41;</span>
&nbsp;</pre>
<p>And thus, the most fundamental operation of <code>Foldable</code> is not <code>toList</code>, but <code>toFreeMonoid</code>, and lists are not free monoids in Haskell.</p>
<p><a name="footnote-1">[1]</a>: What we are doing here is noting that (co)limits are objects that internalize natural transformations, but the natural transformations expressible by quantification in GHC are already automatically internalized using quantifiers. However, one has to be careful that the quantifiers are actually enforcing the relevant naturality conditions. In many simple cases they are.</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Tue 30 Dec 2014</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2014/fast-circular-substitution/" rel="bookmark" title="Permanent Link: Fast Circular Substitution">Fast Circular Substitution</a></h2>
Posted by Edward Kmett under <a href="http://comonad.com/reader/category/algorithms/" title="View all posts in Algorithms" rel="category tag">Algorithms</a> ,  <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> ,  <a href="http://comonad.com/reader/category/type-theory/" title="View all posts in Type Theory" rel="category tag">Type Theory</a> <br/><a href="http://comonad.com/reader/2014/fast-circular-substitution/#comments" title="Comment on Fast Circular Substitution">[48] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>Emil Axelsson and Koen Claessen wrote a functional pearl last year about <a href="http://www.cse.chalmers.se/~emax/documents/axelsson2013using.pdf">Using Circular Programs for Higher-Order Syntax</a>.</p>
<p>About 6 months ago I had an opportunity to play with this approach in earnest, and realized we can speed it up a great deal. This has kept coming up in conversation ever since, so I've decided to write up an article here.</p>
<p>In my <a href="http://hackage.haskell.org/package/bound">bound</a> library I exploit the fact that monads are about substitution to make a monad transformer that manages substitution for me.</p>
<p>Here I'm going to take a more coupled approach.</p>
<p>To have a type system with enough complexity to be worth examining, I'll adapt Dan Doel's <a href="http://hub.darcs.net/dolio/upts">UPTS</a>, which is a pure type system with universe polymorphism. I won't finish the implementation here, but from where we get it should be obvious how to finish the job.</p>
<p> <a href="http://comonad.com/reader/2014/fast-circular-substitution/#more-956" class="more-link">(more...)</a></p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Fri 1 Aug 2014</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2014/letter-to-a-young-haskell-enthusiast/" rel="bookmark" title="Permanent Link: Letter to a Young Haskell Enthusiast">Letter to a Young Haskell Enthusiast</a></h2>
Posted by Gershom Bazerman under <a href="http://comonad.com/reader/category/uncategorized/" title="View all posts in Uncategorized" rel="category tag">Uncategorized</a> <br/><a href="http://comonad.com/reader/2014/letter-to-a-young-haskell-enthusiast/#comments" title="Comment on Letter to a Young Haskell Enthusiast">[126] Comments</a>&nbsp;</div>
<div class="post-content">
	<p><em><small>The following letter is not about what "old hands" know and newcomers do not. Instead, it is about lessons that we all need to learn more than once, and remind ourselves of. It is about tendencies that are common, and understandable, and come with the flush of excitement of learning any new thing that we understand is important, and about the difficulty, always, in trying to decide how best to convey that excitement and sense of importance to others, in a way that they will listen. It is written more specifically, but only because I have found that if we don't talk specifics as well as generalities, the generalities make no sense. This holds for algebraic structures, and it holds for other, vaguer concepts no less. It is a letter full of things I want to remember, as well as of advice I want to share. I expect I will want to remind myself of it when I encounter somebody who is wrong on the internet, which, I understand, may occur on rare occasion.</small><br />
</em></p>
<p>You’ve recently entered the world of strongly typed functional programming, and you’ve decided it is great. You’ve written a program or two or a library or two, and you’re getting the hang of it. You hop on IRC and hear new words and ideas every day. There are always new concepts to learn, new libraries to explore, new ways to refactor your code, new typeclasses to make instances of.</p>
<p>Now, you’re a social person, and you want to go forth and share all the great things you’ve learned. And you have learned enough to distinguish some true statements from some false statements, and you want to go and slay all the false statements in the world.</p>
<p>Is this really what you want to do? Do you want to help people, do you want to teach people new wonderful things? Do you want to share the things that excite you? Or do you want to feel better about yourself, confirm that you are programming better, confirm that you are smarter and know more, reassure yourself that your adherence to a niche language is ok by striking out against the mainstream? Of course, you want to do the former. But a part of you probably secretly wants to do the latter, because in my experience that part is in all of us. It is our ego, and it drives us to great things, but it also can hold us back, make us act like jerks, and, worst of all, stand in the way of communicating with others about what we truly care about.</p>
<p>Haskell wasn’t built on great ideas, although it has those. It was built on a culture of how ideas are treated. It was not built on slaying others’ dragons, but on finding our own way; not tearing down rotten ideas (no matter how rotten) but showing by example how we didn’t need those ideas after all.</p>
<p>In functional programming, our proofs are not by contradiction, but by construction. If you want to teach functional programming, or preach functional programming, or just to even have productive discussions as we all build libraries and projects together, it will serve you well to learn that ethic.</p>
<p>You know better than the next developer, or so you think. This is because of something you have learned. So how do you help them want to learn it too? You do not tell them this is a language for smart people. You do not tell them you are smart because you use this language. You tell them that types are for fallible people, like we all are. They help us reason and catch our mistakes, because while software has grown more complex, we’re still stuck with the same old brains. If they tell you they don’t need types to catch errors, tell them that they must be much smarter than you, because you sure do. But even more, tell them that all the brainpower they use to <strong>not</strong> need types could turn into even greater, bigger, and more creative ideas if they let the compiler help them.</p>
<p>This is not a language for clever people, although there are clever things that can be done in this language. It is a language for simple things and clever things alike, and sometimes we want to be simple, and sometimes we want to be clever. But we don’t give bonus points for being clever. Sometimes, it’s just fun, like solving a crossword puzzle or playing a tricky Bach prelude, or learning a tango. We want to keep simple things simple so that tricky things are possible.</p>
<p>It is not a language that is “more mathematical” or “for math” or “about math”. Yes, in a deep formal sense, programming is math. But when someone objects to this, this is not because they are a dumb person, a bad person, or a malicious person. They object because they have had a bad notion of math foisted on them. “Math” is the thing that people wield over them to tell them they are not good enough, that they cannot learn things, that they don’t have the mindset for it. That’s a dirty lie. Math is not calculation — that’s what computers are for. Nor is math just abstract symbols. Nor is math a prerequisite for Haskell. If anything, Haskell might be what makes somebody find math interesting at all. Our equation should not be that math is hard, and so programming is hard. Rather, it should be that programming can be fun, and this means that math can be fun too. Some may object that programming is not only math, because it is engineering as well, and creativity, and practical tradeoffs. But, surprisingly, these are also elements of the practice of math, if not the textbooks we are given.</p>
<p>I have known great Haskell programmers, and even great computer scientists who know only a little linear algebra maybe, or never bothered to pick up category theory. You don’t <strong>need</strong> that stuff to be a great Haskell programmer. It <strong>might</strong> be one way. The only thing you need category theory for is to take great categorical and mathematical concepts from the world and import them back to programming, and translate them along the way so that others don’t need to make the same journey you did. And you don’t even need to do that, if you have patience, because somebody else will come along and do it for you, eventually.</p>
<p>The most important thing, though not hardest, about teaching and spreading knowledge is to emphasize that this is for <strong>everyone</strong>. Nobody is too young, too inexperienced, too old, too set in their ways, too excitable, insufficiently mathematical, etc. Believe in everyone, attack nobody, even the trolliest.<a href="#fn">*</a> Attacking somebody builds a culture of sniping and argumentativeness. It spreads to the second trolliest, and soforth, and then eventually to an innocent bystander who just says the wrong thing to spark bad memories of the last big argument.</p>
<p>The hardest thing, and the second most important, is to put aside your pride. If you want to teach people, you have to empathize with how they think, and also with how they feel. If your primary goal is to spread knowledge, then you must be relentlessly self-critical of anything you do or say that gets in the way of that. And you don’t get to judge that — others do. And you must just believe them. I told you this was hard. So if somebody finds you offputting, that’s your fault. If you say something and somebody is hurt or takes offense, it is not their fault for being upset, or feeling bad. This is not about what is abstractly hurtful  in a cosmic sense; it is about the fact that you have failed, concretely, to communicate as you desired. So accept the criticism, apologize for giving offense (not just for having upset someone but also for what you did to hurt them), and attempt to learn why they feel how they feel, for next time.</p>
<p>Note that if you have made somebody feel crummy, they may not be in a mood to explain why or how, because their opinion of you has already plummeted. So don’t declare that they must or should explain themselves to you, although you may politely ask. Remember that knowledge does not stand above human behavior. Often, you don't need to know exactly why a person feels the way they do, only that they do, so you can respect that. If you find yourself demanding explanations, ask yourself, if you knew this thing, would that change your behavior? How? If not, then learn to let it go.</p>
<p>Remember also that they were put off by your actions, not by your existence. It is easy to miss this distinction and react defensively. "Fight-or-flight" stands in the way of clear thinking and your ability to empathize; try taking a breath and maybe a walk until the adrenaline isn't derailing your true intentions.</p>
<p>Will this leave you satisfied? That depends. If your goal is to understand everything and have everybody agree with regards to everything that is in some sense objectively true, it will not. If your goal is to have the widest, nicest, most diverse, and most fun Haskell community possible, and to interact in an atmosphere of mutual respect and consideration, then it is the only thing that will leave you satisfied.</p>
<p>If you make even the most modest (to your mind) mistake, be it in social interaction or technical detail, be quick to apologize and retract, and do so freely. What is there to lose? Only your pride. Who keeps track? Only you. What is there to gain? Integrity, and ultimately that integrity will feel far more fulfilling than the cheap passing thrills of cutting somebody else down or deflecting their concerns.</p>
<p>Sometimes it may be, for whatever reason, that somebody doesn’t want to talk to you, because at some point your conversation turned into an argument. Maybe they did it, maybe you did it, maybe you did it together. It doesn’t matter, learn to walk away. Learn from the experience how to communicate better, how to avoid that pattern, how to always be the more positive, more friendly, more forward-looking. Take satisfaction in the effort in that. Don’t talk about them behind their back, because that will only fuel your own bad impulses. Instead, think about how you can change.</p>
<p>Your self-esteem doesn’t need your help. You may feel you need to prove yourself, but you don't. Other people, in general, have better things to do with their time than judge you, even when you may sometimes feel otherwise. You know you’re talented, that you have learned things, and built things, and that this will be recognized in time. Nobody else wants to hear it from you, and the more they hear it, the less they will believe it, and the more it will distract from what you <strong>really</strong> want, which is not to feed your ego, not to <strong>be</strong> great, but to <strong>accomplish</strong> something great, or even just to find others to <strong>share</strong> something great with. In fact, if anyone's self-esteem should be cared for, it is that of the people you are talking to. The more confident they are in their capacity and their worth, the more willing they will be to learn new things, and to acknowledge that their knowledge, like all of ours, is limited and partial. You must believe in yourself to be willing to learn new things, and if you want to cultivate more learners, you must cultivate that self-belief in others.</p>
<p>Knowledge is not imposing. Knowledge is fun. Anyone, given time and inclination, can acquire it. Don’t only lecture, but continue to learn, because there is always much more than you know. (And if there wasn’t, wow, that would be depressing, because what would there be to learn next?) Learn to value all opinions, because they all come from experiences, and all those experiences have something to teach us. Dynamic typing advocates have brought us great leaps in JIT techniques. If you’re interested in certain numerical optimizations, you need to turn to work pioneered in C++ or Fortran. Like you, I would rather write in Haskell. But it is not just the <strong>tools</strong> that matter but the <strong>ideas</strong>, and you will find they come from everywhere.</p>
<p>In fact, we have so much to learn that we direct our learning by setting up barriers — declaring certain tools, fields, languages, or communities not worth our time. This isn’t because they have nothing to offer, but it is a crutch for us to shortcut evaluating too many options all at once. It is fine, and in fact necessary, to narrow the scope of your knowledge to increase its depth. But be glad that others are charting other paths! Who knows what they will bring back from those explorations.</p>
<p>If somebody is chatting about programming on the internet, they’re already ahead of the pack, already interested in craft and knowledge. You may not share their opinions, but you have things to learn from one another, always. Maybe the time and place aren’t right to share ideas and go over disputes. That’s ok. There will be another time and place, or maybe there won’t be. There is a big internet full of people, and you don’t need to be everybody’s friend or everybody’s mentor. You should just avoid being anybody’s enemy, because your time and theirs is too precious to waste it on hard feelings instead of learning new cool stuff.</p>
<p>This advice is not a one-time proposition. Every time we learn something new and want to share it, we face these issues all over again -- the desire to proclaim, to overturn received wisdom all at once -- and the worse the received wisdom, the more vehemently we want to strike out. But if we are generous listeners and attentive teachers, we not only teach better and spread more knowledge, but also learn more, and enjoy ourselves more in the process. To paraphrase Rilke’s “Letter to a Young Poet”: Knowledge is good if it has sprung from necessity. In this nature of its origin lies the judgement of it: there is no other.</p>
<p><em><small>Thanks to the various folks in and around the Haskell world who have helped me refine this article. I don't name you only because I don't want to imply your endorsement, or give what is still, at base, a very personal take, any particular sort of imprimatur of a broader group of people, all of whom I suspect will disagree among themselves and with me about various specifics.</small></em></p>
<p><em><small><a name="fn"></a><b>*:</b> It has been pointed out to me that this advice is not universal. Clearly there are some things that deserve more pointed responses. Bigotry, outright harassment and poisonous behavior, etc. So please read this paragraph only as it applies to talking about technical issues, not as regards to many other things, where there are people <a href="http://modelviewculture.com/">better equipped than me</a> to give advice.</small></em></p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Sun 20 Apr 2014</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2014/cufp-cfp/" rel="bookmark" title="Permanent Link: CUFP 2014 Call For Presentations">CUFP 2014 Call For Presentations</a></h2>
Posted by Edward Kmett under <a href="http://comonad.com/reader/category/conferences/cufp/" title="View all posts in CUFP" rel="category tag">CUFP</a> ,  <a href="http://comonad.com/reader/category/call-for-presentations/" title="View all posts in Call For Presentations" rel="category tag">Call For Presentations</a> ,  <a href="http://comonad.com/reader/category/conferences/" title="View all posts in Conferences" rel="category tag">Conferences</a> ,  <a href="http://comonad.com/reader/category/meta/" title="View all posts in Meta" rel="category tag">Meta</a> <br/><a href="http://comonad.com/reader/2014/cufp-cfp/#comments" title="Comment on CUFP 2014 Call For Presentations">[461] Comments</a>&nbsp;</div>
<div class="post-content">
	<p><center><br />
<strong>Workshop for<br />
Commercial Users of Functional Programming 2014<br />
Sponsored by SIGPLAN<br />
[CUFP 2014](http://cufp.org/conference)<br />
Co-located with <a href="http://icfpconference.org/icfp2014">ICFP 2014</a><br />
Gothenburg, Sweden<br />
Sep 4-6<br />
Talk Proposal Submission Deadline: 27 June 2014<br /></strong><br />
<a href="http://goo.gl/5BJLul">CUFP 2014 Presentation Submission Form</a><br />
</center></p>
<p> <a href="http://comonad.com/reader/2014/cufp-cfp/#more-923" class="more-link">(more...)</a></p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Thu 2 May 2013</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2013/representing-applicatives/" rel="bookmark" title="Permanent Link: Representing Applicatives">Representing Applicatives</a></h2>
Posted by Gershom Bazerman under <a href="http://comonad.com/reader/category/uncategorized/" title="View all posts in Uncategorized" rel="category tag">Uncategorized</a> <br/><a href="http://comonad.com/reader/2013/representing-applicatives/#comments" title="Comment on Representing Applicatives">[313] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>In the <a href="http://comonad.com/reader/2012/abstracting-with-applicatives/">previous</a> <a href="http://comonad.com/reader/2013/algebras-of-applicatives/">two</a> posts, we've built up a whole range of applicatives, out of Const, Identity, Reader, Compose, Product, Sum, and Fix (and some higher-order analogues). Sum has given us the most trouble, but in some sense has been the most powerful, letting us write things like possibly eventually terminating lists, or trees, or in fact any sort of structure with branching alternatives. In this post, I want to think a bit more about why it is that Sum is the trickiest of the bunch, and more generally, what we can say about when two applicative structures are the "same". In the process of doing so, we'll invent something a lot like Traversable en passant.</p>
<p>Let's do some counting exercises. <code>Product Identity Identity</code> holds exactly two things. It is therefore isomorphic to <code>((->) Bool)</code>, or if we prefer, <code>((->) Either () ())</code>. That is to say that a pair that <i>holds</i> two values of type <code>a</code> is the same as a function that <i>takes a two-valued type</i> and <i>yields</i> a value of type <code>a</code>. A product of more functors in turn is isomorphic to the reader of the sum of each of the datatypes that "represent" them. E.g. <code>Product (Product Identity Identity) (Product (Const ()) Identity)</code> is iso to <code>((->) (Either (Either () ()) ())</code>, i.e. a data type with three possible inhabitants. In making this move we took Product to Either -- multiplication to sum. We can pull a similar trick with Compose. <code>Compose (Product Identity Identity) (Product Identity Identity)</code> goes to ((->) (Either () (),Either () ())). So again we took Product to a sum type, but now we took Compose to a pair -- a product type! The intuition is that composition <i>multiplies</i> the possibilities of spaces in each nested functor.</p>
<p>Hmm.. products go to sums, composition goes to multiplication, etc. This should remind us of something -- these rules are exactly the rules for working with exponentials. x^n * x^m = x^(n + m). (x^n)^m = x^(n*m). x^0 = 1, x^1 = x.</p>
<p>Seen from the right standpoint, this isn't surprising at all, but almost inevitable. The functors we're describing are known as "representable," a term which derives from category theory. (See appendix on representable functors below).</p>
<p>In Haskell-land, a "representable functor" is just any functor isomorphic to the reader functor <code>((->) a)</code> for some appropriate a. Now if we think back to our algebraic representations of data types, we call the arrow type constructor an exponential. We can "count" <code>a -> x</code> as x^a, since e.g. there are 3^2 distinct functions that inhabit the type 2 -> 3. The intuition for this is that for each input we pick one of the possible results, so as the number of inputs goes up by one, the number of functions goes up by multiplying through by the set of possible results. 1 -> 3 = 3, 2 -> 3 = 3 * 3, (n + 1) -> 3 = 3 * (n -> 3).</p>
<p>Hence, if we "represent" our functors by exponentials, then we can work with them directly as exponentials as well, with all the usual rules. Edward Kmett has a <a href="http://hackage.haskell.org/packages/archive/representable-functors/3.0.0.1/doc/html/Data-Functor-Representable.html">library encoding representable functors in Haskell</a>.</p>
<p>Meanwhile, Peter Hancock prefers to call such functors <a href="http://sneezy.cs.nott.ac.uk/containers/blog/?p=14">"Naperian"</a> after John Napier, inventor of the logarithm (See also <a href="http://stackoverflow.com/a/13100857/371753">here</a>). Why Naperian? Because if our functors are isomorphic to exponentials, then we can take their logs! And that brings us back to the initial discussion of type mathematics. We have some functor F, and claim that it is isomorphic to -^R for some concrete data type R. Well, this means that R is the logarithm of F. E.g. <code>(R -> a, S -> a) =~ Either R S -> a</code>, which is to say that if log F = R and log G =~ S, then log (F * G) = log F + log G. Similarly, for any other data type n, again with log F = R, we have  <code>n -> F a =~ n -> R -> a =~ (n * R) -> a</code>, which is to say that log (F^n) =~ n * log F.</p>
<p>This gives us one intuition for why the sum functor is not generally representable -- it is very difficult to decompose log (F + G) into some simpler compound expression of logs.</p>
<p>So what functors are Representable? Anything that can be seen as a fixed shape with some index. Pairs, fixed-size vectors, fixed-size matrices, any nesting of fixed vectors and matricies. But also infinite structures of regular shape! However, not things whose shape can vary -- not lists, not sums. Trees of fixed depth or infinite binary trees therefore, but not trees of arbitrary depth or with ragged structure, etc.</p>
<p>Representable functors turn out to be extremely powerful tools. Once we know a functor is representable, we know exactly what its applicative instance must be, and that its applicative instance will be "zippy" -- i.e. acting pointwise across the structure. We also know that it has a monad instance! And, unfortunately, that this monad instance is typically fairly useless (in that it is also "zippy" -- i.e. the monad instance on a pair just acts on the two elements pointwise, without ever allowing anything in the first slot to affect anything in the second slot, etc.). But we know more than that. We know that a representable functor, by virtue of being a reader in disguise, cannot have effects that migrate outwards. So any two actions in a representable functor are commutative. And more than that, they are entirely independent.</p>
<p>This means that all representable functors are "<a href="http://hackage.haskell.org/packages/archive/distributive/0.3.1/doc/html/Data-Distributive.html">distributive</a>"! Given any functor f, and any data type r, then we have </p>
<pre class="haskell">&nbsp;
distributeReader :: <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> f =&gt; f <span style="color: green;">&#40;</span>r -&gt; a<span style="color: green;">&#41;</span> -&gt; <span style="color: green;">&#40;</span>r -&gt; f a<span style="color: green;">&#41;</span>
distributeReader fra = \r -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> <span style="color: green;">&#40;</span>$r<span style="color: green;">&#41;</span> fra
&nbsp;</pre>
<p>That is to say, given an arrow "inside" a functor, we can always pull the arrow out, and "distribute" application across the contents of the functor. A list of functions from <code>Int -> Int</code> becomes a single function from <code>Int</code> to a list of <code>Int</code>, etc. More generally, since all representable functors are isomorphic to reader, given g representable, and f any functor, then we have: <code>distribute :: (Functor f, Representable g) => f (g a) -> g (f a).</code></p>
<p>This is pretty powerful sauce! And if f and g are <i>both</i> representable, then we get the transposition isomorphism, witnessed by <code>flip</code>! That's just the beginning of the good stuff. If we take functions and "unrepresent" them back to functors (i.e. take their logs), then we can do things like move from <code>((->) Bool)</code> to pairs, etc. Since we're in a pervasively lazy language, we've just created a library for <a href="http://hackage.haskell.org/packages/archive/representable-tries/3.0.2/doc/html/Data-Functor-Representable-Trie.html">memoization</a>! This is because we've gone from a function to a data structure we can index into, representing each possible argument to this function as a "slot" in the structure. And the laziness pays off because we only need to evaluate the contents of each slot on demand (otherwise we'd have a precomputed lookup table rather than a dynamically-evaluated memo table). </p>
<p>And now suppose we take our representable functor in the form <code>s -> a</code> and paired it with an "index" into that function, in the form of a concrete <code>s</code>. Then we'd be able to step that <code>s</code> forward or backwards and navigate around our structure of <code>a</code>s. And this is precisely the <a href="http://hackage.haskell.org/packages/archive/comonads-fd/3.0.1/doc/html/Control-Comonad-Store.html">Store Comonad</a>! And this in turn gives a <a href="http://patternsinfp.wordpress.com/2011/01/31/lenses-are-the-coalgebras-for-the-costate-comonad/">characterization of the lens laws</a>.</p>
<p>What this all gives us a tiny taste of, in fact, is the tremendous power of the <a href="http://blog.sigfpe.com/2006/11/yoneda-lemma.html">Yoneda lemma</a>, which, in Haskell, is all about going between values and functions, and in fact captures the important universality and uniqueness properties that make working with representable functors tractable. A further tiny taste of Yoneda comes from a nice <a href="http://conal.net/blog/posts/memoizing-polymorphic-functions-via-unmemoization">blog post</a> by Conal Elliott on memoization.</p>
<p><strong>Extra Credit on Sum Functors</strong></p>
<p>There in fact is a log identity on sums. It goes like this:</p>
<pre>
log(a + c) = log a + log (1 + c/a)
</pre>
<p>Do you have a useful computational interpretation of this? I've got the inklings of one, but not much else.</p>
<p><strong>Appendix: Notes on Representable Functors in Hask.</strong></p>
<p>The way to think about this is to take some arbitrary category C, and some category that's basically Set (in our case, Hask. In fact, in our case, C is Hask too, and we're just talking about endofunctors on Hask). Now, we take some functor F : C -> Set, and some A which is an element of C. The set of morphisms originating at A (denoted by Hom(A,-)) constitutes a functor called the "hom functor." For any object X in C, we can "plug it in" to Hom(A,-), to then get the set of all arrows from A to X. And for any morphism X -> Y in C, we can derive a morphism from Hom(A,X) to Hom(A,Y), by composition. This is equivalent to, in Haskell-land, using a function <code>f :: x -> y</code> to send <code>g :: a -> x</code> to <code>a -> y</code> by writing "functionAToY = f . g".</p>
<p>So, for any A in C, we have a hom functor on C, which is C -> Set, where the elements of the resultant Set are homomorphisms in C. Now, we have this other arbitrary functor F, which is also C -> Set. Now, if there is an isomorphism of functors between F, and Hom(A,_), then we say F is "representable". A representable functor is thus one that can be worked with entirely as an appropriate hom-functor.</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Mon 1 Apr 2013</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2013/japanese-workshop-1/" rel="bookmark" title="Permanent Link: Japanese &#8220;ekmett&#8221; Workshop (Part 1 of 2)">Japanese &#8220;ekmett&#8221; Workshop (Part 1 of 2)</a></h2>
Posted by Edward Kmett under <a href="http://comonad.com/reader/category/haskell/japan/" title="View all posts in Japan" rel="category tag">Japan</a> ,  <a href="http://comonad.com/reader/category/lenses/" title="View all posts in Lenses" rel="category tag">Lenses</a> ,  <a href="http://comonad.com/reader/category/mathematics/" title="View all posts in Mathematics" rel="category tag">Mathematics</a> <br/><a href="http://comonad.com/reader/2013/japanese-workshop-1/#comments" title="Comment on Japanese &#8220;ekmett&#8221; Workshop (Part 1 of 2)">[95] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>A couple of weeks back one of my coworkers brought to my attention <a href="http://partake.in/events/1698f7f8-4151-4048-b317-03a8c3f1a7ab">a several hour long workshop in Japan</a> to go over and describe a number of my libraries, hosted by <a href="https://github.com/tanakh">TANAKA Hideyuki</a> — not the <a href="http://en.wikipedia.org/wiki/Hideyuki_Tanaka">voice actor</a>, I checked!</p>
<p>I was incredibly honored and I figured that if that many people (they had 30 or so registered attendees and 10 presentations) were going to spend that much time going over software that I had written, I should at least offer to show up!</p>
<p>I'd like to apologize for any errors in the romanization of people's names or misunderstandings I may have in the following text. My grasp of Japanese is very poor! Please feel free to send me corrections or additions!</p>
<h2>Surprise!</h2>
<p>Sadly, my <a href="https://twitter.com/mcscottmc">boss</a>'s immediate reaction to hearing that there was a workshop in Japan about my work was to quip that "You're saying you're <a href="http://en.wikipedia.org/wiki/Big_in_Japan_(phrase)">huge in Japan</a>?" With him conspicuously not offering to fly me out here, I had to settle for surprising the organizers and attending via Google Hangout.</p>
<h2>Commentary and Logs</h2>
<p><a href="http://twitter.com/nushio">@nushio</a> was very helpful in getting me connected, and while the speakers gave their talks I sat on the irc.freenode.net #haskell-lens channel and Google Hangout and answered questions and provided a running commentary with more details and references. Per <a href="http://freenode.net/channel_guidelines.shtml">freenode policy</a> the fact that we were logging the channel was announced -- well, at least before things got too far underway.</p>
<p><a href="https://gist.github.com/ekmett/5283253">Here is the IRC session log as a gist</a>. IKEGAMI Daisuke <a href="https://twitter.com/ikegami__">@ikegami__</a> (<code>ikeg</code> in the IRC log) tried to keep up a high-level running commentary about what was happening in the video to the log, which may be helpful if you are trying to follow along through each retroactively.</p>
<p>Other background chatter and material is strewn across twitter under the <a href="https://twitter.com/search?q=%23ekmett_conf&src=typd">#ekmett_conf</a> hash tag and on a japanese twitter aggregator named <a href="http://togetter.com/li/480399">togetter</a></p>
<p> <a href="http://comonad.com/reader/2013/japanese-workshop-1/#more-831" class="more-link">(more...)</a></p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Fri 11 Jan 2013</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2013/algebras-of-applicatives/" rel="bookmark" title="Permanent Link: Algebras of Applicatives">Algebras of Applicatives</a></h2>
Posted by Gershom Bazerman under <a href="http://comonad.com/reader/category/uncategorized/" title="View all posts in Uncategorized" rel="category tag">Uncategorized</a> <br/><a href="http://comonad.com/reader/2013/algebras-of-applicatives/#comments" title="Comment on Algebras of Applicatives">[458] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>While the <a href="http://comonad.com/reader/2012/abstracting-with-applicatives">previous post</a> in this series was relatively immediately applicable, this one has constructions I definitely wouldn't recommend in production code. However, they do take us further in exploring the universe of applicative functors, and, more broadly, exploring which data types provide which properties by construcion.</p>
<p>It's well known that if you have any Functor <code>F a</code>, you can take its "fixpoint", creating a structure of infinitely nested Fs, like so. <code>F (F (F (...) ) )</code> Since we can't have infinite types directly in Haskell, we introduce the Fix newtype:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Fix f = Fix <span style="color: green;">&#40;</span>f <span style="color: green;">&#40;</span>Fix f<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span></pre>
<p>This "wraps up" the recursion so that GHC accepts the type. <code>Fix f</code> is a <code>Fix</code> constructor, containing an "f" of <code>Fix f</code> inside. Each in turn expands out, and soforth. Fixpoints of functors have fixedpoints of functors inside 'em. And so on, and so on, ad infinitum.</p>
<p>(Digression: We speak of "algebraic data types" in Haskell. The "algebra" in question is an "F-algebra", and we can build up structures with fixpoints of functors, taking those functors as initial or terminal objects and generating either initial algebras or terminal coalgebras. These latter two concepts coincide in Haskell in the Fix description given above, as greatest and least fixpoints of data types in Haskell turn out to be the same thing. For more background, one can go to Wadler's "<a href="http://homepages.inf.ed.ac.uk/wadler/papers/free-rectypes/free-rectypes.txt">Recursive Types for Free</a>,"  or Jacobs and Rutten's "<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.1418">Tutorial on (Co)Algebras and (Co)Induction</a>" for starters.)</p>
<p>The family of functors built from our friends Const, Sum, Product, and Reader (exponentiation) are known as Polynomial Functors. If we take closure of these with a proper fixpoint construct (that lets us build infinite structures), we get things that are variously known as Containers, Shapely Types, and Strictly Positive types.</p>
<p>One irritating thing is that the fixpoint of a functor as we've written it is no longer itself a functor. The type constructor Fix is of kind <code>(* -> *) -> *</code>, which says it takes an "f" which takes one argument (e.g. "Maybe" or "Identity" or etc.) and returns a proper type (i.e. a value at the type level of kind *).</p>
<p>We want a fixpoint construction that gives back something of kind <code>* -> *</code> — i.e. something that is a type constructor representing a functor, and not just a plain old type. The following does the trick.</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> FixF f a = FixF <span style="color: green;">&#40;</span>f <span style="color: green;">&#40;</span>FixF f<span style="color: green;">&#41;</span> a<span style="color: green;">&#41;</span>
<span style="color: #06c; font-weight: bold;">deriving</span> <span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a> <span style="color: green;">&#40;</span>f <span style="color: green;">&#40;</span>FixF f<span style="color: green;">&#41;</span> a<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> =&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a> <span style="color: green;">&#40;</span>FixF f a<span style="color: green;">&#41;</span></pre>
<p>(I learned about FixF from <a href="http://www.cs.ox.ac.uk/ralf.hinze/SSGIP10/AdjointFolds.pdf">a paper by Ralf Hinze</a>, but I'm sure the origins go back much further).</p>
<p>FixF is of kind <code>((* -> *) -> * -> *) -> * -> *</code>. It takes the fixpoint of a "second-order Functor" (a Functor that sends a Functor to another Functor, i.e. an endofunctor on the functor category of hask), to recover a standard "first order Functor" back out. This sounds scary, but it isn't once you load it up in ghci and start playing with it. In fact, we've encountered second order functors just recently. Product, Sum, and Compose are all of kind <code>(* -> *) -> (* -> *) -> * -> *</code>. So they all send two functors to a third functor. That means that <code>Product Const</code>, <code>Sum Identity</code> and <code>Compose Maybe</code> are all second-order functors, and things appropriate to take our "second-order fixpoint" of.</p>
<p>Conceptually, "Fix f" took a value with one hole, and we filled that hole with "Fix f" so there was no room for a type parameter. Now we've got an "f" with two holes, the first of which takes a functor, and the second of which is the hole of the resulting functor.</p>
<p>Unlike boring old "Fix", we can write Functor and Applicative instances for "FixF", and they're about as simple and compositional as we could possibly hope.</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>f <span style="color: green;">&#40;</span>FixF f<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> =&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>FixF f<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>FixF x<span style="color: green;">&#41;</span> = FixF $ <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f x
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Applicative <span style="color: green;">&#40;</span>f <span style="color: green;">&#40;</span>FixF f<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> =&gt; Applicative <span style="color: green;">&#40;</span>FixF f<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    pure x = FixF $ pure x
    <span style="color: green;">&#40;</span>FixF f<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>FixF x<span style="color: green;">&#41;</span> = FixF <span style="color: green;">&#40;</span>f &lt; *&gt; x<span style="color: green;">&#41;</span></pre>
<p>But now we run into a new problem! It seems like this "a" parameter is just hanging out there, doing basically nothing. We take our classic functors and embed them in there, and they still only have "one hole" at the value level, so don't actually have any place to put the "a" type we now introduced. For example, we can write the following:</p>
<pre class="haskell"><span style="color: #5d478b; font-style: italic;">-- FixF . Compose . Just . FixF . Compose $ Nothing</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; FixF (Compose (Just (FixF (Compose Nothing))))</span>
<span style="color: #5d478b; font-style: italic;">-- :t FixF (Compose (Just (FixF (Compose Nothing))))</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; FixF (Compose Maybe) a</span></pre>
<p>We now introduce one new member of our basic constructions — a second order functor that acts like "const" on the type level, taking any functor and returning Identity.</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Embed <span style="color: green;">&#40;</span>f :: * -&gt; *<span style="color: green;">&#41;</span> a = Embed a <span style="color: #06c; font-weight: bold;">deriving</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a><span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Embed f<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>Embed x<span style="color: green;">&#41;</span> = Embed $ f x
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Applicative <span style="color: green;">&#40;</span>Embed f<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    pure x = Embed x
    <span style="color: green;">&#40;</span>Embed f<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>Embed x<span style="color: green;">&#41;</span> = Embed <span style="color: green;">&#40;</span>f x<span style="color: green;">&#41;</span></pre>
<p>Now we can actually stick functorial values into our fixpoints:</p>
<pre class="haskell"><span style="color: #5d478b; font-style: italic;">-- FixF $ Embed &quot;hi&quot;</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; FixF (Embed &quot;hi&quot;)</span>
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- fmap (++ &quot; world&quot;) $ FixF (Embed &quot;hi&quot;)</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; FixF (Embed &quot;hi world&quot;)</span>
&nbsp;
<span style="color: #5d478b; font-style: italic;">-- FixF . Product (Embed &quot;hi&quot;) .</span>
<span style="color: #5d478b; font-style: italic;">--        FixF . Product (Embed &quot;there&quot;) . FixF $ undefined</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; FixF (Product (Embed &quot;hi&quot;)</span>
<span style="color: #5d478b; font-style: italic;">--   (FixF (Product (Embed &quot;there&quot;)</span>
<span style="color: #5d478b; font-style: italic;">--   (FixF *** Exception: Prelude.undefined</span></pre>
<p>You may have noticed that we seem to be able to use "product" to begin a chain of nested fixpoints, but we don't seem able to stick a "Maybe" in there to <strong>stop</strong> the chain. And it seems like we're not even "fixing" where we intend to be:</p>
<pre class="haskell"><span style="color: #5d478b; font-style: italic;">-- :t FixF . Product (Embed &quot;hi&quot;) . FixF . Product (Embed &quot;there&quot;) . FixF $ undefined</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; FixF (Product (Embed f)) [Char]</span></pre>
<p>That's because we're applying Product, takes and yields arguments of kind <code>* -> *</code> in a context where we really want to take and yield second-order functors as arguments — things of kind <code>(* -> *) -> * -> *</code>. If we had proper kind polymorphism, "Product" and "ProductF" would be able to collapse (and maybe, soon, they will). But at least in the ghc 7.4.1 that I'm working with, we have to write the same darn thing, but "up a kind".</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">data</span> ProductF f g <span style="color: green;">&#40;</span>b :: * -&gt; *<span style="color: green;">&#41;</span> a =
      ProductF <span style="color: green;">&#40;</span>f b a<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>g b a<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">deriving</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>f b<span style="color: green;">&#41;</span>, <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>g b<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> =&gt;
         <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>ProductF f g b<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
                <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>ProductF x y<span style="color: green;">&#41;</span> = ProductF <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f x<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f y<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span>Applicative <span style="color: green;">&#40;</span>f b<span style="color: green;">&#41;</span>, Applicative <span style="color: green;">&#40;</span>g b<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> =&gt;
         Applicative <span style="color: green;">&#40;</span>ProductF f g b<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
               pure x = ProductF <span style="color: green;">&#40;</span>pure x<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>pure x<span style="color: green;">&#41;</span>
              <span style="color: green;">&#40;</span>ProductF f g<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>ProductF x y<span style="color: green;">&#41;</span> = ProductF <span style="color: green;">&#40;</span>f &lt; *&gt; x<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>g &lt; *&gt; y<span style="color: green;">&#41;</span></pre>
<p>We can now do the following properly.</p>
<pre class="haskell">yy = FixF . ProductF <span style="color: green;">&#40;</span>Embed <span style="color: #3c7331;">&quot;foo&quot;</span><span style="color: green;">&#41;</span> $ InL $ Const <span style="color: green;">&#40;</span><span style="color: green;">&#41;</span>
xx = FixF . ProductF <span style="color: green;">&#40;</span>Embed <span style="color: #3c7331;">&quot;bar&quot;</span><span style="color: green;">&#41;</span> . InR .
        FixF . ProductF <span style="color: green;">&#40;</span>Embed <span style="color: #3c7331;">&quot;baz&quot;</span><span style="color: green;">&#41;</span> . InL $ Const <span style="color: green;">&#40;</span><span style="color: green;">&#41;</span></pre>
<p>So we've recovered proper lists in Haskell, as the "second-order fixpoint" of polynomial functors. And the types look right too:</p>
<pre class="haskell"><span style="color: #5d478b; font-style: italic;">-- :t yy</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; FixF (ProductF Embed (Sum (Const ()))) [Char]</span></pre>
<p>Because we've built our Applicative instances compositionally, we have an applicative for our list list construction automatically:</p>
<pre class="haskell"><span style="color: #5d478b; font-style: italic;">-- (++) &lt; $&gt; yy &lt; *&gt; xx</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; FixF (ProductF (Embed &quot;foobar&quot;) (InL (Const ())))</span></pre>
<p>This is precisely the "ZipList" applicative instance. In fact, our applicative instances from this "functor toolkit" are all "zippy" — matching up structure where possible, and "smashing it down" where not. This is because Sum, with its associated natural transformation logic, is the only way to introduce a disjoint choice of shape. Here are some simple examples with Sum to demonstrate:</p>
<pre class="haskell"><span style="color: #5d478b; font-style: italic;">-- liftA2 (++) (InL (Identity &quot;hi&quot;)) $</span>
<span style="color: #5d478b; font-style: italic;">--      InR (Product (Identity &quot; there&quot;) (Const ([12::Int])))</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; InL (Identity &quot;hi there&quot;)</span>
<span style="color: #5d478b; font-style: italic;">-- liftA2 (++) (InR (Identity &quot;hi&quot;)) $ InL (Product (Identity &quot; there&quot;) (Const ([12::Int])))</span>
<span style="color: #5d478b; font-style: italic;">-- &gt; InL (Product (Identity &quot;hi there&quot;) (Const [12]))</span></pre>
<p>We're always "smashing" towards the left. So in the first case, that means throwing away half of the pair. In the second case, it means injecting Const mempty into a pair, and then operating with that.</p>
<p>In any case, we now have infinite and possibly infinite branching structures. And not only are they Functors, but they're also Applicatives, and in a way that's uniform and straightforward to reason about.</p>
<p>In the next post, we'll stop building out our vocabulary of "base" Functors (though it's not quite complete) and instead push forward on what else these functors can provide "beyond" Applicative.</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Wed 26 Dec 2012</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2012/abstracting-with-applicatives/" rel="bookmark" title="Permanent Link: Abstracting with Applicatives">Abstracting with Applicatives</a></h2>
Posted by Gershom Bazerman under <a href="http://comonad.com/reader/category/category-theory/" title="View all posts in Category Theory" rel="category tag">Category Theory</a> ,  <a href="http://comonad.com/reader/category/data-structures/" title="View all posts in Data Structures" rel="category tag">Data Structures</a> ,  <a href="http://comonad.com/reader/category/monoids/" title="View all posts in Monoids" rel="category tag">Monoids</a> <br/><a href="http://comonad.com/reader/2012/abstracting-with-applicatives/#comments" title="Comment on Abstracting with Applicatives">[56] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>Consider the humble Applicative. More than a functor, less than a monad. It gives us such lovely syntax. Who among us still prefers to write <code>liftM2 foo a b</code> when we could instead write <code>foo &lt;$> a &lt;*> b</code>? But we seldom use the Applicative as such — when Functor is too little, Monad is too much, but a lax monoidal functor is just right. I noticed lately a spate of proper uses of Applicative —<a href="http://groups.inf.ed.ac.uk/links/formlets/">Formlets</a> (and their later incarnation in the <a href="http://hackage.haskell.org/package/reform">reform</a> library), <a href="http://hackage.haskell.org/package/optparse-applicative">OptParse-Applicative</a> (and its competitor library <a href=""http://hackage.haskell.org/package/cmdtheline>CmdTheLine</a>), and a <a href="http://gergo.erdi.hu/blog/2012-12-01-static_analysis_with_applicatives/">post by Gergo Erdi</a> on applicatives for declaring dependencies of computations. I also ran into a very similar genuine use for applicatives in working on the Panels library (part of <a href="http://hackage.haskell.org/package/jmacro-rpc">jmacro-rpc</a>), where I wanted to determine dependencies of a dynamically generated dataflow computation. And then, again, I stumbled into an applicative while cooking up a form validation library, which turned out to be a reinvention of the same ideas as formlets.</p>
<p>Given all this, It seems post on thinking with applicatives is in order, showing how to build them up and reason about them. One nice thing about the approach we'll be taking is that it uses a "final" encoding of applicatives, rather than building up and then later interpreting a structure. This is in fact how we typically write monads (pace operational, free, etc.), but since we more often only determine our data structures are applicative after the fact, we often get some extra junk lying around (OptParse-Applicative, for example, has a GADT that I think is entirely extraneous).</p>
<p>So the usual throat clearing:</p>
<pre class="haskell"><span style="color: #5d478b; font-style: italic;">{-# LANGUAGE TypeOperators, MultiParamTypeClasses, FlexibleInstances,
StandaloneDeriving, FlexibleContexts, UndecidableInstances,
GADTs, KindSignatures, RankNTypes #-}</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">module</span> Main <span style="color: #06c; font-weight: bold;">where</span>
<span style="color: #06c; font-weight: bold;">import</span> Control.Applicative <span style="color: #06c; font-weight: bold;">hiding</span> <span style="color: green;">&#40;</span>Const<span style="color: green;">&#41;</span>
<span style="color: #06c; font-weight: bold;">import</span> Data.Monoid <span style="color: #06c; font-weight: bold;">hiding</span> <span style="color: green;">&#40;</span>Sum, Product<span style="color: green;">&#41;</span>
<span style="color: #06c; font-weight: bold;">import</span> Control.<a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Monad"><span style="background-color: #efefbf; font-weight: bold;">Monad</span></a>.Identity
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a> a =&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a> <span style="color: green;">&#40;</span>Identity a<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:show"><span style="font-weight: bold;">show</span></a> <span style="color: green;">&#40;</span>Identity x<span style="color: green;">&#41;</span> = <span style="color: #3c7331;">&quot;(Identity &quot;</span> ++ <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:show"><span style="font-weight: bold;">show</span></a> x ++ <span style="color: #3c7331;">&quot;)&quot;</span></pre>
<p>And now, let's start with a classic applicative, going back to the <a href="http://www.soi.city.ac.uk/~ross/papers/Applicative.pdf">Applicative Programming With Effects</a> paper:</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">data</span> Const mo a = Const mo <span style="color: #06c; font-weight: bold;">deriving</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Const mo<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> _ <span style="color: green;">&#40;</span>Const mo<span style="color: green;">&#41;</span> = Const mo
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Monoid mo =&gt; Applicative <span style="color: green;">&#40;</span>Const mo<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    pure _ = Const mempty
    <span style="color: green;">&#40;</span>Const f<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>Const x<span style="color: green;">&#41;</span> = Const <span style="color: green;">&#40;</span>f &lt;&gt; x<span style="color: green;">&#41;</span></pre>
<p>(<code>Const</code> lives in <a href="http://hackage.haskell.org/package/transformers">transformers</a> as the <code>Constant</code> functor, or in base as <code>Const</code>)</p>
<p>Note that <code>Const</code> is not a monad. We've defined it so that its structure is independent of the `a` type. Hence if we try to write <code>(>>=) </code>of type <code>Const mo a -> (a -> Const mo b) -> Const mo b</code>, we'll have no way to "get out" the first `a` and feed it to our second argument.</p>
<p>One great thing about Applicatives is that there is no distinction between applicative transformers and applicatives themselves. This is to say that the composition of two applicatives is cleanly and naturally always also an applicative. We can capture this like so:</p>
<pre class="haskell">&nbsp;
<span style="color: #06c; font-weight: bold;">newtype</span> Compose f g a = Compose <span style="color: green;">&#40;</span>f <span style="color: green;">&#40;</span>g a<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">deriving</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> f, <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> g<span style="color: green;">&#41;</span> =&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Compose f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>Compose x<span style="color: green;">&#41;</span> = Compose $ <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> . <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a><span style="color: green;">&#41;</span> f x
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span>Applicative f, Applicative g<span style="color: green;">&#41;</span> =&gt; Applicative <span style="color: green;">&#40;</span>Compose f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    pure = Compose . pure . pure
    <span style="color: green;">&#40;</span>Compose f<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>Compose x<span style="color: green;">&#41;</span> = Compose $ <span style="color: green;">&#40;</span>&lt; *&gt;<span style="color: green;">&#41;</span> &lt; $&gt; f &lt; *&gt; x</pre>
<p>(<code>Compose</code> also lives in transformers)</p>
<p>Note that Applicatives compose <b>two</b> ways. We can also write:</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">data</span> Product f g a = Product <span style="color: green;">&#40;</span>f a<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>g a<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">deriving</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> f, <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> g<span style="color: green;">&#41;</span> =&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Product f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>Product  x y<span style="color: green;">&#41;</span> = Product <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f x<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f y<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span>Applicative f, Applicative g<span style="color: green;">&#41;</span> =&gt; Applicative <span style="color: green;">&#40;</span>Product f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    pure x = Product <span style="color: green;">&#40;</span>pure x<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>pure x<span style="color: green;">&#41;</span>
    <span style="color: green;">&#40;</span>Product f g<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>Product  x y<span style="color: green;">&#41;</span> = Product <span style="color: green;">&#40;</span>f &lt; *&gt; x<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>g &lt; *&gt; y<span style="color: green;">&#41;</span></pre>
<p>(<code>Product</code> lives in transformers as well)</p>
<p>This lets us now construct an extremely rich set of applicative structures from humble beginnings. For example, we can reconstruct the Writer Applicative.</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">type</span> Writer mo = Product <span style="color: green;">&#40;</span>Const mo<span style="color: green;">&#41;</span> Identity
&nbsp;
tell :: mo -&gt; Writer mo <span style="color: green;">&#40;</span><span style="color: green;">&#41;</span>
tell x = Product <span style="color: green;">&#40;</span>Const x<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>pure <span style="color: green;">&#40;</span><span style="color: green;">&#41;</span><span style="color: green;">&#41;</span></pre>
<pre>-- tell [1] *> tell [2]
-- > Product (Const [1,2]) (Identity ())</pre>
<p>Note that if we strip away the newtype noise, Writer turns into <code>(mo,a)</code> which is isomorphic to the Writer monad. However, we've learned something along the way, which is that the monoidal component of Writer (as long as we stay within the rules of applicative) is entirely independent from the "identity" component. However, if we went on to write the Monad instance for our writer (by defining <code>>>=</code>), we'd have to "reach in" to the identity component to grab a value to hand back to the function yielding our monoidal component. Which is to say we would destroy this nice seperation of "trace" and "computational content" afforded by simply taking the product of two Applicatives.</p>
<p>Now let's make things more interesting. It turns out that just as the composition of two applicatives may be a monad, so too the composition of two monads may be no stronger than an applicative!</p>
<p>We'll see this by introducing Maybe into the picture, for possibly failing computations.</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">type</span> FailingWriter mo = Compose <span style="color: green;">&#40;</span>Writer mo<span style="color: green;">&#41;</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Maybe"><span style="background-color: #efefbf; font-weight: bold;">Maybe</span></a>
&nbsp;
tellFW :: Monoid mo =&gt; mo -&gt; FailingWriter mo <span style="color: green;">&#40;</span><span style="color: green;">&#41;</span>
tellFW x = Compose <span style="color: green;">&#40;</span>tell x *&gt; pure <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:Just"><span style="font-weight: bold;">Just</span></a> <span style="color: green;">&#40;</span><span style="color: green;">&#41;</span><span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
&nbsp;
failFW :: Monoid mo =&gt; FailingWriter mo a
failFW = Compose <span style="color: green;">&#40;</span>pure <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:Nothing"><span style="font-weight: bold;">Nothing</span></a><span style="color: green;">&#41;</span></pre>
<pre>-- tellFW [1] *> tellFW [2]
-- > Compose (Product (Const [1,2]) (Identity Just ()))

-- tellFW [1] *> failFW *> tellFW [2]
-- > Compose (Product (Const [1,2]) (Identity Nothing))</pre>
<p>Maybe over Writer gives us the same effects we'd get in a Monad — either the entire computation fails, or we get the result and the trace. But Writer over Maybe gives us new behavior. We get the entire trace, even if some computations have failed! This structure, just like Const, cannot be given a proper Monad instance. (In fact if we take Writer over Maybe as a Monad, we get only the trace until the first point of failure).</p>
<p>This seperation of a monoidal trace from computational effects (either entirely independent of a computation [via a product] or independent between parts of a computation [via Compose]) is the key to lots of neat tricks with applicative functors.</p>
<p>Next, let's look at Gergo Erdi's "Static Analysis with Applicatives" that is built using free applicatives. We can get essentially the same behavior directly from the product of a constant monad with an arbitrary effectful monad representing our ambient environment of information. As long as we constrain ourselves to only querying it with the takeEnv function, then we can either read the left side of our product to statically read dependencies, or the right side to actually utilize them.</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">type</span> HasEnv k m = Product <span style="color: green;">&#40;</span>Const <span style="color: green;">&#91;</span>k<span style="color: green;">&#93;</span><span style="color: green;">&#41;</span> m
takeEnv :: <span style="color: green;">&#40;</span>k -&gt; m a<span style="color: green;">&#41;</span> -&gt; k -&gt; HasEnv k m a
takeEnv f x = Product <span style="color: green;">&#40;</span>Const <span style="color: green;">&#91;</span>x<span style="color: green;">&#93;</span><span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>f x<span style="color: green;">&#41;</span></pre>
<p>If we prefer, we can capture queries of a static environment directly with the standard Reader applicative, which is just a newtype over the function arrow. There are other varients of this that perhaps come closer to exactly how Erdi's post does things, but I think this is enough to demonstrate the general idea.</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">data</span> Reader r a = Reader <span style="color: green;">&#40;</span>r -&gt; a<span style="color: green;">&#41;</span>
<span style="color: #06c; font-weight: bold;">instance</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Reader r<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>Reader x<span style="color: green;">&#41;</span> = Reader <span style="color: green;">&#40;</span>f . x<span style="color: green;">&#41;</span>
<span style="color: #06c; font-weight: bold;">instance</span> Applicative <span style="color: green;">&#40;</span>Reader r<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    pure x = Reader $ pure x
    <span style="color: green;">&#40;</span>Reader f<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>Reader x<span style="color: green;">&#41;</span> = Reader <span style="color: green;">&#40;</span>f &lt; *&gt; x<span style="color: green;">&#41;</span>
&nbsp;
runReader :: <span style="color: green;">&#40;</span>Reader r a<span style="color: green;">&#41;</span> -&gt; r -&gt; a
runReader <span style="color: green;">&#40;</span>Reader f<span style="color: green;">&#41;</span> = f
&nbsp;
takeEnvNew :: <span style="color: green;">&#40;</span>env -&gt; k -&gt; a<span style="color: green;">&#41;</span> -&gt; k -&gt; HasEnv k <span style="color: green;">&#40;</span>Reader env<span style="color: green;">&#41;</span> a
takeEnvNew f x = Product <span style="color: green;">&#40;</span>Const <span style="color: green;">&#91;</span>x<span style="color: green;">&#93;</span><span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>Reader $ <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:flip"><span style="font-weight: bold;">flip</span></a> f x<span style="color: green;">&#41;</span></pre>
<p>So, what then is a full formlet? It's something that can be executed in one context as a monoid that builds a form, and in another as a parser. so the top level must be a product.</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">type</span> FormletOne mo a = Product <span style="color: green;">&#40;</span>Const mo<span style="color: green;">&#41;</span> Identity a</pre>
<p>Below the product, we read from an environment and perhaps get an answer. So that's reader with a maybe.</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">type</span> FormletTwo mo env a =
    Product <span style="color: green;">&#40;</span>Const mo<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>Compose <span style="color: green;">&#40;</span>Reader env<span style="color: green;">&#41;</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Maybe"><span style="background-color: #efefbf; font-weight: bold;">Maybe</span></a><span style="color: green;">&#41;</span> a</pre>
<p>Now if we fail, we want to have a trace of errors. So we expand out the Maybe into a product as well to get the following, which adds monoidal errors:</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">type</span> FormletThree mo err env a =
    Product <span style="color: green;">&#40;</span>Const mo<span style="color: green;">&#41;</span>
            <span style="color: green;">&#40;</span>Compose <span style="color: green;">&#40;</span>Reader env<span style="color: green;">&#41;</span> <span style="color: green;">&#40;</span>Product <span style="color: green;">&#40;</span>Const err<span style="color: green;">&#41;</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Maybe"><span style="background-color: #efefbf; font-weight: bold;">Maybe</span></a><span style="color: green;">&#41;</span><span style="color: green;">&#41;</span> a</pre>
<p>But now we get errors whether or not the parse succeeds. We want to say either the parse succeeds or we get errors. For this, we can turn to the typical Sum functor, which currently lives as Coproduct in comonad-transformers, but will hopefully be moving as Sum to the transformers library in short order.</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">data</span> Sum f g a = InL <span style="color: green;">&#40;</span>f a<span style="color: green;">&#41;</span> | InR <span style="color: green;">&#40;</span>g a<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">deriving</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Show"><span style="background-color: #efefbf; font-weight: bold;">Show</span></a>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> f, <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> g<span style="color: green;">&#41;</span> =&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> <span style="color: green;">&#40;</span>Sum f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>InL x<span style="color: green;">&#41;</span> = InL <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f x<span style="color: green;">&#41;</span>
    <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f <span style="color: green;">&#40;</span>InR y<span style="color: green;">&#41;</span> = InR <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> f y<span style="color: green;">&#41;</span></pre>
<p>The Functor instance is straightforward for Sum, but the applicative instance is puzzling. What should "pure" do? It needs to inject into either the left or the right, so clearly we need some form of "bias" in the instance. What we really need is the capacity to "work in" one side of the sum until compelled to switch over to the other, at which point we're stuck there. If two functors, F and G are in a relationship such that we can always send <code>f x -> g x</code> in a way that "respects" fmap (that is to say, such that (<code>fmap f . fToG == ftoG . fmap f</code>) then we call this a natural transformation. The action that sends f to g is typically called "eta". (We actually want something slightly stronger called a "monoidal natural transformation" that respects not only the functorial action <code>fmap</code> but the applicative action <code>&lt;*></code>, but we can ignore that for now).</p>
<p>Now we can assert that as long as there is a natural transformation between g and f, then Sum f g can be made an Applicative, like so:</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">class</span> Natural f g <span style="color: #06c; font-weight: bold;">where</span>
    eta :: f a -&gt; g a
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span>Applicative f, Applicative g, Natural g f<span style="color: green;">&#41;</span> =&gt;
  Applicative <span style="color: green;">&#40;</span>Sum f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    pure x = InR $ pure x
    <span style="color: green;">&#40;</span>InL f<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>InL x<span style="color: green;">&#41;</span> = InL <span style="color: green;">&#40;</span>f &lt; *&gt; x<span style="color: green;">&#41;</span>
    <span style="color: green;">&#40;</span>InR g<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>InR y<span style="color: green;">&#41;</span> = InR <span style="color: green;">&#40;</span>g &lt; *&gt; y<span style="color: green;">&#41;</span>
    <span style="color: green;">&#40;</span>InL f<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>InR x<span style="color: green;">&#41;</span> = InL <span style="color: green;">&#40;</span>f &lt; *&gt; eta x<span style="color: green;">&#41;</span>
    <span style="color: green;">&#40;</span>InR g<span style="color: green;">&#41;</span> &lt; *&gt; <span style="color: green;">&#40;</span>InL x<span style="color: green;">&#41;</span> = InL <span style="color: green;">&#40;</span>eta g &lt; *&gt; x<span style="color: green;">&#41;</span></pre>
<p>The natural transformation we'll tend to use simply sends any functor to Const.</p>
<pre>instance Monoid mo => Natural f (Const mo) where
    eta = const (Const mempty)</pre>
<p>However, there are plenty of other natural transformations that we could potentially make use of, like so:</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">instance</span> Applicative f =&gt;
  Natural g <span style="color: green;">&#40;</span>Compose f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
     eta = Compose . pure
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span>Applicative g, <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Functor"><span style="background-color: #efefbf; font-weight: bold;">Functor</span></a> f<span style="color: green;">&#41;</span> =&gt; Natural f <span style="color: green;">&#40;</span>Compose f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
     eta = Compose . <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#v:fmap"><span style="font-weight: bold;">fmap</span></a> pure
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span>Natural f g<span style="color: green;">&#41;</span> =&gt; Natural f <span style="color: green;">&#40;</span>Product f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    eta x = Product x <span style="color: green;">&#40;</span>eta x<span style="color: green;">&#41;</span>
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span>Natural g f<span style="color: green;">&#41;</span> =&gt; Natural g <span style="color: green;">&#40;</span>Product f g<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    eta x = Product <span style="color: green;">&#40;</span>eta x<span style="color: green;">&#41;</span> x
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Natural <span style="color: green;">&#40;</span>Product f g<span style="color: green;">&#41;</span> f <span style="color: #06c; font-weight: bold;">where</span>
    eta <span style="color: green;">&#40;</span>Product x _ <span style="color: green;">&#41;</span> = x
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Natural <span style="color: green;">&#40;</span>Product f g<span style="color: green;">&#41;</span> g <span style="color: #06c; font-weight: bold;">where</span>
    eta <span style="color: green;">&#40;</span>Product _ x<span style="color: green;">&#41;</span> = x
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Natural g f =&gt; Natural <span style="color: green;">&#40;</span>Sum f g<span style="color: green;">&#41;</span> f <span style="color: #06c; font-weight: bold;">where</span>
    eta <span style="color: green;">&#40;</span>InL x<span style="color: green;">&#41;</span> = x
    eta <span style="color: green;">&#40;</span>InR y<span style="color: green;">&#41;</span> = eta y
&nbsp;
<span style="color: #06c; font-weight: bold;">instance</span> Natural Identity <span style="color: green;">&#40;</span>Reader r<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span>
    eta <span style="color: green;">&#40;</span>Identity x<span style="color: green;">&#41;</span> = pure x</pre>
<p>In theory, there should also be a natural transformation that can be built magically from the product of any other two natural transformations, but that will just confuse the Haskell typechecker hopelessly. This is because we know that often different "paths" of typeclass choices will often be isomorphic, but the compiler has to actually pick one "canonical" composition of natural transformations to compute with, although multiple paths will typically be possible.</p>
<p>For similar reasons of avoiding overlap, we can't both have the terminal homomorphism that sends everything to "Const" <b>and</b> the initial homomorphism that sends "Identity" to anything like so:</p>
<pre class="haskell"><span style="color: #5d478b; font-style: italic;">-- instance Applicative g =&gt; Natural Identity g where</span>
<span style="color: #5d478b; font-style: italic;">--     eta (Identity x) = pure x</span>
&nbsp;</pre>
<p>We choose to keep the terminal transformation around because it is more generally useful for our purposes. As the comments below point out, it turns out that a version of "Sum" with the initial transformation baked in now lives in transformers as <code>Lift</code>.</p>
<p>In any case we can now write a proper Validation applicative:</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">type</span> Validation mo = Sum <span style="color: green;">&#40;</span>Const mo<span style="color: green;">&#41;</span> Identity
&nbsp;
validationError :: Monoid mo =&gt; mo -&gt; Validation mo a
validationError x = InL <span style="color: green;">&#40;</span>Const x<span style="color: green;">&#41;</span></pre>
<p>This applicative will yield either a single result, or an accumulation of monoidal errors. It exists on hackage in the <a href="http://hackage.haskell.org/package/Validation">Validation</a> package.</p>
<p>Now, based on the same principles, we can produce a full Formlet.</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">type</span> Formlet mo err env a =
    Product <span style="color: green;">&#40;</span>Const mo<span style="color: green;">&#41;</span>
            <span style="color: green;">&#40;</span>Compose <span style="color: green;">&#40;</span>Reader env<span style="color: green;">&#41;</span>
                     <span style="color: green;">&#40;</span>Sum <span style="color: green;">&#40;</span>Const err<span style="color: green;">&#41;</span> Identity<span style="color: green;">&#41;</span><span style="color: green;">&#41;</span>
    a</pre>
<p>All the type and newtype noise looks a bit ugly, I'll grant. But the idea is to <strong>think</strong> with structures built with applicatives, which gives guarantees that we're building applicative structures, and furthermore, structures with certain guarantees in terms of which components can be interpreted independently of which others. So, for example, we can strip away the newtype noise and find the following:</p>
<pre class="haskell"><span style="color: #06c; font-weight: bold;">type</span> FormletClean mo err env a = <span style="color: green;">&#40;</span>mo, env -&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Either"><span style="background-color: #efefbf; font-weight: bold;">Either</span></a> err a<span style="color: green;">&#41;</span></pre>
<p>Because we built this up from our basic library of applicatives, we also know how to write its applicative instance directly.</p>
<p>Now that we've gotten a basic algebraic vocabulary of applicatives, and especially now that we've produced this nifty Sum applicative (which I haven't seen presented before), we've gotten to where I intended to stop.</p>
<p>But lots of other questions arise, on two axes. First, what other typeclasses beyond applicative do our constructions satisfy? Second, what basic pieces of vocabulary are missing from our constructions — what do we need to add to flesh out our universe of discourse? (Fixpoints come to mind).</p>
<p>Also, what statements can we make about "completeness" — what portion of the space of all applicatives can we enumerate and construct in this way? Finally, why is it that monoids seem to crop up so much in the course of working with Applicatives? I plan to tackle at least some of these questions in future blog posts.</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Fri 7 Dec 2012</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2012/natural-deduction-sequent-calculus-and-type-classes/" rel="bookmark" title="Permanent Link: Natural Deduction, Sequent Calculus and Type Classes">Natural Deduction, Sequent Calculus and Type Classes</a></h2>
Posted by Dan Doel under <a href="http://comonad.com/reader/category/uncategorized/" title="View all posts in Uncategorized" rel="category tag">Uncategorized</a> <br/><a href="http://comonad.com/reader/2012/natural-deduction-sequent-calculus-and-type-classes/#comments" title="Comment on Natural Deduction, Sequent Calculus and Type Classes">[447] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>By and large, there are two sorts of proof systems that people use (these days) when studying logic: natural deduction, and sequent calculus. I know of at least one other---Hilbert style---but it is older, and the above systems were invented due to dissatisfaction with Hilbert systems (for a programming analogy, Hilbert systems are like programming entirely with combinators (S, K, etc.), rather than a lambda calculus).</p>
<h2>Natural Deduction</h2>
<p>Probably the best way to categorize the difference, for the purpose of where we're eventually going, is that natural deduction focuses on the ways to build proof terms up from their constituent parts. This comes in the form of introduction and elimination rules for the various propositions. For instance, the rules for conjunction are:</p>
<div class="codeblock">
<p align="center"> <img src='http://comonad.com/latex/783ccc760a775c36798d4f43a6b1d7f0.png' title=' \inference{A \,\,\,\,\,\,\,\,\, B}{A \wedge B}[$\wedge$-I]' alt=' \inference{A \,\,\,\,\,\,\,\,\, B}{A \wedge B}[$\wedge$-I]' align=absmiddle> </p>
<p align="center"> <img src='http://comonad.com/latex/72830d280ca501adac8178a3be715d1f.png' title=' \inference{A \wedge B}{A}[$\wedge$-E1] \,\,\,\,\,\, \inference{A \wedge B}{B}[$\wedge$-E2]' alt=' \inference{A \wedge B}{A}[$\wedge$-E1] \,\,\,\,\,\, \inference{A \wedge B}{B}[$\wedge$-E2]' align=absmiddle> </p>
</div>
<p>This spartan style gets a bit annoying (in my opinion) for the hypothetical premises of the implication introduction, but this can be solved by adding contexts:</p>
<div class="codeblock">
<p align="center"> <img src='http://comonad.com/latex/9b10e662928fdfe29c4969fe8b301a33.png' title=' \inference{\Gamma, A \vdash B}{\Gamma \vdash A \rightarrow B}[$\rightarrow$-I] ' alt=' \inference{\Gamma, A \vdash B}{\Gamma \vdash A \rightarrow B}[$\rightarrow$-I] ' align=absmiddle> </p>
<p align="center"> <img src='http://comonad.com/latex/2ebd29c4b4b2726fdc20e9e4f6bb4fa3.png' title=' \inference{\Gamma \vdash A \rightarrow B \,\,\,\,\,\,\,\,\, \Gamma \vdash A}{\Gamma \vdash B}[$\rightarrow$-E] ' alt=' \inference{\Gamma \vdash A \rightarrow B \,\,\,\,\,\,\,\,\, \Gamma \vdash A}{\Gamma \vdash B}[$\rightarrow$-E] ' align=absmiddle> </p>
</div>
<p>This is the style most commonly adopted for presenting type theories, except we reason about terms with a type, rather than just propositions. The context we added for convenience above also becomes fairly essential for keeping track of variables:</p>
<div class="codeblock">
<p align="center"> <img src='http://comonad.com/latex/a443c308ea53f52ac8c79390c6dd8151.png' title=' \inference{\Gamma \vdash M : A \,\,\,\,\,\,\,\,\, \Gamma \vdash N : B}{\Gamma \vdash (M, N) : A \times B}[$\times$-I] ' alt=' \inference{\Gamma \vdash M : A \,\,\,\,\,\,\,\,\, \Gamma \vdash N : B}{\Gamma \vdash (M, N) : A \times B}[$\times$-I] ' align=absmiddle> </p>
<p align="center"> <img src='http://comonad.com/latex/ec4510483acc5255daecda473c747b43.png' title=' \inference{\Gamma \vdash M : A \times B}{\Gamma \vdash \mathsf{fst}\, M : A}[$\times$-E1] ' alt=' \inference{\Gamma \vdash M : A \times B}{\Gamma \vdash \mathsf{fst}\, M : A}[$\times$-E1] ' align=absmiddle> </p>
<p align="center"> <img src='http://comonad.com/latex/09fff955437d0808666db20270638ee7.png' title=' \inference{\Gamma \vdash M : A \times B}{\Gamma \vdash \mathsf{snd}\, M : B}[$\times$-E2] ' alt=' \inference{\Gamma \vdash M : A \times B}{\Gamma \vdash \mathsf{snd}\, M : B}[$\times$-E2] ' align=absmiddle> </p>
<p align="center"> <img src='http://comonad.com/latex/3e743e06355407c7d58e5933cbb0bb2f.png' title=' \inference{\Gamma, x : A \vdash M : B}{\Gamma \vdash (\lambda x:A. \,\, M) : A \rightarrow B}[$\rightarrow$-I] ' alt=' \inference{\Gamma, x : A \vdash M : B}{\Gamma \vdash (\lambda x:A. \,\, M) : A \rightarrow B}[$\rightarrow$-I] ' align=absmiddle> </p>
<p align="center"> <img src='http://comonad.com/latex/55b21349085679b21328e7f97bbb5aa4.png' title=' \inference{\Gamma \vdash M : A \rightarrow B \,\,\,\,\,\,\,\,\, \Gamma \vdash N : A}{\Gamma \vdash M \, N : B}[$\rightarrow$-E] ' alt=' \inference{\Gamma \vdash M : A \rightarrow B \,\,\,\,\,\,\,\,\, \Gamma \vdash N : A}{\Gamma \vdash M \, N : B}[$\rightarrow$-E] ' align=absmiddle> </p>
</div>
<p>As can be seen, all the rules involve taking terms from the premise and building on them in the conclusion.</p>
<h2>Sequent Calculi</h2>
<p>The other type of system in question, sequent calculus, looks very similar, but represents a subtle shift in focus for our purposes (sequent calculi are a lot more obviously different when presenting classical logics). First, the inference rules relate sequents, which look a lot like our contextual judgments above, and I'll write them the same way. The difference is that not all rules operate on the conclusion side; some operate just on the context. Generally, introduction rules stay similar to natural deduction (and are called right rules), while elimination rules are replaced by manipulations of the context, and are called left rules. For pairs, we can use the rules:</p>
<div class="codeblock">
<p align="center"> <img src='http://comonad.com/latex/026317e5c95937857e51a76c0cb1e430.png' title=' \inference{\Gamma \vdash A \,\,\,\,\,\,\,\,\, \Gamma \vdash B}{\Gamma \vdash A \wedge B}[$\wedge$-R] ' alt=' \inference{\Gamma \vdash A \,\,\,\,\,\,\,\,\, \Gamma \vdash B}{\Gamma \vdash A \wedge B}[$\wedge$-R] ' align=absmiddle> </p>
<p align="center"> <img src='http://comonad.com/latex/3494cc388869c925dbb52144fd97d30d.png' title=' \inference{\Gamma, A, B \vdash C}{\Gamma, A \wedge B \vdash C}[$\wedge$-L] ' alt=' \inference{\Gamma, A, B \vdash C}{\Gamma, A \wedge B \vdash C}[$\wedge$-L] ' align=absmiddle> </p>
</div>
<p>We could also have two separate left rules:</p>
<div class="codeblock">
<p align="center"><img src='http://comonad.com/latex/110c2bbcf5f66f7c6398c3f6ba990f07.png' title='\inference{\Gamma, A \vdash C}{\Gamma, A \wedge B \vdash C}[$\wedge$-L1]' alt='\inference{\Gamma, A \vdash C}{\Gamma, A \wedge B \vdash C}[$\wedge$-L1]' align=absmiddle></p>
<p align="center"><img src='http://comonad.com/latex/84aa197282ba310d5b850f2cd0a60be3.png' title='\inference{\Gamma, B \vdash C}{\Gamma, A \wedge B \vdash C}[$\wedge$-L2]' alt='\inference{\Gamma, B \vdash C}{\Gamma, A \wedge B \vdash C}[$\wedge$-L2]' align=absmiddle></p>
</div>
<p>But these two different sets are equivalent as long as we're not considering substructural logics. Do note, however, that we're moving from <img src='http://comonad.com/latex/7fc56270e7a70fa81a5935b72eacbe29.png' title='A' alt='A' align=absmiddle> on the top left to <img src='http://comonad.com/latex/b05f38111aa635f08d594f45b197586a.png' title='A \wedge B' alt='A \wedge B' align=absmiddle> on the bottom left, using the fact that <img src='http://comonad.com/latex/b05f38111aa635f08d594f45b197586a.png' title='A \wedge B' alt='A \wedge B' align=absmiddle> is sufficient to imply <img src='http://comonad.com/latex/7fc56270e7a70fa81a5935b72eacbe29.png' title='A' alt='A' align=absmiddle>. That is, projections apply contravariantly to the left.</p>
<p>It turns out that almost no type theory is done in this style; natural deduction is far and away more popular. There are, I think, a few reasons for this. The first is: how do we even extend the left rules to type theory (eliminations are obvious, by contrast)? I know of two ways. The first is to introduce pattern matching into the contexts, so our left rule becomes:</p>
<div class="codeblock">
<p align="center"> <img src='http://comonad.com/latex/9013cfad42a40c2e76a7ecd7049e0e65.png' title=' \inference{\Gamma, x : A, y : B \vdash M : C}{\Gamma, (x, y) : A \times B \vdash M : C}[$\times$-L] ' alt=' \inference{\Gamma, x : A, y : B \vdash M : C}{\Gamma, (x, y) : A \times B \vdash M : C}[$\times$-L] ' align=absmiddle> </p>
</div>
<p>This is an acceptable choice (and may avoid some of the pitfalls in the next option), but it doesn't gel with your typical lambda calculus. It's probably more suited to a pattern calculus of some sort (although, even then, if you want to bend your brain, go look at the left rule for implication and try to figure out how it translates into such a theory; I think you probably need higher-order contexts of some sort). Anyhow, I'm not going to explore this further.</p>
<p>The other option (and one that I've seen in the literature) is that left rules actually involve a variable substitution. So we come up with the following rule:</p>
<div class="codeblock">
<p align="center"> <img src='http://comonad.com/latex/8b9164f5b58ce45f73a1dd4e5d792d2c.png' title=' \inference{\Gamma, x : A, y : B \vdash M : C}{\Gamma, p : A \times B \vdash M[x := \mathsf{fst}\, p, y := \mathsf{snd}\, p] : C}[$\times$-L] ' alt=' \inference{\Gamma, x : A, y : B \vdash M : C}{\Gamma, p : A \times B \vdash M[x := \mathsf{fst}\, p, y := \mathsf{snd}\, p] : C}[$\times$-L] ' align=absmiddle> </p>
</div>
<p>And with this rule, it becomes (I think) more obvious why natural deduction is preferred over sequent calculus, as implementing this rule in a type checker seems significantly harder. Checking the rules of natural deduction involves examining some outer-most structure of the term, and then checking the constituents of the term, possibly in an augmented context, and which rule we're dealing with is always syntax directed. But this left rule has no syntactic correspondent, so it seems as though we must nondeterministically try all left rules at each step, which is unlikely to result in a good algorithm. This is the same kind of problem that plagues extensional type theory, and ultimately results in only <em>derivations</em> being checkable, not terms.</p>
<h2>The Type Class Connection</h2>
<p>However, there are certain problems that I believe are well modeled by such a sequent calculus, and one of them is type class checking and associated dictionary translations. This is due mainly to the fact that the process is mainly context-directed term building, rather than term-directed type checking. As far as the type class algorithm goes, there are two interesting cases, having to do with the following two varieties of declaration:</p>
<pre class="haskell">&nbsp;
  <span style="color: #06c; font-weight: bold;">class</span> <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Eq"><span style="background-color: #efefbf; font-weight: bold;">Eq</span></a> a =&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Ord"><span style="background-color: #efefbf; font-weight: bold;">Ord</span></a> a <span style="color: #06c; font-weight: bold;">where</span> ...
  <span style="color: #06c; font-weight: bold;">instance</span> <span style="color: green;">&#40;</span><a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Eq"><span style="background-color: #efefbf; font-weight: bold;">Eq</span></a> a, <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Eq"><span style="background-color: #efefbf; font-weight: bold;">Eq</span></a> b<span style="color: green;">&#41;</span> =&gt; <a href="http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t:Eq"><span style="background-color: #efefbf; font-weight: bold;">Eq</span></a> <span style="color: green;">&#40;</span>a, b<span style="color: green;">&#41;</span> <span style="color: #06c; font-weight: bold;">where</span> ...
&nbsp;</pre>
<p>It turns out that each of these leads to a left rule in a kind of type class sequent calculus:</p>
<div class="codeblock">
<p align="center"> <img src='http://comonad.com/latex/f75290bbac8202c1d47fb62954e7606b.png' title=' \inference{\Gamma, \mathbf{Eq} \, a \vdash M : T}{\Gamma, \mathbf{Ord} \,  a \vdash M : T}[Eq-pre-Ord] ' alt=' \inference{\Gamma, \mathbf{Eq} \, a \vdash M : T}{\Gamma, \mathbf{Ord} \,  a \vdash M : T}[Eq-pre-Ord] ' align=absmiddle> </p>
<p align="center"> <img src='http://comonad.com/latex/4093e2180dce354d1d940438588e32a9.png' title=' \inference{\Gamma, \mathbf{Eq} \, (a, b) \vdash M : T}{\Gamma, \mathbf{Eq} \, a, \mathbf{Eq} \, b \vdash M : T}[Eq-pair] ' alt=' \inference{\Gamma, \mathbf{Eq} \, (a, b) \vdash M : T}{\Gamma, \mathbf{Eq} \, a, \mathbf{Eq} \, b \vdash M : T}[Eq-pair] ' align=absmiddle> </p>
</div>
<p>That is:</p>
<ol>
<li> if <code>Eq a</code> is a sufficient constraint for <code>M : T</code>, then the stronger constraint <code>Ord a</code> is also sufficient, so we can discharge the <code>Eq a</code> constraint and use <code>Ord a</code> instead.</li>
<li> We can discharge an <code>Eq (a, b)</code> constraint using two constraints, <code>Eq a, Eq b</code> together with an instance telling us how to do so. This also works for instances without contexts, giving us rules like:
<div class="codeblock">
<p align="center"><img src='http://comonad.com/latex/81d80ab8d9bd02d1b409ec1e59b4cdb4.png' title='\inference{\Gamma, \mathbf{Show\, Int} \vdash M : T}{\Gamma \vdash M : T}[Show-Int] ' alt='\inference{\Gamma, \mathbf{Show\, Int} \vdash M : T}{\Gamma \vdash M : T}[Show-Int] ' align=absmiddle></p>
</div>
</li>
</ol>
<p>Importantly, the type inference algorithm for type classes specifies when we should use these rules based only on the contexts we're dealing with. Now, these look more like the logical sequent rules, but it turns out that they have corresponding type theory-like versions when we consider dictionary passing:</p>
<div class="codeblock">
<p align="center"> <img src='http://comonad.com/latex/46926ac44142bdb8f4b1e07f8f6fd2b8.png' title=' \inference{\Gamma, eqd : \mathbf{Eq} \, a \vdash M : T}{\Gamma, ordd : \mathbf{Ord} \,  a \vdash M[eqd := \mathsf{eqOrdPrj}\, ordd] : T}[Eq-pre-Ord] ' alt=' \inference{\Gamma, eqd : \mathbf{Eq} \, a \vdash M : T}{\Gamma, ordd : \mathbf{Ord} \,  a \vdash M[eqd := \mathsf{eqOrdPrj}\, ordd] : T}[Eq-pre-Ord] ' align=absmiddle> </p>
<p align="center"> <img src='http://comonad.com/latex/89345750380d8f1f636ab4a29d31ef11.png' title='\inference{\Gamma, peq : \mathbf{Eq} \, (a, b) \vdash M : T}{\Gamma, aeq : \mathbf{Eq} \, a, beq : \mathbf{Eq} \, b \vdash M[peq := \mathsf{eqPair} \, aeq \, beq] : T}[Eq-pair]' alt='\inference{\Gamma, peq : \mathbf{Eq} \, (a, b) \vdash M : T}{\Gamma, aeq : \mathbf{Eq} \, a, beq : \mathbf{Eq} \, b \vdash M[peq := \mathsf{eqPair} \, aeq \, beq] : T}[Eq-pair]' align=absmiddle> </p>
</div>
<p>And this kind of substituting into dictionary variables produces exactly the evidence passing translation we want.</p>
<p>Another way to look at the difference in feasibility is that type checking involves moving bottom-to-top across the rules; in natural deduction, this is always easy, and we need look only at the terms to figure out which we should do. Type class checking and dictionary translation moves from top-to-bottom, directed by the left hand context, and produces terms on the right via complex operations, and that is a perfect fit for the sequent calculus rules.</p>
<p>I believe this corresponds to the general opinion on those who have studied sequent calculi with regard to type theory. A quick search revealed mostly papers on proof search, rather than type checking, and type classes rather fall into that realm (they're a very limited form of proof search).</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Sat 22 Sep 2012</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2012/unnatural-transformations-and-quantifiers/" rel="bookmark" title="Permanent Link: Unnatural Transformations and Quantifiers">Unnatural Transformations and Quantifiers</a></h2>
Posted by Dan Doel under <a href="http://comonad.com/reader/category/category-theory/" title="View all posts in Category Theory" rel="category tag">Category Theory</a> ,  <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> ,  <a href="http://comonad.com/reader/category/kan-extensions/" title="View all posts in Kan Extensions" rel="category tag">Kan Extensions</a> ,  <a href="http://comonad.com/reader/category/mathematics/" title="View all posts in Mathematics" rel="category tag">Mathematics</a> ,  <a href="http://comonad.com/reader/category/monads/" title="View all posts in Monads" rel="category tag">Monads</a> <br/><a href="http://comonad.com/reader/2012/unnatural-transformations-and-quantifiers/#comments" title="Comment on Unnatural Transformations and Quantifiers">[458] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>Recently, a fellow in category land <a href="http://golem.ph.utexas.edu/category/2012/09/where_do_monads_come_from.html">discovered</a> a fact that we in Haskell land have actually known for a while (in addition to things most of us probably don't). Specifically, given two categories <img src='http://comonad.com/latex/db5f7b3e9934fbc5a2859d88c4ba84a3.png' title='$\mathcal{C}$' alt='$\mathcal{C}$' align=absmiddle> and <img src='http://comonad.com/latex/eaf85f2b753a4c7585def4cc7ecade43.png' title='$\mathcal{D}$' alt='$\mathcal{D}$' align=absmiddle>, a functor <img src='http://comonad.com/latex/28408c9aaded61e50623807633e3ce37.png' title='$G : \mathcal{C} \rightarrow \mathcal{D}$' alt='$G : \mathcal{C} \rightarrow \mathcal{D}$' align=absmiddle>, and provided some conditions in <img src='http://comonad.com/latex/eaf85f2b753a4c7585def4cc7ecade43.png' title='$\mathcal{D}$' alt='$\mathcal{D}$' align=absmiddle> hold, there exists a monad <img src='http://comonad.com/latex/e049fb90e6d941ff5046ca1c48041c8b.png' title='$T^G$' alt='$T^G$' align=absmiddle>, the codensity monad of <img src='http://comonad.com/latex/5201385589993766eea584cd3aa6fa13.png' title='$G$' alt='$G$' align=absmiddle>.</p>
<p>In category theory, the codensity monad is given by the rather frightening expression:</p>
<p><img src='http://comonad.com/latex/050bb5034bed82159df4c52c89c07f3c.png' title='$ T^G(a) = \int_r \left[\mathcal{D}(a, Gr), Gr\right] $' alt='$ T^G(a) = \int_r \left[\mathcal{D}(a, Gr), Gr\right] $' align=absmiddle></p>
<p> <a href="http://comonad.com/reader/2012/unnatural-transformations-and-quantifiers/#more-660" class="more-link">(more...)</a></p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Wed 29 Aug 2012</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2012/hackage-mirror/" rel="bookmark" title="Permanent Link: Working around Hackage Outages">Working around Hackage Outages</a></h2>
Posted by Edward Kmett under <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> ,  <a href="http://comonad.com/reader/category/haskell/infrastructure/" title="View all posts in Infrastructure" rel="category tag">Infrastructure</a> <br/><a href="http://comonad.com/reader/2012/hackage-mirror/#comments" title="Comment on Working around Hackage Outages">[51] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>Luite Stegeman has a mirror of the packages from <a href="http://hackage.haskell.org/">Hackage</a>.</p>
<p>He uses it to power his incredibly useful <a href="http://hdiff.luite.com">hdiff</a> website.</p>
<p>During a Hackage outage, you can set up your local cabal configuration to point to it instead by (temporarily) replacing the remote-repo in your <code>~/.cabal/config</code> file with:</p>
<p><code><br />
remote-repo:<br />
  hdiff.luite.com:http://hdiff.luite.com/packages/archive<br />
</code></p>
<p>and then running <code>cabal update</code>.</p>
<p>I have a <a href="https://github.com/ekmett/lens/blob/master/config"><code>~/.cabal/config</code></a> that I use whenever hackage goes down in my <a href="https://github.com/ekmett/lens">lens</a> package.</p>
<p>If you use <a href="http://travis-ci.org/">travis-ci</a>, you can avoid build failures during hackage outages by first copying that config to ~/.cabal/config <a href="https://github.com/ekmett/lens/blob/master/.travis.yml#L4">during before_install</a>. -- You'll still be stuck waiting while it first tries to refresh from the real hackage server, but it only adds a few minutes to buildbot times.</p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
						<div class="post">
				<p class="post-date">Sun 24 Jun 2012</p>
<div class="post-info"><h2 class="post-title"><a href="http://comonad.com/reader/2012/mirrored-lenses/" rel="bookmark" title="Permanent Link: Mirrored Lenses">Mirrored Lenses</a></h2>
Posted by Edward Kmett under <a href="http://comonad.com/reader/category/algorithms/" title="View all posts in Algorithms" rel="category tag">Algorithms</a> ,  <a href="http://comonad.com/reader/category/data-structures/" title="View all posts in Data Structures" rel="category tag">Data Structures</a> ,  <a href="http://comonad.com/reader/category/haskell/" title="View all posts in Haskell" rel="category tag">Haskell</a> ,  <a href="http://comonad.com/reader/category/lenses/" title="View all posts in Lenses" rel="category tag">Lenses</a> <br/><a href="http://comonad.com/reader/2012/mirrored-lenses/#comments" title="Comment on Mirrored Lenses">[491] Comments</a>&nbsp;</div>
<div class="post-content">
	<p>Lenses are a great way to deal with functional references, but there are two common issues that arise from their use. </p>
<ol>
<li>There is a long-standing folklore position that lenses do not support polymorphic updates. This has actually caused a fair bit of embarrassment for the folks who'd like to incorporate lenses in any Haskell record system improvement.</li>
<li>Access control. It'd be nice to have read-only or write-only properties -- "one-way" or "mirrored" lenses, as it were. Moreover, lenses are commonly viewed as an all or nothing proposition, in that it is hard to mix them with arbitrary user functions.</li>
<li>Finally there is a bit of a cult around trying to generalize lenses by smashing a monad in the middle of them somewhere, it would be nice to be able to get into a list and work with each individual element in it without worrying about someone mucking up our lens laws, and perhaps avoid the whole generalized lens issue entirely.</li>
</ol>
<p>We'll take a whack at each of these concerns in turn today.<br />
 <a href="http://comonad.com/reader/2012/mirrored-lenses/#more-600" class="more-link">(more...)</a></p>
	<div class="post-info">
			</div>
	<div class="post-footer">&nbsp;</div>
</div>
							</div>
					<p align="center"><a href="http://comonad.com/reader/page/2/" >Next Page &raquo;</a></p>		
	</div>
	<div id="sidebar">
<h2>About</h2>
<ul><li><div align="center">
<script language="JavaScript" type="text/javascript" src="http://www.linkedinabox.com/inabox.js"></script>
<script language="JavaScript" type="text/javascript">createInABox('160', '274', '10285663', 'Edward Kmett',1,'undefined');</script>
</div></li></ul>
<?/*
	_e('About the Site:');
	bloginfo('description');
*/?>
		
		
		<h2><label for="s">Search</label></h2>
	<ul>
		<li>
			<form id="searchform" method="get" action="/reader/index.php">
				<div style="text-align:center">
					<p><input type="text" name="s" id="s" size="10" /> <input type="submit" name="submit" value="Search" /></p>
				</div>
			</form>
		</li>
	</ul>
<h2>RSS Feeds</h2>
	<ul>
		<li>
			<a title="RSS2 Feed for Posts" href="http://comonad.com/reader/feed/">Posts</a> | <a title="RSS2 Feed for Comments" href="http://comonad.com/reader/comments/feed/">Comments</a></li>	
	</ul>	

		<h2>Links</h2>
		<ul><li><a href="http://planet.haskell.org" target="_top">Planet Haskell</a></li>
<li><a href="http://www.haskell.org/hawiki/TheMonadReader" target="_top">The Monad.Reader</a></li>
</ul>
		
		<h2>Meta</h2>
				<ul>
										<li><a href="http://comonad.com/reader/wp-login.php">Log in</a></li>
									</ul>	
	</div>
	
<p id="footer">Design based on <a href="http://www.vanillamist.com" title="Vanilla Mist">www.vanillamist.com</a></p></div>
</div>
</body>
</html>
